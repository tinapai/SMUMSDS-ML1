{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','gluc','smoke','alco','active','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.59676925, 0.82714343, 0.4690938 , 0.56981913, 0.67389536,\n",
       "        0.20877488, 0.17586263, 0.17718148, 0.15691272, 0.21043698]),\n",
       " 'std_fit_time': array([0.09953698, 0.1779119 , 0.09510146, 0.16243457, 0.19888046,\n",
       "        0.07100195, 0.04217917, 0.04620582, 0.05259981, 0.09405589]),\n",
       " 'mean_score_time': array([0.00700227, 0.0036339 , 0.00364161, 0.00364685, 0.00295989,\n",
       "        0.00598399, 0.00465504, 0.00332435, 0.00631738, 0.00432158]),\n",
       " 'std_score_time': array([5.01612216e-03, 4.54131439e-04, 4.59480172e-04, 4.62948024e-04,\n",
       "        2.28453717e-05, 2.15438807e-03, 1.69654192e-03, 4.69965550e-04,\n",
       "        2.48858646e-03, 1.88042379e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77436411, 0.77434394, 0.77423573, 0.77433893, 0.77432185,\n",
       "        0.61547778, 0.61547771, 0.61547767, 0.61547767, 0.61547767]),\n",
       " 'split1_test_score': array([0.76548753, 0.76537142, 0.76543481, 0.76548649, 0.7653571 ,\n",
       "        0.65328433, 0.65326677, 0.65326544, 0.65326493, 0.65326497]),\n",
       " 'split2_test_score': array([0.7802853 , 0.78036549, 0.78036065, 0.78030579, 0.78022412,\n",
       "        0.64261832, 0.64260674, 0.64260443, 0.64260512, 0.78041703]),\n",
       " 'mean_test_score': array([0.77337898, 0.77336028, 0.77334373, 0.77337707, 0.77330102,\n",
       "        0.63712681, 0.63711707, 0.63711585, 0.63711591, 0.68305322]),\n",
       " 'std_test_score': array([0.00608119, 0.00616069, 0.00612601, 0.00608807, 0.00611221,\n",
       "        0.01591543, 0.01590819, 0.01590749, 0.0159074 , 0.07055378]),\n",
       " 'rank_test_score': array([ 1,  3,  4,  2,  5,  7,  8, 10,  9,  6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.773379 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773379 (0.006081) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773360 (0.006161) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773344 (0.006126) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773377 (0.006088) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773301 (0.006112) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.637127 (0.015915) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637117 (0.015908) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637116 (0.015907) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637116 (0.015907) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.683053 (0.070554) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=1000, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7778126510967109\n",
      "confusion matrix\n",
      " [[3381 1311]\n",
      " [1732 4187]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7732837004564681\n",
      "confusion matrix\n",
      " [[3378 1295]\n",
      " [1762 4176]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7774341023047546\n",
      "confusion matrix\n",
      " [[3339 1361]\n",
      " [1646 4265]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0724771 , 0.14029209, 0.0588425 , 0.12036641, 0.0681409 ,\n",
       "        0.11003931, 0.06449445, 0.11868278, 0.05589135, 0.15026553,\n",
       "        0.03855356, 0.12066483, 0.1067156 , 0.04521147, 0.1698796 ,\n",
       "        0.1279796 , 0.03623637, 0.16784644, 0.12930894, 0.03658096,\n",
       "        0.18417303, 0.11136858, 0.0378987 , 0.13830805, 0.10038638]),\n",
       " 'std_fit_time': array([0.01093367, 0.00870546, 0.00354984, 0.01165632, 0.01434765,\n",
       "        0.00169528, 0.01155431, 0.02891668, 0.00217465, 0.01434609,\n",
       "        0.00417367, 0.0111725 , 0.0168263 , 0.00835769, 0.01141046,\n",
       "        0.01435748, 0.00470168, 0.00122883, 0.01305101, 0.00188802,\n",
       "        0.02835262, 0.0012445 , 0.00570075, 0.00752963, 0.00385977]),\n",
       " 'mean_score_time': array([0.00365297, 0.00365599, 0.00465417, 0.00497707, 0.00399963,\n",
       "        0.00365655, 0.00365678, 0.00365607, 0.00394869, 0.003335  ,\n",
       "        0.00398819, 0.00332673, 0.0033261 , 0.00531888, 0.00332419,\n",
       "        0.00498668, 0.00398954, 0.00432316, 0.00332451, 0.00332419,\n",
       "        0.00465536, 0.0036571 , 0.00398922, 0.0046552 , 0.00465425]),\n",
       " 'std_score_time': array([4.67629557e-04, 4.70078344e-04, 4.70190736e-04, 8.27768805e-04,\n",
       "        1.54087198e-05, 4.70302644e-04, 4.70134086e-04, 9.39256568e-04,\n",
       "        5.79940636e-05, 4.61953373e-04, 8.77806426e-07, 4.72831444e-04,\n",
       "        4.68227436e-04, 1.88008666e-03, 4.70077860e-04, 2.15427770e-03,\n",
       "        4.49566384e-07, 1.22582790e-03, 4.70358870e-04, 4.70077941e-04,\n",
       "        4.70527910e-04, 4.70358870e-04, 3.89335909e-07, 1.69255247e-03,\n",
       "        2.35038925e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77735931, 0.77736586, 0.77734318, 0.77734297, 0.77734038,\n",
       "        0.7773411 , 0.77734002, 0.7773416 , 0.7773403 , 0.77734052,\n",
       "        0.77731994, 0.77731922, 0.77731979, 0.77734009, 0.77733915,\n",
       "        0.77734052, 0.77734178, 0.77734059, 0.77734102, 0.77734153,\n",
       "        0.77734074, 0.77734167, 0.7773416 , 0.77734196, 0.77734214]),\n",
       " 'split1_test_score': array([0.77797437, 0.77797938, 0.77796425, 0.77796386, 0.77796375,\n",
       "        0.77796339, 0.77796465, 0.77796306, 0.77796404, 0.77796378,\n",
       "        0.77794916, 0.77794902, 0.77794862, 0.77796371, 0.77796378,\n",
       "        0.77796418, 0.7779636 , 0.77796296, 0.77796025, 0.77796321,\n",
       "        0.77796213, 0.77796346, 0.77796321, 0.77796468, 0.77796389]),\n",
       " 'split2_test_score': array([0.77379457, 0.77379915, 0.77379064, 0.77379223, 0.77379122,\n",
       "        0.77379075, 0.77378956, 0.77379064, 0.77378859, 0.77379086,\n",
       "        0.77378851, 0.77378884, 0.77378862, 0.77378855, 0.77378837,\n",
       "        0.77378866, 0.77379061, 0.77379154, 0.77379028, 0.77379061,\n",
       "        0.77379043, 0.77379089, 0.77379061, 0.77379075, 0.77379107]),\n",
       " 'mean_test_score': array([0.77637608, 0.77638146, 0.77636603, 0.77636635, 0.77636511,\n",
       "        0.77636508, 0.77636474, 0.7763651 , 0.77636431, 0.77636505,\n",
       "        0.77635254, 0.77635236, 0.77635235, 0.77636412, 0.77636377,\n",
       "        0.77636445, 0.77636533, 0.77636503, 0.77636385, 0.77636511,\n",
       "        0.77636443, 0.77636534, 0.77636514, 0.7763658 , 0.7763657 ]),\n",
       " 'std_test_score': array([0.00184259, 0.00184307, 0.00183864, 0.00183774, 0.00183773,\n",
       "        0.00183797, 0.0018387 , 0.00183801, 0.00183902, 0.00183793,\n",
       "        0.00183115, 0.00183083, 0.00183091, 0.00183891, 0.00183885,\n",
       "        0.00183907, 0.00183822, 0.00183738, 0.00183727, 0.00183806,\n",
       "        0.00183769, 0.00183802, 0.00183807, 0.0018385 , 0.00183815]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3, 10, 13, 16, 12, 19, 14, 23, 24, 25, 20, 22, 17,  8,\n",
       "        15, 21, 11, 18,  7,  9,  5,  6])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.776381 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776376 (0.001843) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776381 (0.001843) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776366 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001839) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776353 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776352 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776352 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776365 (0.001837) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776364 (0.001837) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776364 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7772939740908584\n",
      "[0.7181227  0.71689756 0.71237395]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7757609974791919\n",
      "confusion matrix\n",
      " [[3425 1301]\n",
      " [1714 4171]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7789532951984123\n",
      "confusion matrix\n",
      " [[3418 1332]\n",
      " [1659 4202]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7750579545752139\n",
      "confusion matrix\n",
      " [[3354 1299]\n",
      " [1772 4186]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29725385, 0.8957176 , 0.12865162, 0.28283007, 0.10075454]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','age','gender','height','weight','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bmi','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.06715377, 2.32718468, 3.63931052, 0.05352354, 2.02214718,\n",
       "        3.6851689 , 0.0418884 , 2.02882441, 3.57047542, 0.04785983,\n",
       "        2.02494955, 3.58376257, 0.06781888, 1.99593377, 3.53813108]),\n",
       " 'std_fit_time': array([0.00448684, 0.31920119, 0.05985453, 0.01293594, 0.03740269,\n",
       "        0.05784741, 0.00081381, 0.05553029, 0.06400667, 0.00706186,\n",
       "        0.02777344, 0.07860238, 0.01332982, 0.0424709 , 0.04103285]),\n",
       " 'mean_score_time': array([0.00365583, 0.00395568, 0.00294582, 0.00332403, 0.00298842,\n",
       "        0.0026323 , 0.00299207, 0.00365559, 0.00263182, 0.0023396 ,\n",
       "        0.00264359, 0.0033075 , 0.00398922, 0.00462969, 0.00394996]),\n",
       " 'std_score_time': array([9.39088107e-04, 1.63003243e-03, 8.26212019e-06, 1.88042380e-03,\n",
       "        8.29912582e-04, 4.50805606e-04, 1.12391596e-07, 4.68617578e-04,\n",
       "        4.73652910e-04, 4.61339684e-04, 4.58831708e-04, 1.89071105e-03,\n",
       "        1.62839744e-03, 1.89988598e-03, 1.41524403e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100,\n",
       "                    1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}],\n",
       " 'split0_test_score': array([0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918,\n",
       "        0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918,\n",
       "        0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918]),\n",
       " 'split1_test_score': array([0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204,\n",
       "        0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204,\n",
       "        0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204]),\n",
       " 'split2_test_score': array([0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652,\n",
       "        0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652,\n",
       "        0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652]),\n",
       " 'mean_test_score': array([0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258,\n",
       "        0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258,\n",
       "        0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258]),\n",
       " 'std_test_score': array([0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301,\n",
       "        0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301,\n",
       "        0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "#  {'C': [.1, 1, 10, 100, 1000],\n",
    " #  'penalty': ['l1'],\n",
    "  # 'solver': ['liblinear', 'saga']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=4000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.735133 using {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.1, class_weight=None, solver='lbfgs' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7363849510067295\n",
      "confusion matrix\n",
      " [[3423 1246]\n",
      " [1911 4031]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7375246503388824\n",
      "confusion matrix\n",
      " [[3384 1301]\n",
      " [1838 4088]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7327580506037955\n",
      "confusion matrix\n",
      " [[3458 1278]\n",
      " [1922 3953]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0325791 , 0.07116469, 0.02892232, 0.0730962 , 0.03889481,\n",
       "        0.0545187 , 0.0279146 , 0.06483905, 0.03257958, 0.06748637,\n",
       "        0.02127663, 0.07280533, 0.06948074, 0.01762009, 0.11470334,\n",
       "        0.09506663, 0.0169553 , 0.0887622 , 0.05784512, 0.02393643,\n",
       "        0.08477259, 0.05053147, 0.01562421, 0.09341677, 0.07446869]),\n",
       " 'std_fit_time': array([0.0032912 , 0.01220755, 0.00354928, 0.01957796, 0.01345487,\n",
       "        0.00680523, 0.00244313, 0.00923087, 0.00124277, 0.00981776,\n",
       "        0.0012439 , 0.00960049, 0.01541438, 0.0032915 , 0.02268182,\n",
       "        0.03235604, 0.00293731, 0.00453496, 0.00508453, 0.00373092,\n",
       "        0.01355328, 0.00773932, 0.00308316, 0.01727902, 0.01129311]),\n",
       " 'mean_score_time': array([0.00432173, 0.00363588, 0.00233873, 0.00265988, 0.00432158,\n",
       "        0.00399113, 0.0033346 , 0.00398763, 0.00432165, 0.00465401,\n",
       "        0.00265988, 0.00265956, 0.00365671, 0.00365694, 0.00564011,\n",
       "        0.0049866 , 0.00398938, 0.00299207, 0.0039889 , 0.00498645,\n",
       "        0.00299263, 0.00332475, 0.00332355, 0.00432189, 0.00498573]),\n",
       " 'std_score_time': array([1.88081723e-03, 9.32039673e-04, 4.62242751e-04, 4.70246438e-04,\n",
       "        1.88092956e-03, 2.15273440e-03, 4.61568695e-04, 2.15578633e-03,\n",
       "        2.04911212e-03, 1.88081723e-03, 4.70077860e-04, 4.70527507e-04,\n",
       "        1.69549779e-03, 9.40998764e-04, 4.62634009e-04, 2.15446164e-03,\n",
       "        1.40995259e-03, 8.13712245e-04, 1.40894105e-03, 1.62937097e-03,\n",
       "        3.37174788e-07, 4.71371801e-04, 1.87958086e-03, 1.88053628e-03,\n",
       "        1.40950306e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013]),\n",
       " 'split1_test_score': array([0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018]),\n",
       " 'split2_test_score': array([0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786]),\n",
       " 'mean_test_score': array([0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297]),\n",
       " 'std_test_score': array([0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734673 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7327580506037955\n",
      "[0.70587127 0.69503346 0.70530581]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7392666949100711\n",
      "confusion matrix\n",
      " [[3453 1206]\n",
      " [1905 4047]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7323875924914998\n",
      "confusion matrix\n",
      " [[3444 1238]\n",
      " [1934 3995]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7273072261367277\n",
      "confusion matrix\n",
      " [[3440 1286]\n",
      " [1945 3940]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.09443405]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.85772761, 1.05984712, 0.89385668, 1.24303007, 0.80253839,\n",
       "        0.25166003, 0.23107775, 0.24800316, 0.25132895, 0.18483861]),\n",
       " 'std_fit_time': array([0.11453076, 0.3602612 , 0.27844553, 0.22999703, 0.15472474,\n",
       "        0.11010601, 0.0640617 , 0.08573024, 0.07164654, 0.06119013]),\n",
       " 'mean_score_time': array([0.00429519, 0.00396919, 0.0039645 , 0.00629536, 0.00562851,\n",
       "        0.00432158, 0.00329518, 0.00664941, 0.00465322, 0.00731365]),\n",
       " 'std_score_time': array([1.26596863e-03, 2.02501463e-05, 1.70713178e-05, 1.87108661e-03,\n",
       "        1.71076111e-03, 1.24413389e-03, 4.90599204e-04, 1.87969325e-03,\n",
       "        1.69482766e-03, 4.70077941e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77987107, 0.77982106, 0.77981164, 0.77981232, 0.77979055,\n",
       "        0.66067475, 0.66066092, 0.6627988 , 0.67384393, 0.66065905]),\n",
       " 'split1_test_score': array([0.78198072, 0.78156855, 0.78206247, 0.78207487, 0.78161375,\n",
       "        0.61334362, 0.61334228, 0.61334214, 0.61334214, 0.6133421 ]),\n",
       " 'split2_test_score': array([0.78019565, 0.78027309, 0.77966553, 0.78027482, 0.7802537 ,\n",
       "        0.65539128, 0.6528766 , 0.65285732, 0.65285732, 0.65285721]),\n",
       " 'mean_test_score': array([0.78068248, 0.78055424, 0.78051321, 0.78072067, 0.78055266,\n",
       "        0.64313655, 0.64229327, 0.64299942, 0.64668113, 0.64228612]),\n",
       " 'std_test_score': array([0.00092751, 0.00074059, 0.00109711, 0.000976  , 0.00077376,\n",
       "        0.02117692, 0.02071664, 0.02135999, 0.02508287, 0.02071287]),\n",
       " 'rank_test_score': array([ 2,  3,  5,  1,  4,  7,  9,  8,  6, 10])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.780721 using {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780682 (0.000928) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780554 (0.000741) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780513 (0.001097) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780721 (0.000976) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780553 (0.000774) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.643137 (0.021177) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642293 (0.020717) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642999 (0.021360) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.646681 (0.025083) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642286 (0.020713) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7854504726435688\n",
      "confusion matrix\n",
      " [[3388 1222]\n",
      " [1725 4276]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7817470520594516\n",
      "confusion matrix\n",
      " [[3372 1281]\n",
      " [1730 4228]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7786116035695742\n",
      "confusion matrix\n",
      " [[3399 1389]\n",
      " [1631 4192]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0867784 , 0.19680611, 0.09707483, 0.20843832, 0.08710074,\n",
       "        0.23805221, 0.08577061, 0.22979315, 0.08510574, 0.19846845,\n",
       "        0.0468746 , 0.2081097 , 0.17187405, 0.0588429 , 0.26696332,\n",
       "        0.16589936, 0.04654225, 0.23171298, 0.16057134, 0.06151366,\n",
       "        0.18784165, 0.15691241, 0.04688811, 0.23803997, 0.16389434]),\n",
       " 'std_fit_time': array([0.00803452, 0.03944448, 0.02067177, 0.02817772, 0.01924246,\n",
       "        0.01225835, 0.00081624, 0.0336347 , 0.00896927, 0.02378397,\n",
       "        0.00635917, 0.0363652 , 0.01964279, 0.0078523 , 0.03987367,\n",
       "        0.01483394, 0.00094117, 0.00983122, 0.00695654, 0.02439465,\n",
       "        0.00878869, 0.02823671, 0.00588624, 0.02971557, 0.01459726]),\n",
       " 'mean_score_time': array([0.00664981, 0.00598502, 0.00797757, 0.00398938, 0.00432142,\n",
       "        0.00396641, 0.00797892, 0.00464328, 0.00531896, 0.00465504,\n",
       "        0.00498676, 0.00364582, 0.00365655, 0.00565076, 0.00564138,\n",
       "        0.00398986, 0.00571744, 0.00399065, 0.00498629, 0.00576242,\n",
       "        0.00364614, 0.00598502, 0.00564893, 0.00397937, 0.00598383]),\n",
       " 'std_score_time': array([1.24371040e-03, 2.82131005e-03, 2.82052358e-03, 2.24783192e-07,\n",
       "        4.70134691e-04, 1.66896790e-05, 2.15442485e-03, 9.47835939e-04,\n",
       "        1.88019902e-03, 2.35016452e-03, 2.15457201e-03, 4.85475743e-04,\n",
       "        4.71145933e-04, 1.69393912e-03, 2.35812633e-03, 4.05233662e-07,\n",
       "        2.30456559e-03, 1.52040533e-06, 1.40939063e-03, 2.29656734e-03,\n",
       "        4.63135807e-04, 2.15541816e-03, 2.48448719e-03, 8.02158127e-04,\n",
       "        1.62800842e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77901223, 0.77901557, 0.77900687, 0.77900637, 0.77900565,\n",
       "        0.77900536, 0.77900446, 0.77900543, 0.77900464, 0.77900612,\n",
       "        0.77900392, 0.779004  , 0.77900331, 0.77900482, 0.77900407,\n",
       "        0.77900446, 0.77900565, 0.77900572, 0.77900619, 0.77900511,\n",
       "        0.77900551, 0.77900525, 0.77900511, 0.77900497, 0.77900561]),\n",
       " 'split1_test_score': array([0.77520229, 0.77520164, 0.77519228, 0.77519225, 0.77519171,\n",
       "        0.77519044, 0.77519116, 0.77519055, 0.77519048, 0.77519077,\n",
       "        0.77519766, 0.77519622, 0.77519748, 0.77519102, 0.77518972,\n",
       "        0.77519041, 0.77519084, 0.77519095, 0.77519124, 0.77519084,\n",
       "        0.77519059, 0.77519023, 0.77519091, 0.77519149, 0.77519033]),\n",
       " 'split2_test_score': array([0.77860264, 0.77860383, 0.77855605, 0.77855623, 0.7785513 ,\n",
       "        0.7785512 , 0.77855076, 0.77855231, 0.77855105, 0.77855199,\n",
       "        0.77854523, 0.77854375, 0.77854541, 0.77855148, 0.77855159,\n",
       "        0.77855231, 0.77855188, 0.77855127, 0.77855202, 0.77855181,\n",
       "        0.7785513 , 0.77855174, 0.77855174, 0.77855041, 0.77855051]),\n",
       " 'mean_test_score': array([0.77760572, 0.77760701, 0.77758507, 0.77758495, 0.77758289,\n",
       "        0.77758233, 0.77758213, 0.77758277, 0.77758206, 0.77758296,\n",
       "        0.77758227, 0.77758132, 0.77758207, 0.77758244, 0.77758179,\n",
       "        0.77758239, 0.77758279, 0.77758265, 0.77758315, 0.77758259,\n",
       "        0.77758247, 0.77758241, 0.77758259, 0.77758229, 0.77758215]),\n",
       " 'std_test_score': array([0.00170769, 0.00170914, 0.00170193, 0.00170185, 0.00170096,\n",
       "        0.00170145, 0.00170078, 0.00170164, 0.00170121, 0.00170166,\n",
       "        0.00169654, 0.00169696, 0.00169649, 0.00170109, 0.00170151,\n",
       "        0.00170143, 0.00170148, 0.00170133, 0.00170147, 0.00170131,\n",
       "        0.00170145, 0.00170163, 0.00170127, 0.0017007 , 0.00170145]),\n",
       " 'rank_test_score': array([ 2,  1,  3,  4,  7, 17, 21,  9, 23,  6, 19, 25, 22, 14, 24, 16,  8,\n",
       "        10,  5, 12, 13, 15, 11, 18, 20])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.777607 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777606 (0.001708) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777607 (0.001709) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777585 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777585 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777583 (0.001702) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777583 (0.001702) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001697) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777581 (0.001697) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001696) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001702) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7786511652363493\n",
      "[0.71265668 0.71199698 0.71623787]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7773814507479797\n",
      "confusion matrix\n",
      " [[3361 1293]\n",
      " [1725 4232]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7734876054094295\n",
      "confusion matrix\n",
      " [[3313 1292]\n",
      " [1712 4294]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7798040522052846\n",
      "confusion matrix\n",
      " [[3402 1324]\n",
      " [1699 4186]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29565621,  0.9020981 ,  0.1296683 ,  0.3236999 , -0.07848062,\n",
       "        -0.03665095, -0.04820689, -0.09434821,  0.10183709]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.780\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xu8VXWd//HXmwOICmkKjSkikDijmZqS98x+Rnlp1MzxhnfT0USczClLxxpHZ5gcnXIyiZTMMrHUjEmKMcdySkFgvASSCijjycqTgoEKyOHz+2MtjtvD3vusc85e+/p+Ph7n4V7fvfZen7UP7s/53hURmJmZAQyodQBmZlY/nBTMzKyLk4KZmXVxUjAzsy5OCmZm1sVJwczMujgpmJlZFycFMzPr4qRgZmZdBtY6gN4aPnx4jB49utZhmJk1lAULFvwpIkb0dF7DJYXRo0czf/78WodhZtZQJC3Pcp6bj8zMrIuTgpmZdXFSMDOzLg3Xp1DMm2++SXt7O2vWrKl1KHVryJAhjBw5kkGDBtU6FDOrY02RFNrb2xk2bBijR49GUq3DqTsRwcsvv0x7eztjxoypdThmVsdyaz6SNF3SS5IWlnhekm6QtETSk5L27uu11qxZw7bbbuuEUIIktt12W9ekzKxHedYUbgW+DtxW4vkjgHHpz37ATel/+8QJoTx/PmaNZcHyFVz4vQX8cdVaBreJIZu10aYBnLDPSC47ctfcrptbUoiIhySNLnPKMcBtkewHOkfS1pLeHRG/zysmM7Na2vhF/4dVa7vKNmsTw7YYxBvrOnljbScICNhQ8Lq1ncHa19cDMPWhZQC5JYZa9insALxQcNyelm2SFCSdB5wHMGrUqKoE11tDhw5l9erV/XqPF198kcmTJ3PXXXcVfX7lypV8//vf59Of/nSm882sehYsX8Ep0x5hbeem+96n3/NFre0M1q5a91ZBqRML/GzRH5oyKRRrzyj6cUTENGAawPjx4zN8ZI1p++23L/sFv3LlSr7xjW90JYWezjezylqwfAVnTp/LqrWdvXpdpb+0Dn/vdhV+x7fUMim0AzsWHI8EXqzWxRcsX8GcZS+z/9ht2Wend+ZyjeXLl3P22WfT0dHBiBEj+Pa3v82oUaNYunQpEydOpLOzkyOOOILrr7+e1atX8/zzz/Pxj3+chQsXsmjRIs466yzWrVvHhg0buPvuu/mHf/gHli5dyl577cWECRO48MILu87v7Ozk85//PLNnz0YS5557LhdddFEu92XWbE6/ZS4PPfunTcrbBMOGDGT12k4GKFjXu1xQUVttMbCx+xQymAlMkjSDpIP51Ur0J/zjfy7iqRf/XPacVWve5Ld/WMWGgAGCv9puGMOGlB6/v9v27+BLf/3eXscyadIkTj/9dM444wymT5/O5MmTuffee7n44ou5+OKLOfnkk5k6dWrR106dOpWLL76YiRMnsm7dOjo7O5kyZQoLFy7k8ccfB+D555/vOn/atGk899xzPPbYYwwcOJBXXnml1/GaNaMpsxZ3tcN3N4C3t9131xmw8o31ucS1UbE+BaXXBhg3Ykvu/+yhucZQKLekIOkO4FBguKR24EvAIICImArMAo4ElgCvA2flFUt3f16zng3pB74hkuNySaGvHnnkEe655x4ATjvtND73uc91ld97770AnHLKKVx66aWbvPaAAw7gmmuuob29neOOO45x48aVvdbPf/5zzj//fAYOTH6l22yzTSVvxazuFf61v1mbCGBdkfb9QuUSQiVp488A+Mu/GMY/Hfu+3Foo+ivP0Ucn9/B8ABdW+rpZ/qJfsHwFE2+ew5vrNzBo4AC+dtL7q/IL6s2w0FNOOYX99tuP++67j4997GPcfPPNjB07tuT5EeFhp9bUio3cKaVYZ2+1jBg6mHlXTKjZ9furKWY099Y+O72T2z+1f+59CgceeCAzZszgtNNO4/bbb+fggw8GYP/99+fuu+/mxBNPZMaMGUVfu2zZMsaOHcvkyZNZtmwZTz75JHvuuSerVq0qev5HP/pRpk6dyqGHHtrVfOTagjWqCdf9gmc7Xqt1GG/rUxg0QLyxPqlbVLtJp5paMilAkhgqmQxef/11Ro4c2XV8ySWXcMMNN3D22Wdz7bXXdnU0A3z1q1/l1FNP5brrruOoo45iq6222uT97rzzTr73ve8xaNAgtttuO6688kq22WYbDjroIHbffXeOOOIILrzwrYrWpz71KZ555hn22GMPBg0axLnnnsukSZMqdn9meaj1l/8AwaABIhA7v2vLum7WqRYlrTiNY/z48dF9k53Fixez66759cZX2uuvv87mm2+OJGbMmMEdd9zBj3/849yv22ifkzWHUiN78jRoQNJcW9in0Mx/3WchaUFEjO/pvJatKdTSggULmDRpEhHB1ltvzfTp02sdklm/1fqvfoB3DBnIt8/at+X/2u8PJ4Ua+OAHP8gTTzxR6zDM+mTjHJ/r/+tpqt2f2zZAnHvwmFzH6be6pkkKHn1TXqM1E1r9qGUNoNWbfGqhKZLCkCFDePnll718dgkb91MYMmRIrUOxOnf6LXP51bN/qtr4fYDd3l3f4/ZbTVMkhZEjR9Le3k5HR0etQ6lbG3deM9uomh3Ag9vE2Qe52acRNEVSGDRokHcUM+tBNZLAAMF5HxzrL/8G1hRJwczeUq0aQKPP3LXinBTMmkA1OoPd6dsanBTMGsyC5Ss4/qaHK75G/0YCPjhuOLed0+fdca2BOSmY1bm+buyS1SFOAFbAScGszixYvoITpj6cy8QwAXddcKCHf1pJTgpmdSCPzmF3BFtfOCmY1VClO4jdFGT95aRgVmWVSgQeDWR5cFIwy9mC5Sv45E0P9+s9BggO3tm1AMufk4JZDirRR+CagNWCk4JZhVSiWcidw1ZrTgpm/TBl1mKmPrSsX+/hjWGsnjgpmPXS7lf+jNXr+jeRTMDfHuKF46z+OCmY9WDB8hWcMu0R1vZzNpmbhqwROCmYFfGeL9xXkRnFnjdgjcZJwSxViUTgZSSs0TkpWEurVNPQ0MFtLLzq8ApFZVY7TgrWkvpbK/Dy0tasnBSspXzg6vvpWL2uT68d3CaeuebICkdkVl+cFKwl9GU+wcAB4s6/PcD9A9ZSnBSsqfVlTsHd7ii2FpZrUpB0OPA1oA24OSKmdHt+FPAdYOv0nMsiYlaeMVlz6+sM4zbB0n85KoeIzBpLbklBUhtwIzABaAfmSZoZEU8VnHYF8IOIuEnSbsAsYHReMVlz6s8M4/M9q9jsbfKsKewLLImIZQCSZgDHAIVJIYB3pI+3Al7MMR5rIv3pMAavQGpWSp5JYQfghYLjdqD7+L0vA/8l6SJgS+AjOcZjDc6rkJrlL8+koCJl3UeGnwzcGhHXSToA+K6k3SNiw9veSDoPOA9g1KhRuQRr9au/tQKPIjLLLs+k0A7sWHA8kk2bh84BDgeIiEckDQGGAy8VnhQR04BpAOPHj6/AijTWCPpTM3DzkFnf5JkU5gHjJI0BfgecBJzS7Zz/Aw4DbpW0KzAE6MgxJmsQoy+7r9ev8eJzZv2XW1KIiPWSJgGzSYabTo+IRZKuAuZHxEzgs8C3JH2GpGnpzIhwTaBFLVi+ghOmPtyr5SdcIzCrrFznKaRzDmZ1K7uy4PFTwEF5xmCN4eApD9C+ck2mc91ZbJYfz2i2murNZDM3D5nlz0nBaqK3M4+fn+LZxmbV4KRgVbfzF+9j/YaezwPXDsyqzUnBqqY3exi4ZmBWG04KlrvTb5nLQ8/+KdO5Hk1kVltOCpab3sxE9ogis/rgpGC5GHvZfWTsNnBTkVkdGVDrAKz5jM6YEMaN2NIJwazOuKZgFZN1mKn3MDCrX04KVhG7XvFT3uhhnKn7DczqX6akIGkwMCoiluQcjzWQ3kxAczORWWPoMSlIOgq4HhgMjJG0F/CliPhE3sFZferNfANwQjBrJFk6mq8i2TFtJUBEPA7snGdQVr9GX5Y9IRwybrgTglmDydJ89GZErJTetpGal7duMbtcPot1vageOBmYNaYsSWGxpBOAAemGORcDc/INy+pFb7fC9Ixks8aWJSlMAq4ENgD3kGya84U8g7L6kHX3szbB0n9xzcCsGWRJCh+LiM8Dn99YIOk4kgRhTSjr3sj//In3ccp+o6oQkZlVS5akcAWbJoDLi5RZg8uaDATcdcGB7LPTO/MPysyqqmRSkPQx4HBgB0nXFzz1Dsi8rI01iKxNRe4zMGtu5WoKLwELgTXAooLyVcBleQZl1dObUUUeUWTW/EomhYh4DHhM0u0RkW1HdWsYu1/5M1av68x0rpenMGsdWfoUdpB0DbAbMGRjYUTskltUlpsFy1fwyZseznTu0MFtLLzq8JwjMrN6kiUp3ApcDfwbcARwFu5TaEhZFq2DZJr7MjcVmbWkLMtcbBERswEiYmlEXAF8ON+wrJKmzFrM6Mvuy5QQDhk33AnBrIVlqSmsVbLGxVJJ5wO/A96Vb1hWKd7jwMx6I0tS+AwwFJgMXANsBZydZ1BWGVnmHbgT2cwK9ZgUImJu+nAVcBqApJF5BmX9lyUheIipmXVXtk9B0gckHStpeHr8Xkm34QXx6tqUWYvLJgTvjWxmpZSb0fwvwCeBJ4ArJP2IZIXUfwXOr0541ls9zUy+28tTmFkZ5ZqPjgH2jIg3JG0DvJgeP12d0Ky3nBDMrL/KNR+tiYg3ACLiFeC3Tgj1ywnBzCqhXE1hrKSNK6EKGF1wTEQc19ObSzoc+BrQBtwcEVOKnHMC8GWS3dyeiIhTsodvkExKK8cJwcyyKpcUPtnt+Ou9eWNJbcCNwASgHZgnaWZEPFVwzjiSDXsOiogVkjz/oZdOv2VuyUlpAwfAkn92h7KZZVduQbwH+vne+wJLImIZgKQZJP0UTxWccy5wY0SsSK/5Uj+v2XIeevZPRcudEMysL7Isc9FXOwAvFBy3p2WFdgF2kfRrSXPS5qZNSDpP0nxJ8zs6OnIKt/GU60dwQjCzvsgzKahIWfeF+wcC44BDgZOBmyVtvcmLIqZFxPiIGD9ixIiKB9qI9vrH2SWf8xwEM+urzElB0ma9fO92YMeC45Ekw1q7n/PjiHgzIp4DniZJElbG6MvuY+Ub64s+N27EllWOxsyaSY9JQdK+kn4DPJse7ynpPzK89zxgnKQxkgYDJwEzu51zL+mKq+ms6V2Anldva2E9DT31Vplm1h9Zago3AB8HXgaIiCfIsHR2RKwHJgGzgcXADyJikaSrJB2dnjYbeFnSU8CDwN9HxMu9v43W0FNCcLORmfVXllVSB0TE8mT17C6Z9nGMiFnArG5lVxY8DuCS9MfKGOuEYGZVkKWm8IKkfYGQ1Cbp74Bnco7LCpx+y9ySW91tvflAJwQzq5gsSeECkr/kRwF/BPZPy6xKSs1F2HzgAB7/0seqHI2ZNbMszUfrI+Kk3COxoso1Gy2++ogqRmJmrSBLTWGepFmSzpA0LPeIrMvBUx4o2WzkJiMzy0OPSSEi3gNcDewD/EbSvZJcc8jZsV//Fe0r1xR97pBxw6scjZm1ikyT1yLi4YiYDOwN/Bm4PdeoWtzBUx7g8fZXSz5/2zn7VTEaM2slWSavDZU0UdJ/Ao8CHcCBuUfWoqbMWlyyhgBuNjKzfGXpaF4I/CfwlYj4n5zjaXlTHyo9odsJwczyliUpjI2IUv2dVkHlZiw7IZhZNZRMCpKui4jPAndL6r66aaad1yy7ckNPnRDMrFrK1RTuTP/bqx3XrPfK1RAGtxVbgdzMLB/ldl57NH24a0S8LTFImgT0d2c2A97zhfJrGj1zzZFVisTMLNuQ1LOLlJ1T6UBaVecmDXNvcbORmVVbuT6FE0n2QBgj6Z6Cp4YBK/MOrBV84Or7i5Z7f2Uzq5VyfQqPkuyhMBK4saB8FfBYnkG1io7V64qWOyGYWa2U61N4DngO+Hn1wmkdpTqXzz9kbJUjMTN7S7nmo19GxIckrQAKW75Fsj/ONrlH16R2/mLpzuXLjty1ipGYmb1dueajjVtuevW1Cjr9lrmsLzEV0AvdmVmtlRx9VDCLeUegLSI6gQOAvwW2rEJsTanchjle6M7Mai3LkNR7SbbifA9wG7Ar8P1co2pSu1/5s6LlA/CGOWZWH7IkhQ0R8SZwHPDViLgI2CHfsJrT6nWdRcuXeT6CmdWJLElhvaS/AU4DfpKWDcovpNYyYujgWodgZtYl64zmD5Msnb1M0hjgjnzDaj6lJqrNu2JClSMxMyutx6WzI2KhpMnAzpL+ClgSEdfkH1pzKTZRbZstXOEys/rSY1KQ9EHgu8DvSOYobCfptIj4dd7BNYtSHcwnjN+xypGYmZWXZZOdfweOjIinACTtSpIkxucZWDMp1cHsiWpmVm+y9CkM3pgQACJiMeDe0YxOv2Vu0fK7L/A212ZWf7LUFP5X0jdJagcAE/GCeJmVmqy2z07vrHIkZmY9y5IUzgcmA58j6VN4CPiPPINqFguWryhaPm6EJ4SbWX0qmxQkvQ94D/CjiPhKdUJqHp+86eGi5fd/9tDqBmJmllHJPgVJXyRZ4mIicL+kYjuwlSXpcElPS1oi6bIy5x0vKSQ1Ted1qb4EL41tZvWsXE1hIrBHRLwmaQQwC5ie9Y0ltZFszjMBaAfmSZpZ2GmdnjeMpHmq+LdogyrVl+ARR2ZWz8qNPlobEa8BRERHD+cWsy/JRLdlEbEOmAEcU+S8fwK+Aqzp5fvXrQnX/aJouZe0MLN6V66mMLZgb2YB7yncqzkijuvhvXcAXig4bgfetja0pPcDO0bETyRdmj3s+vZsx2tFy72khZnVu3JJ4ZPdjr/ey/dWkbKuHdwkDSCZGHdmj28knQecBzBq1KhehlFdpWoJg9uKfRxmZvWl3B7ND/TzvdtJNujZaCTwYsHxMGB34BeSALYDZko6OiLmd4tlGjANYPz48YVbg9adUrWEZ645ssqRmJn1Xm/7CXpjHjBO0hhJg4GTgJkbn4yIVyNieESMjojRwBxgk4TQDDwvwcwaRW5JISLWA5OA2cBi4AcRsUjSVZKOzuu6tVRqGKrnJZhZo8gyoxkASZtFxNrevHlEzCIZylpYdmWJcw/tzXvXo2LDULcbtlkNIjEz65seawqS9pX0G+DZ9HhPSV7mopspsxYXLb/x1H2qHImZWd9laT66Afg48DJARDxBshObFfjWr54rWu6F78yskWRJCgMiYnm3suIbBLSwzg2bDopyB7OZNZosfQovSNoXiHTpiouAZ/INqzm4g9nMGk2WmsIFwCXAKOCPwP5pmaVKTVgzM2s0PdYUIuIlkjkGVkKpCWtmZo2mx6Qg6VsULE+xUUScl0tEDaZULcH9CWbWiLL0Kfy84PEQ4BO8faG7llaqluD+BDNrRFmaj+4sPJb0XeD+3CJqIB+4uvjHcMi44VWOxMysMvqyzMUYYKdKB9KIOlavK1p+2zn7FS03M6t3WfoUVvBWn8IA4BWg5NaarcLbbZpZMyqbFJSsab0n8Lu0aENE1PXS1dXi7TbNrBmVbT5KE8CPIqIz/XFCoPSII/clmFmjy9Kn8KikvXOPpIGUGnHkvgQza3Qlm48kDUz3RDgYOFfSUuA1km02IyJaMlHs/MX7ipaPGDq4ypGYmVVeuT6FR4G9gWOrFEvdmzJrMes3FH9u3hUTqhuMmVkOyiUFAUTE0irFUvemPrSsaLn7EsysWZRLCiMkXVLqyYi4Pod46lapIagDB7gvwcyaR7mk0AYMJa0xtLpSQ1CX/PNRVY7EzCw/5ZLC7yPiqqpF0oAGtzlfmllzKTck1d94qQXLVxQtf+aaI6sciZlZvsolhcOqFkWdm7Ps5VqHYGZWFSWTQkS8Us1A6tncIknBI47MrBn1ZZXUlvPrJZt2MnvEkZk1IyeFDDq94pOZtQgnhR5MmbW41iGYmVWNk0IPSs1iNjNrRk4KfTBuxJa1DsHMLBdOCmWUWtri/s8eWt1AzMyqxEmhjFJLW5iZNSsnhV7yvglm1sxyTQqSDpf0tKQlki4r8vwlkp6S9KSkByTtlGc8vVFqy03vm2BmzSy3pCCpDbgROALYDThZ0m7dTnsMGB8RewB3AV/JK57eKrbl5haDXLEys+aW57fcvsCSiFgWEeuAGcAxhSdExIMR8Xp6OAcYmWM8/Xb6AaNrHYKZWa7yTAo7AC8UHLenZaWcA/y02BOSzpM0X9L8jo6OCoZY3O5X/qxo+WVH7pr7tc3MainPpFBs6e2iC0ZIOhUYD1xb7PmImBYR4yNi/IgRIyoYYnGr13VuUuaWIzNrBeU22emvdmDHguORwIvdT5L0EeBy4EMRsTbHePrlnIPH1joEM7Pc5fn37zxgnKQxkgYDJwEzC0+Q9H7gm8DREfFSjrFk5qYjM2tluSWFiFgPTAJmA4uBH0TEIklXSTo6Pe1akn2gfyjpcUkzS7xd1RRrOhq2WVsNIjEzq748m4+IiFnArG5lVxY8/kie1++tUiui3nq2904ws9bg7tMC3/rVc0XL99npnVWOxMysNpwUCnRu2HRw1N0XHFiDSMzMasNJIbXL5bOKlruWYGatxEkhtc57bpqZOSkALFi+omj5+Yd4boKZtRYnBeCbv1xatNxzE8ys1TgpAH/885pNyrzlppm1IicF4Jk/rNqkzFtumlkrclIA3li/odYhmJnVhZZPCh+4+v5ah2BmVjdaPil0rF5X6xDMzOpGyyeFYtzJbGatqqWTQqllst3JbGatqqWTQrFlsrcbtlkNIjEzqw8tnRSKufHUfWodgplZzbRsUii1tIUXwDOzVtaySWHit+bUOgQzs7rTsklhTZEJayOGDq5BJGZm9aNlk0Ix866YUOsQzMxqqiWTwoTrflHrEMzM6lJLJoVnO17bpMxDUc3MWjQpFOOhqGZmLZgUPBTVzKy0lksKxYaiDmq5T8HMrLiW+zosNhT1nIO9F7OZGbRgUijGezGbmSVaKil4KKqZWXktlRSKDUVtqQ/AzKwHLf+deN4h7k8wM9uoZZJCqaYj9yeYmb0l16Qg6XBJT0taIumyIs9vJunO9Pm5kkbnFUuxpiMzM3u73JKCpDbgRuAIYDfgZEm7dTvtHGBFROwM/Dvwr3nFU8wh44ZX83JmZnUvz5rCvsCSiFgWEeuAGcAx3c45BvhO+vgu4DBJqnQgU2YtLlp+2zn7VfpSZmYNLc+ksAPwQsFxe1pW9JyIWA+8Cmxb6UC+O2d5pd/SzKwp5ZkUiv3FH304B0nnSZovaX5HR0evA3mz0xvqmJllkWdSaAd2LDgeCbxY6hxJA4GtgFe6v1FETIuI8RExfsSIEb0O5Mj3vfttx4Pb5A11zMyKyDMpzAPGSRojaTBwEjCz2zkzgTPSx8cD/x0Rm9QU+uurJ72fY/fanq23GMSxe23PM9ccWelLmJk1hYF5vXFErJc0CZgNtAHTI2KRpKuA+RExE7gF+K6kJSQ1hJPyiuerJ70/r7c2M2sauSUFgIiYBczqVnZlweM1wN/kGYOZmWXXMjOazcysZ04KZmbWxUnBzMy6OCmYmVkXJwUzM+uiHKYF5EpSB9DXdSuGA3+qYDiNwPfcGnzPraE/97xTRPQ4+7fhkkJ/SJofEeNrHUc1+Z5bg++5NVTjnt18ZGZmXZwUzMysS6slhWm1DqAGfM+twffcGnK/55bqUzAzs/JaraZgZmZlNGVSkHS4pKclLZF0WZHnN5N0Z/r8XEmjqx9lZWW450skPSXpSUkPSNqpFnFWUk/3XHDe8ZJCUsOPVMlyz5JOSH/XiyR9v9oxVlqGf9ujJD0o6bH033dDr40vabqklyQtLPG8JN2Qfh5PStq7ogFERFP9kCzTvRQYCwwGngB263bOp4Gp6eOTgDtrHXcV7vnDwBbp4wta4Z7T84YBDwFzgPG1jrsKv+dxwGPAO9Pjd9U67irc8zTggvTxbsDztY67n/d8CLA3sLDE80cCPyXZuXJ/YG4lr9+MNYV9gSURsSwi1gEzgGO6nXMM8J308V3AYZKKbQ3aKHq854h4MCJeTw/nkOyE18iy/J4B/gn4CrCmmsHlJMs9nwvcGBErACLipSrHWGlZ7jmAd6SPt2LTHR4bSkQ8RJEdKAscA9wWiTnA1pLeXeb8XmnGpLAD8ELBcXtaVvSciFgPvApsW5Xo8pHlngudQ/KXRiPr8Z4lvR/YMSJ+Us3AcpTl97wLsIukX0uaI+nwqkWXjyz3/GXgVEntJPu3XFSd0Gqmt/+/90qum+zUSLG/+LsPscpyTiPJfD+STgXGAx/KNaL8lb1nSQOAfwfOrFZAVZDl9zyQpAnpUJLa4P9I2j0iVuYcW16y3PPJwK0RcZ2kA0h2c9w9IjbkH15N5Pr91Yw1hXZgx4LjkWxanew6R9JAkipnuepavctyz0j6CHA5cHRErK1SbHnp6Z6HAbsDv5D0PEnb68wG72zO+m/7xxHxZkQ8BzxNkiQaVZZ7Pgf4AUBEPAIMIVkjqFll+v+9r5oxKcwDxkkaI2kwSUfyzG7nzATOSB8fD/x3pD04DarHe06bUr5JkhAavZ0ZerjniHg1IoZHxOiIGE3Sj3J0RMyvTbgVkeXf9r0kgwqQNJykOWlZVaOsrCz3/H/AYQCSdiVJCh1VjbK6ZgKnp6OQ9gdejYjfV+rNm675KCLWS5oEzCYZuTA9IhZJugqYHxEzgVtIqphLSGoIJ9Uu4v7LeM/XAkOBH6Z96v8XEUfXLOh+ynjPTSXjPc8GPirpKaAT+PuIeLl2UfdPxnv+LPAtSZ8haUY5s5H/yJN0B0nz3/C0n+RLwCCAiJhK0m9yJLAEeB04q6LXb+DPzszMKqwZm4/MzKyPnBTMzKyLk4KZmXVxUjAzsy5OCmZm1sVJweqOpE5Jjxf8jC5z7uhSq0n28pq/SFfifCJdIuIv+/Ae50s6PX18pqTtC567WdJuFY5znqS9Mrzm7yRt0d9rW2twUrB69EZE7FXw83yVrjsxIvYkWSzx2t6+OCKmRsRt6eGZwPYFz30qIp6qSJRvxfkNssX5d4CTgmXipGANIa0R/I+k/01/DixyznslPZrWLp6UNC4tP7Wg/JuS2nq43EPAzulgjjOaAAADFElEQVRrD0vX6f9Nus79Zmn5FL21P8W/pWVflnSppONJ1pe6Pb3m5ulf+OMlXSDpKwUxnynpP/oY5yMULIQm6SZJ85Xso/CPadlkkuT0oKQH07KPSnok/Rx/KGloD9exFuKkYPVo84Kmox+lZS8BEyJib+BE4IYirzsf+FpE7EXypdyeLntwInBQWt4JTOzh+n8N/EbSEOBW4MSIeB/JCgAXSNoG+ATw3ojYA7i68MURcRcwn+Qv+r0i4o2Cp+8Cjis4PhG4s49xHk6yrMVGl0fEeGAP4EOS9oiIG0jWxflwRHw4XfriCuAj6Wc5H7ikh+tYC2m6ZS6sKbyRfjEWGgR8PW1D7yRZ06e7R4DLJY0E7omIZyUdBuwDzEuX99icJMEUc7ukN4DnSZZf/kvguYh4Jn3+O8CFwNdJ9me4WdJ9QOaluSOiQ9KydM2aZ9Nr/Dp9397EuSXJsg+Fu26dIOk8kv+v302y4cyT3V67f1r+6/Q6g0k+NzPAScEax2eAPwJ7ktRwN9k0JyK+L2kucBQwW9KnSJYZ/k5EfCHDNSYWLpgnqegeG+l6PPuSLMJ2EjAJ+H+9uJc7gROA3wI/iohQ8g2dOU6SHcimADcCx0kaA1wKfCAiVki6lWRhuO4E3B8RJ/ciXmshbj6yRrEV8Pt0jfzTSP5KfhtJY4FlaZPJTJJmlAeA4yW9Kz1nG2Xfn/q3wGhJO6fHpwG/TNvgt4qIWSSduMVGAK0iWb67mHuAY0n2AbgzLetVnBHxJkkz0P5p09M7gNeAVyX9BXBEiVjmAAdtvCdJW0gqVuuyFuWkYI3iG8AZkuaQNB29VuScE4GFkh4H/opky8KnSL48/0vSk8D9JE0rPYqINSQrUP5Q0m+ADcBUki/Yn6Tv90uSWkx3twJTN3Y0d3vfFcBTwE4R8Wha1us4076K64BLI+IJkr2ZFwHTSZqkNpoG/FTSgxHRQTIy6o70OnNIPiszwKukmplZAdcUzMysi5OCmZl1cVIwM7MuTgpmZtbFScHMzLo4KZiZWRcnBTMz6+KkYGZmXf4/iO2EVSt8OmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','gluc','smoke','alco','active','cardio','bmi','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.58977667, 0.61006085, 0.50205167, 0.66789786, 0.62170815,\n",
       "        0.23470434, 0.16256507, 0.14594237, 0.1791877 , 0.16256571]),\n",
       " 'std_fit_time': array([0.14277105, 0.12323054, 0.06742446, 0.12424486, 0.14168672,\n",
       "        0.11365907, 0.02684776, 0.02407847, 0.02394067, 0.0355976 ]),\n",
       " 'mean_score_time': array([0.00361983, 0.00462731, 0.00363   , 0.00498184, 0.00395195,\n",
       "        0.00698217, 0.00365702, 0.00498676, 0.00465393, 0.00664822]),\n",
       " 'std_score_time': array([4.67968739e-04, 9.58724525e-04, 4.85599762e-04, 2.17114763e-03,\n",
       "        7.80211418e-06, 8.13322746e-04, 9.39425201e-04, 2.15405697e-03,\n",
       "        1.24273209e-03, 1.24328429e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77541749, 0.77528774, 0.77530839, 0.77534189, 0.77542691,\n",
       "        0.65145173, 0.61447231, 0.61447238, 0.61447238, 0.61447238]),\n",
       " 'split1_test_score': array([0.77700179, 0.77685783, 0.77690186, 0.77696873, 0.77695995,\n",
       "        0.61707295, 0.77693632, 0.61707366, 0.61707331, 0.61707331]),\n",
       " 'split2_test_score': array([0.77182184, 0.77169922, 0.77185484, 0.77164538, 0.77166388,\n",
       "        0.61772326, 0.61772341, 0.61772337, 0.61772333, 0.61772333]),\n",
       " 'mean_test_score': array([0.77474704, 0.77461493, 0.77468836, 0.774652  , 0.77468358,\n",
       "        0.62874931, 0.66971068, 0.61642314, 0.61642301, 0.61642301]),\n",
       " 'std_test_score': array([0.0021672 , 0.00215906, 0.00210656, 0.00222733, 0.00222508,\n",
       "        0.01605523, 0.07583159, 0.00140466, 0.0014046 , 0.0014046 ]),\n",
       " 'rank_test_score': array([1, 5, 2, 4, 3, 7, 6, 8, 9, 9])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.774747 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774747 (0.002167) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774615 (0.002159) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774688 (0.002107) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774652 (0.002227) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774684 (0.002225) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.628749 (0.016055) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.669711 (0.075832) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7829777782643877\n",
      "confusion matrix\n",
      " [[3402 1285]\n",
      " [1742 4182]]\n",
      "====Iteration 1  ====\n",
      "auc 0.77953422780246\n",
      "confusion matrix\n",
      " [[3366 1317]\n",
      " [1697 4231]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7747743403872166\n",
      "confusion matrix\n",
      " [[3349 1325]\n",
      " [1708 4229]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08809757, 0.13563728, 0.06482752, 0.16489116, 0.07480113,\n",
       "        0.14961012, 0.06216677, 0.15092953, 0.05485304, 0.17256172,\n",
       "        0.04654177, 0.16123454, 0.11635526, 0.03590242, 0.18483822,\n",
       "        0.13430683, 0.03324374, 0.20578257, 0.15159082, 0.04055818,\n",
       "        0.19380649, 0.15458751, 0.04986604, 0.21110177, 0.15325602]),\n",
       " 'std_fit_time': array([0.03218648, 0.01485994, 0.00924807, 0.03804149, 0.01216045,\n",
       "        0.04236068, 0.00470067, 0.01793922, 0.00293634, 0.02788303,\n",
       "        0.00835811, 0.01477766, 0.01192058, 0.00162811, 0.0333917 ,\n",
       "        0.01265079, 0.00046997, 0.00954353, 0.02492565, 0.00308274,\n",
       "        0.02732095, 0.04044341, 0.01447601, 0.01186529, 0.01681352]),\n",
       " 'mean_score_time': array([0.00565147, 0.0036575 , 0.00432118, 0.00365742, 0.00398898,\n",
       "        0.00364661, 0.0043215 , 0.00531912, 0.00365702, 0.00529559,\n",
       "        0.00365678, 0.0053196 , 0.00398978, 0.00532039, 0.00399025,\n",
       "        0.00531896, 0.00332483, 0.00631698, 0.00465369, 0.00548855,\n",
       "        0.00397881, 0.0043207 , 0.00631706, 0.0039893 , 0.0053192 ]),\n",
       " 'std_score_time': array([2.48763076e-03, 4.70471583e-04, 4.70471583e-04, 4.70077860e-04,\n",
       "        1.94667955e-07, 4.62491035e-04, 4.69909263e-04, 2.61769653e-03,\n",
       "        9.40436725e-04, 1.87182507e-03, 4.70471261e-04, 1.88143536e-03,\n",
       "        8.15074920e-04, 2.61832230e-03, 7.86741172e-07, 2.04895751e-03,\n",
       "        4.71314168e-04, 2.35100780e-03, 9.40211902e-04, 2.12054846e-03,\n",
       "        1.43874413e-05, 4.70808557e-04, 2.04940865e-03, 1.07214749e-06,\n",
       "        1.88070477e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.78195624, 0.78195818, 0.78194988, 0.78195117, 0.78194956,\n",
       "        0.78194776, 0.78194772, 0.78194837, 0.78194546, 0.78194718,\n",
       "        0.78193935, 0.78193928, 0.78194003, 0.78194582, 0.78194603,\n",
       "        0.781946  , 0.78194744, 0.78194787, 0.7819474 , 0.78194751,\n",
       "        0.78194754, 0.78194643, 0.7819474 , 0.78194794, 0.78194797]),\n",
       " 'split1_test_score': array([0.77785879, 0.77786002, 0.77785547, 0.77785568, 0.77785547,\n",
       "        0.77785568, 0.77785532, 0.77785659, 0.77785493, 0.77785576,\n",
       "        0.7778524 , 0.77785319, 0.77785258, 0.77785493, 0.77785467,\n",
       "        0.77785485, 0.77785558, 0.77785597, 0.77785576, 0.77785576,\n",
       "        0.77785518, 0.77785532, 0.77785597, 0.77785478, 0.77785359]),\n",
       " 'split2_test_score': array([0.78418725, 0.78418923, 0.78417137, 0.78417022, 0.78416942,\n",
       "        0.78416863, 0.78416935, 0.78416989, 0.7841673 , 0.78416896,\n",
       "        0.78415934, 0.7841592 , 0.78415938, 0.78416748, 0.78416654,\n",
       "        0.78416798, 0.78416942, 0.78417195, 0.78416842, 0.78416964,\n",
       "        0.78416838, 0.78416849, 0.78416964, 0.78416795, 0.78416795]),\n",
       " 'mean_test_score': array([0.78133409, 0.78133581, 0.78132557, 0.78132569, 0.78132482,\n",
       "        0.78132403, 0.78132413, 0.78132495, 0.78132256, 0.78132397,\n",
       "        0.78131703, 0.78131722, 0.78131733, 0.78132274, 0.78132242,\n",
       "        0.78132295, 0.78132415, 0.78132526, 0.78132386, 0.7813243 ,\n",
       "        0.7813237 , 0.78132341, 0.78132434, 0.78132356, 0.78132317]),\n",
       " 'std_test_score': array([0.00262077, 0.0026211 , 0.00261597, 0.00261556, 0.00261524,\n",
       "        0.00261472, 0.00261513, 0.00261482, 0.00261439, 0.00261476,\n",
       "        0.00261213, 0.00261172, 0.00261212, 0.00261448, 0.00261427,\n",
       "        0.00261471, 0.00261503, 0.0026158 , 0.00261458, 0.00261503,\n",
       "        0.00261483, 0.00261472, 0.00261493, 0.00261488, 0.00261541]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3,  7, 12, 11,  6, 21, 13, 25, 24, 23, 20, 22, 19, 10,\n",
       "         5, 14,  9, 15, 17,  8, 16, 18])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.781336 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781334 (0.002621) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781336 (0.002621) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781326 (0.002616) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781326 (0.002616) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781325 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781325 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781323 (0.002614) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781323 (0.002614) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781322 (0.002614) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781325 (0.002616) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774929622251729\n",
      "[0.71124305 0.71209123 0.70907549]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7753158137417063\n",
      "confusion matrix\n",
      " [[3353 1340]\n",
      " [1733 4185]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7755508656370104\n",
      "confusion matrix\n",
      " [[3434 1287]\n",
      " [1762 4128]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7724583962001766\n",
      "confusion matrix\n",
      " [[3362 1318]\n",
      " [1747 4184]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30249373, 0.09140337, 0.8996206 , 0.12844921, 0.28637318]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.772\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','ap_hi','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.28792159, 0.3982842 , 0.34011745, 0.27063163, 0.29957183,\n",
       "        0.02470827, 0.02825872, 0.02491188, 0.03523866, 0.03025254]),\n",
       " 'std_fit_time': array([0.02944319, 0.03942984, 0.08878178, 0.03130499, 0.03117728,\n",
       "        0.00250116, 0.00248755, 0.00162936, 0.00971533, 0.00692428]),\n",
       " 'mean_score_time': array([0.0029579 , 0.00430473, 0.00362992, 0.00496467, 0.00361713,\n",
       "        0.0032169 , 0.0046525 , 0.00332411, 0.00432165, 0.00299136]),\n",
       " 'std_score_time': array([3.22428747e-06, 4.81892504e-04, 4.74639717e-04, 8.28353901e-04,\n",
       "        9.35435760e-04, 5.61182179e-04, 2.35229991e-03, 4.68617012e-04,\n",
       "        1.88070479e-03, 1.32507737e-06]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.74937626, 0.74934896, 0.74934534, 0.74936344, 0.74936742,\n",
       "        0.61387189, 0.61387189, 0.61387189, 0.61387189, 0.61387189]),\n",
       " 'split1_test_score': array([0.73950087, 0.73943044, 0.73943141, 0.73949925, 0.73944709,\n",
       "        0.60895519, 0.60895519, 0.60895519, 0.60895519, 0.60895519]),\n",
       " 'split2_test_score': array([0.74173435, 0.741696  , 0.74172531, 0.74171948, 0.74172024,\n",
       "        0.6147249 , 0.6147249 , 0.6147249 , 0.6147249 , 0.6147249 ]),\n",
       " 'mean_test_score': array([0.74353716, 0.7434918 , 0.74350069, 0.74352739, 0.74351158,\n",
       "        0.61251733, 0.61251733, 0.61251733, 0.61251733, 0.61251733]),\n",
       " 'std_test_score': array([0.00422835, 0.00424366, 0.00423757, 0.00422508, 0.00424342,\n",
       "        0.00254277, 0.00254277, 0.00254277, 0.00254277, 0.00254277]),\n",
       " 'rank_test_score': array([1, 5, 4, 2, 3, 6, 6, 6, 6, 6])}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "LogisticRegression()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.6545841722217853\n",
      "confusion matrix\n",
      " [[ 321 4334]\n",
      " [ 157 5799]]\n",
      "====Iteration 1  ====\n",
      "auc 0.6576116009160325\n",
      "confusion matrix\n",
      " [[ 256 4415]\n",
      " [ 154 5786]]\n",
      "====Iteration 2  ====\n",
      "auc 0.6506144107276153\n",
      "confusion matrix\n",
      " [[ 403 4267]\n",
      " [ 275 5666]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03557197, 0.08942699, 0.04489152, 0.10970656, 0.04089117,\n",
       "        0.0997328 , 0.02991954, 0.0930829 , 0.04255311, 0.11668921,\n",
       "        0.02760235, 0.11135689, 0.10040871, 0.03058624, 0.13398631,\n",
       "        0.07944194, 0.02359223, 0.12234012, 0.1090529 , 0.03292378,\n",
       "        0.17496681, 0.10039862, 0.03058441, 0.15358957, 0.078789  ]),\n",
       " 'std_fit_time': array([0.00308246, 0.00448607, 0.00775783, 0.0171591 , 0.01272123,\n",
       "        0.00906804, 0.00081459, 0.01164095, 0.00339056, 0.00614811,\n",
       "        0.00515952, 0.01110522, 0.01970331, 0.00417954, 0.02376628,\n",
       "        0.01262173, 0.0012312 , 0.01301187, 0.01477985, 0.00734337,\n",
       "        0.02226991, 0.01186713, 0.00542353, 0.00564352, 0.0048851 ]),\n",
       " 'mean_score_time': array([0.00432221, 0.00398938, 0.00563947, 0.00531912, 0.00365655,\n",
       "        0.00565219, 0.00365734, 0.00398993, 0.00433334, 0.00564988,\n",
       "        0.0056502 , 0.00299287, 0.00431061, 0.00598327, 0.00432189,\n",
       "        0.00465322, 0.00400066, 0.00365686, 0.00564019, 0.00497564,\n",
       "        0.00397452, 0.00398874, 0.00565203, 0.00565108, 0.00531888]),\n",
       " 'std_score_time': array([4.70246599e-04, 2.97360213e-07, 2.33381149e-03, 3.29133173e-03,\n",
       "        4.70134207e-04, 1.87974945e-03, 4.70527668e-04, 1.03008599e-06,\n",
       "        4.85475509e-04, 1.87997427e-03, 2.32778454e-03, 1.52040533e-06,\n",
       "        1.24607396e-03, 2.15457205e-03, 4.70979246e-04, 1.69389232e-03,\n",
       "        1.58472150e-05, 4.70023630e-04, 2.33465443e-03, 1.65849024e-05,\n",
       "        8.21387273e-04, 1.01152436e-06, 2.35038935e-03, 1.69423526e-03,\n",
       "        1.88076098e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.74323294, 0.74323341, 0.74323193, 0.74323294, 0.74323215,\n",
       "        0.74323279, 0.7432324 , 0.74323243, 0.74323229, 0.74323247,\n",
       "        0.74323121, 0.74323142, 0.7432311 , 0.74323114, 0.74323182,\n",
       "        0.74323153, 0.74323233, 0.74323157, 0.74323186, 0.74323233,\n",
       "        0.74323272, 0.74323222, 0.74323233, 0.74323153, 0.74323269]),\n",
       " 'split1_test_score': array([0.74452091, 0.74451986, 0.74452026, 0.74452047, 0.74451989,\n",
       "        0.74452026, 0.74451997, 0.74451986, 0.74451989, 0.74452004,\n",
       "        0.74452033, 0.74452054, 0.7445204 , 0.74451971, 0.74452015,\n",
       "        0.74451961, 0.74451971, 0.74451986, 0.74452036, 0.74451982,\n",
       "        0.74452022, 0.74451986, 0.74451993, 0.74451982, 0.74451946]),\n",
       " 'split2_test_score': array([0.74398301, 0.74398347, 0.74398066, 0.74398102, 0.74397983,\n",
       "        0.74398037, 0.74398023, 0.74398001, 0.74398041, 0.74397976,\n",
       "        0.74398048, 0.74398001, 0.74398005, 0.74398045, 0.74398023,\n",
       "        0.74398091, 0.74398034, 0.74397969, 0.74398037, 0.74398037,\n",
       "        0.74398041, 0.74398052, 0.74398037, 0.74398019, 0.74398034]),\n",
       " 'mean_test_score': array([0.74391228, 0.74391225, 0.74391095, 0.74391148, 0.74391062,\n",
       "        0.74391114, 0.74391086, 0.74391077, 0.74391086, 0.74391076,\n",
       "        0.74391067, 0.74391066, 0.74391052, 0.74391043, 0.74391073,\n",
       "        0.74391068, 0.74391079, 0.74391037, 0.74391086, 0.74391084,\n",
       "        0.74391112, 0.74391086, 0.74391088, 0.74391052, 0.74391083]),\n",
       " 'std_test_score': array([0.00052818, 0.0005276 , 0.00052826, 0.00052793, 0.00052799,\n",
       "        0.00052788, 0.00052793, 0.00052786, 0.00052796, 0.00052791,\n",
       "        0.00052859, 0.00052856, 0.00052865, 0.00052838, 0.00052825,\n",
       "        0.00052819, 0.00052787, 0.00052822, 0.00052832, 0.00052791,\n",
       "        0.0005279 , 0.00052798, 0.00052795, 0.00052824, 0.00052762]),\n",
       " 'rank_test_score': array([ 1,  2,  6,  3, 21,  4,  9, 15, 10, 16, 19, 20, 22, 24, 17, 18, 14,\n",
       "        25,  8, 12,  5, 11,  7, 23, 13])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.743912 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743912 (0.000528) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743912 (0.000528) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743910 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743910 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333350033357999\n",
      "[0.69983979 0.70483461 0.70210159]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7449583077169937\n",
      "confusion matrix\n",
      " [[3178 1483]\n",
      " [1636 4314]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7403036835573813\n",
      "confusion matrix\n",
      " [[3123 1522]\n",
      " [1641 4325]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7442072616685852\n",
      "confusion matrix\n",
      " [[3157 1549]\n",
      " [1602 4303]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34692142, 0.18307629, 0.79513794]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.744\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
