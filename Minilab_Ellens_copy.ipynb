{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Machine Learning I / Mini Lab Predictive Analysis</b>\n",
    "<br><b>Authors:</b> Fabio Savorgnon, Tina Pai, Paritosh Rai, Ellen Lull\n",
    "<br><b>Data set from:</b> https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our initial Exploratory Data Analysis (EDA) project, we needed to pick a model that would predict if a patient would have cardiovascular disease based on the variables available in our data.  These are:  gender, systolic blood pressure, diastolic blood pressure, age, height and weight (which we used to calculate Body Mass Index or BMI), a cholesterol level indicator, a glucose level indicator, and indicators to identify if a patient used alcohol, smoked or was active.    You can view the full descriptions of these data elements in our EDA document.\n",
    "<br>  \n",
    "\n",
    "During our EDA, we determined that the factors that had the highest level of correlation to cardiovascular disease were:   Blood pressure, BMI, Age, Cholesterol and Glucose.     However, we didn’t want to limit ourselves to only these.   So, we ran five combinations of these variables.  For each combination of variables, we ran both SVM and Logistical Regression models.  For each combination and method, we ran with scaled data and non-scaled data.   Our findings are documented below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "dfin = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "dfin = dfin[dfin[\"weight\"] < 200]\n",
    "dfin = dfin[dfin[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "dfin = dfin[dfin[\"height\"] < 200]\n",
    "dfin = dfin[dfin[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "dfin = dfin[dfin[\"ap_hi\"] > 110]\n",
    "dfin = dfin[dfin[\"ap_lo\"] < 150]\n",
    "dfin = dfin[dfin[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "dfin['bmi'] = dfin['weight'] / (dfin['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "dfin['bp'] = np.where((dfin.ap_hi < 120) & (dfin.ap_lo < 80), 1, 0)\n",
    "dfin['bp'] = np.where((dfin.ap_hi >= 120) & (dfin.ap_hi < 130) & (dfin.ap_lo < 80), 2, dfin.bp)\n",
    "dfin['bp'] = np.where((dfin.ap_hi >= 130) & (dfin.ap_hi < 140) | ((dfin.ap_lo >= 80) & (dfin.ap_lo < 90)), 3, dfin.bp)\n",
    "dfin['bp'] = np.where((dfin.ap_hi >= 140) | (dfin.ap_lo >= 90), 4, dfin.bp)\n",
    "dfin['bp'] = np.where((dfin.ap_hi > 180) | (dfin.ap_lo > 120), 5, dfin.bp)\n",
    "dfin['bp'] = pd.cut(dfin.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a backup of the dataframe to use later in other models when we need a clean copy\n",
    "df = dfin.copy(deep=True)\n",
    "#df=dfin.copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elevated</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage1</th>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage2</th>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage3</th>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp                 \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    305"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df.groupby(by='bp')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cardio' in df:\n",
    "    y = df['cardio'].values\n",
    "    del df['cardio']\n",
    "    X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active        bmi            bp  \n",
       "1     0       1  34.927679  Hyper_Stage2  \n",
       "2     0       0  23.507805  Hyper_Stage1  \n",
       "3     0       1  28.710479  Hyper_Stage2  \n",
       "5     0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Variable Selection Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 'ap_hi' (highest co-relation)\n",
    "2. 'bmi', 'ap_hi', 'ap_lo','cholesterol','age'\n",
    "3. 'bmi', 'age', ‘bp’, 'cholesterol'\n",
    "4. ‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol'\n",
    "5. 'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active', 'weight' (all variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some more explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Baseline model (ap_hi only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73484996 0.73373353 0.73051278]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73793992 0.73409683 0.73757284]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM using BMI, age, ap_hi, ap_lo, cholesterol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64321623 0.6993939  0.47588858]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76639356 0.77038063 0.76869966]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('classifier',\n",
       "                                        SGDClassifier(alpha=0.0001,\n",
       "                                                      average=False,\n",
       "                                                      class_weight=None,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=0.1, eta0=0.0,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      l1_ratio=0.15,\n",
       "                                                      learning_rate='optimal',\n",
       "                                                      loss='hinge',\n",
       "                                                      max_it...\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'classifier__alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1],\n",
       "                          'classifier__loss': ['modified_huber'],\n",
       "                          'classifier__penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__loss': ['modified_huber'],\n",
    "   'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "   'classifier__alpha': [.001, .01, .05, .1, .5, 1]}\n",
    " ]\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SGDClassifier())])\n",
    "\n",
    "clf = GridSearchCV(svm, param_grid, scoring=\"roc_auc\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.001,\n",
       " 'classifier__loss': 'modified_huber',\n",
       " 'classifier__penalty': 'l1'}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best auc: 0.758408 using {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.758408 (0.008192) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.757774 (0.007686) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.753385 (0.013354) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.745677 (0.015692) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.748100 (0.007681) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.746677 (0.009164) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.732505 (0.001613) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.738571 (0.003593) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.736433 (0.003679) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.732319 (0.001547) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.736023 (0.001455) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.734047 (0.001928) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.607579 (0.076082) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.732955 (0.001279) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.732512 (0.001830) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.500000 (0.000000) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.732200 (0.001476) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.732948 (0.001878) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best auc: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74936434 0.76637654 0.75203515]\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model = clf.best_estimator_ #this was alpha=.1, loss='modified_huber', penalty='elasticnet'\n",
    "calibrator = CalibratedClassifierCV(model, cv=3)\n",
    "\n",
    "aucs = cross_val_score(calibrator, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model ROC AUC=0.761\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "scl_obj = std_scl.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "svm_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "svm_probs = svm_probs[:, 1]\n",
    "# calculate scores\n",
    "svm_auc = roc_auc_score(y_test, svm_probs)\n",
    "# summarize scores\\\n",
    "print('SVM Model ROC AUC=%.3f' % (svm_auc))\n",
    "# calculate roc curves\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(svm_fpr, svm_tpr, marker='.', label='SVM')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find probability threshold for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59493307, 0.68979928, 0.31774004, ..., 0.76764536, 0.73853907,\n",
       "       0.32758137])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.000000 : accuracy=0.560\n",
      "alpha 0.100000 : accuracy=0.561\n",
      "alpha 0.200000 : accuracy=0.569\n",
      "alpha 0.300000 : accuracy=0.616\n",
      "alpha 0.400000 : accuracy=0.687\n",
      "alpha 0.500000 : accuracy=0.704\n",
      "alpha 0.600000 : accuracy=0.667\n",
      "alpha 0.700000 : accuracy=0.603\n",
      "alpha 0.800000 : accuracy=0.543\n",
      "alpha 0.900000 : accuracy=0.499\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, .1)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune a little finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.400000 : accuracy=0.687\n",
      "alpha 0.410000 : accuracy=0.692\n",
      "alpha 0.420000 : accuracy=0.696\n",
      "alpha 0.430000 : accuracy=0.701\n",
      "alpha 0.440000 : accuracy=0.705\n",
      "alpha 0.450000 : accuracy=0.706\n",
      "alpha 0.460000 : accuracy=0.709\n",
      "alpha 0.470000 : accuracy=0.709\n",
      "alpha 0.480000 : accuracy=0.707\n",
      "alpha 0.490000 : accuracy=0.707\n",
      "alpha 0.500000 : accuracy=0.704\n",
      "alpha 0.510000 : accuracy=0.701\n",
      "alpha 0.520000 : accuracy=0.698\n",
      "alpha 0.530000 : accuracy=0.694\n",
      "alpha 0.540000 : accuracy=0.692\n",
      "alpha 0.550000 : accuracy=0.688\n",
      "alpha 0.560000 : accuracy=0.686\n",
      "alpha 0.570000 : accuracy=0.681\n",
      "alpha 0.580000 : accuracy=0.678\n",
      "alpha 0.590000 : accuracy=0.671\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(.4, .6, .01)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are multiple parameters that can help build a Logistic  Regression model listed below with the default value.  \n",
    "\n",
    "\n",
    "*(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None])*\n",
    "\n",
    "\n",
    "\n",
    "However, our team decided to focus on few critical in tuning process like C, solver and penalty. \n",
    "\n",
    "\n",
    "\n",
    "Hyperparameters sets the algorithm that can be adjusted to optimize performance, these are the knobs to generate optimal outcome. These Hyperparameters in machine learning model help define your model architecture. Leveraging grid search optimal automated exploration is launched to find the optimal parameter value to extract best model architecture. \n",
    "\n",
    "The project Grid search approach was used to tune the parameters of the model. Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid. However, grid search suffers from the curse of dimensionality: the number of times required to evaluate the model during hyperparameter optimization grows exponentially in the number of parameters. \n",
    "\n",
    "The other popular method is Random Search. It is performed by evaluating n uniformly random points in the hyperparameter space and select the one producing the best performance. The drawback of random search is unnecessarily high variance. The method is, after all, entirely random, and uses no intelligence in selecting which points to try. You are relying on luck to get good results.\n",
    "\n",
    "In the model building excises Grid Search was used and to overcome the curse of dimensionality hyper parameter list was highly evaluated and one making maxim impact were chosen. The model tuning process three parameters were considered, C, penalty and Solver. \n",
    "\n",
    "<b>C:</b> This control the complexity and simplicity of model. However, complexity can lead to over fitting vs. simplicity will lead to under fitting. Small values of C, we increase the regularization strength which will create simple models which underfit the data. For big values of C the power of regularization is decrease which impels the model is allowed to increase it's complexity, and therefore, overfit the data. \n",
    "\n",
    "<b>Penalty:</b> This project uses two penalties. Li and L2. The Penalty is used to specify the penalization method of the coefficients of noncontributing or less contributing variables.\n",
    "Lasso (L1) performs feature selection by shrinking the less important feature’s coefficient to zero.\n",
    "Ridge (L2) all variables are included in the model, though some are shrunk (but not to zero like L1 Penalty. Less computationally intensive than lasso.\n",
    "Both penalty values restrict solver choices. It is critical to choose the right combination of Penalty.\n",
    "\n",
    "\n",
    "\n",
    "<b>Solver:</b> Are the algorithm used in Logistic Regression to predict the outcome. Default value is lbfgs. other possible values (to list few) are, liblinear, sag and saga.\n",
    "liblinear − It is a good choice for small datasets. It also handles L1 penalty. For multiclass problems, it is limited to one-versus-rest schemes.\n",
    "lbfgs − For multiclass problems, it handles multinomial loss. It also handles only L2 penalty.\n",
    "saga − It is a good choice for large datasets. For multiclass problems, it also handles multinomial loss. Along with L1 penalty, it also supports ‘elasticnet’ penalty.\n",
    "sag − It is also used for large datasets. For multiclass problems, it also handles multinomial loss.\n",
    "\n",
    "\n",
    "\n",
    "<b>Ref:</b> \n",
    "https://sigopt.com/blog/common-problems-in-hyperparameter-optimization\n",
    "\n",
    "https://towardsdatascience.com/hyper-parameter-tuning-and-model-selection-like-a-movie-star-a884b8ee8d\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "df1 = dfin\n",
    "#df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    " \n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Logistical Regression Options:\n",
    "\n",
    "Description of Variable Combinations for Logistical Regresson models: \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest correlation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dfin\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cardio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cardio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-276-eefea51464b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# option 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cardio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# get the labels we want\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gender'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gluc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'smoke'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'alco'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'active'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cardio'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# get rid of the class label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#df.head(5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cardio'"
     ]
    }
   ],
   "source": [
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','gluc','smoke','alco','active','cardio','bp'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21914</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22113</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  ap_hi  ap_lo  cholesterol        bmi\n",
       "1  20228    140     90            3  34.927679\n",
       "2  18857    130     70            3  23.507805\n",
       "3  17623    150    100            1  28.710479\n",
       "5  21914    120     80            2  29.384676\n",
       "6  22113    130     80            3  37.729725"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21914</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22113</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  ap_hi  ap_lo  cholesterol        bmi\n",
       "1  20228    140     90            3  34.927679\n",
       "2  18857    130     70            3  23.507805\n",
       "3  17623    150    100            1  28.710479\n",
       "5  21914    120     80            2  29.384676\n",
       "6  22113    130     80            3  37.729725"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.59906395, 0.70145639, 0.56948709, 0.75632087, 0.62601296,\n",
       "        0.14195355, 0.14261858, 0.13829684, 0.14328361, 0.14494514]),\n",
       " 'std_fit_time': array([0.18142376, 0.21545753, 0.10649503, 0.09266549, 0.14858796,\n",
       "        0.03170964, 0.03467279, 0.04069419, 0.0343289 , 0.03341985]),\n",
       " 'mean_score_time': array([0.00332443, 0.0036571 , 0.00331378, 0.0033141 , 0.0036358 ,\n",
       "        0.00398938, 0.00332427, 0.0039893 , 0.00299152, 0.00365734]),\n",
       " 'std_score_time': array([4.70077860e-04, 4.70358829e-04, 4.78115316e-04, 4.77860875e-04,\n",
       "        4.78027064e-04, 1.12391596e-07, 4.70190252e-04, 1.12391596e-07,\n",
       "        2.24783192e-07, 4.70527668e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.76853058, 0.76941597, 0.76936327, 0.76753385, 0.76794792,\n",
       "        0.62719517, 0.62711002, 0.62709142, 0.62709063, 0.62709278]),\n",
       " 'split1_test_score': array([0.77365165, 0.77312724, 0.77322311, 0.77314663, 0.77312949,\n",
       "        0.64526509, 0.64523392, 0.64522617, 0.64522574, 0.64522706]),\n",
       " 'split2_test_score': array([0.76348656, 0.76347035, 0.7638585 , 0.76346163, 0.76488838,\n",
       "        0.63478382, 0.6347831 , 0.63478324, 0.63478328, 0.63478328]),\n",
       " 'mean_test_score': array([0.76855626, 0.76867119, 0.76881496, 0.76804737, 0.76865527,\n",
       "        0.63574802, 0.63570901, 0.63570028, 0.63569988, 0.63570104]),\n",
       " 'std_test_score': array([0.00414992, 0.00397743, 0.0038427 , 0.00397052, 0.00340139,\n",
       "        0.00740845, 0.00742796, 0.00743182, 0.00743194, 0.00743168]),\n",
       " 'rank_test_score': array([ 4,  2,  1,  5,  3,  6,  7,  9, 10,  8])}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a grid search for logistic regression\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.768815 using {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768556 (0.004150) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768671 (0.003977) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768815 (0.003843) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768047 (0.003971) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768655 (0.003401) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.635748 (0.007408) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.635709 (0.007428) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.635700 (0.007432) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.635700 (0.007432) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.635701 (0.007432) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=1000, class_weight=None, solver='liblinear' ) # get object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7629193833918267\n",
      "confusion matrix\n",
      " [[3111 1550]\n",
      " [1581 4403]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7560733341937407\n",
      "confusion matrix\n",
      " [[3164 1535]\n",
      " [1584 4362]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7638123978593047\n",
      "confusion matrix\n",
      " [[3082 1660]\n",
      " [1430 4473]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi            bp  \n",
       "1     0       1       1  34.927679  Hyper_Stage2  \n",
       "2     0       0       1  23.507805  Hyper_Stage1  \n",
       "3     0       1       1  28.710479  Hyper_Stage2  \n",
       "5     0       0       0  29.384676  Hyper_Stage1  \n",
       "6     0       1       0  37.729725  Hyper_Stage1  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.09507465, 1.04771495, 0.1003983 , 0.86069775, 0.06682094,\n",
       "        0.83876864, 0.06615575, 0.85372996, 0.06150349, 0.86403624,\n",
       "        0.04587889, 0.79057765, 0.82132093, 0.06017232, 0.72605729,\n",
       "        0.73571245, 0.05718064, 0.69549441, 0.71278683, 0.04820498,\n",
       "        0.66089948, 0.72472835, 0.06150262, 0.70496281, 0.68151085]),\n",
       " 'std_fit_time': array([0.01074711, 0.06242498, 0.01821477, 0.05924451, 0.00354981,\n",
       "        0.05495627, 0.00463013, 0.08746861, 0.00756679, 0.05621345,\n",
       "        0.00215523, 0.0197143 , 0.03769932, 0.00261764, 0.02850095,\n",
       "        0.00755299, 0.00950815, 0.06374556, 0.01016355, 0.00497352,\n",
       "        0.03206422, 0.05017228, 0.00384877, 0.02075222, 0.00188065]),\n",
       " 'mean_score_time': array([0.00664926, 0.00498637, 0.00631642, 0.00398898, 0.00432189,\n",
       "        0.00397746, 0.00432245, 0.00397642, 0.00433143, 0.00364383,\n",
       "        0.0039885 , 0.0046277 , 0.00465345, 0.00531912, 0.0039893 ,\n",
       "        0.00397619, 0.00432165, 0.00363533, 0.00396395, 0.00432158,\n",
       "        0.00432158, 0.00398978, 0.00598335, 0.00432054, 0.00465496]),\n",
       " 'std_score_time': array([4.70358991e-04, 8.14393390e-04, 4.70021695e-04, 5.15042996e-07,\n",
       "        4.69965469e-04, 1.73094005e-05, 4.70920787e-04, 1.67870309e-05,\n",
       "        4.62739787e-04, 4.61030656e-04, 1.03008599e-06, 4.51310815e-04,\n",
       "        4.69853561e-04, 4.70190252e-04, 7.37000982e-07, 1.80950470e-05,\n",
       "        4.70471221e-04, 4.75370629e-04, 1.84719272e-05, 4.70358870e-04,\n",
       "        4.71539433e-04, 8.15172155e-04, 8.14101456e-04, 4.68729161e-04,\n",
       "        1.24479259e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.7738171 , 0.76435976, 0.77449369, 0.76485127, 0.77456193,\n",
       "        0.76495363, 0.77456703, 0.76494146, 0.77456807, 0.76507682,\n",
       "        0.77016674, 0.76823013, 0.76315624, 0.77410874, 0.77101925,\n",
       "        0.76490805, 0.77452371, 0.77132048, 0.76503574, 0.77456556,\n",
       "        0.77135   , 0.76513903, 0.77456979, 0.77132504, 0.76506619]),\n",
       " 'split1_test_score': array([0.75851676, 0.74870111, 0.7600407 , 0.74940755, 0.76018143,\n",
       "        0.74951896, 0.76020438, 0.74958446, 0.76014542, 0.74951696,\n",
       "        0.75425789, 0.75203655, 0.7480415 , 0.75945728, 0.75496591,\n",
       "        0.74944163, 0.76013452, 0.75540077, 0.74969819, 0.76020184,\n",
       "        0.75531675, 0.74949851, 0.76020846, 0.75528472, 0.74950795]),\n",
       " 'split2_test_score': array([0.75620052, 0.74662516, 0.75786101, 0.74758798, 0.75801473,\n",
       "        0.74748312, 0.7580428 , 0.74744051, 0.75802741, 0.74762195,\n",
       "        0.75178392, 0.74974981, 0.74581377, 0.75724902, 0.75282211,\n",
       "        0.74749305, 0.75796183, 0.75328419, 0.74746612, 0.75803798,\n",
       "        0.75328019, 0.74748276, 0.75804566, 0.7533603 , 0.74751476]),\n",
       " 'mean_test_score': array([0.76284479, 0.75322867, 0.7641318 , 0.75394894, 0.76425269,\n",
       "        0.75398524, 0.7642714 , 0.75398881, 0.76424697, 0.75407191,\n",
       "        0.75873618, 0.75667217, 0.75233717, 0.76360501, 0.75960242,\n",
       "        0.75394758, 0.76420669, 0.76000182, 0.75406668, 0.76426846,\n",
       "        0.75998232, 0.7540401 , 0.76427464, 0.75999002, 0.75402964]),\n",
       " 'std_test_score': array([0.007816  , 0.00791636, 0.0073808 , 0.00774482, 0.0073432 ,\n",
       "        0.00780023, 0.0073334 , 0.00779399, 0.00734917, 0.00782001,\n",
       "        0.00814548, 0.00822586, 0.0077041 , 0.00748177, 0.00812022,\n",
       "        0.00779095, 0.00734896, 0.00805002, 0.00780964, 0.00733454,\n",
       "        0.00808105, 0.00789116, 0.00733313, 0.00805348, 0.00784633]),\n",
       " 'rank_test_score': array([ 9, 24,  7, 22,  4, 21,  2, 20,  5, 16, 14, 15, 25,  8, 13, 23,  6,\n",
       "        10, 17,  3, 12, 18,  1, 11, 19])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.764275 using {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.762845 (0.007816) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.753229 (0.007916) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.764132 (0.007381) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.753949 (0.007745) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.764253 (0.007343) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.753985 (0.007800) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.764271 (0.007333) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.753989 (0.007794) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.764247 (0.007349) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.754072 (0.007820) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.758736 (0.008145) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.756672 (0.008226) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.752337 (0.007704) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.763605 (0.007482) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.759602 (0.008120) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.753948 (0.007791) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.764207 (0.007349) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.760002 (0.008050) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.754067 (0.007810) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.764268 (0.007335) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.759982 (0.008081) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.754040 (0.007891) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.764275 (0.007333) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.759990 (0.008053) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.754030 (0.007846) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7523105462200697\n",
      "[0.70023485 0.69384688 0.69694692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7444468680686455\n",
      "confusion matrix\n",
      " [[3091 1621]\n",
      " [1633 4300]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "auc 0.7473724736212846\n",
      "confusion matrix\n",
      " [[3076 1582]\n",
      " [1661 4326]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7510826707593753\n",
      "confusion matrix\n",
      " [[3131 1515]\n",
      " [1665 4334]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "#df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3\n",
    "Following are combo I selected based on high correlation and removing\n",
    "\n",
    "'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "'ap_hi' (highest co-relation)\n",
    "'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_clean\n",
    "df1\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following is the summary of Analysis that was run on Logistic Regression and SVM with Five options in unscaled and scaled options.\n",
    "\n",
    "The chart below shows the comparison of all models we ran on AUC score.   We are showing the results of the more significant models in the main body of this notebook, and have included the models of less interest in the Appendix.\n",
    "\n",
    "We compared all models both with and without scaling the data.  \n",
    "\n",
    "The highest performing model for Logistic Regression, per AUC, was Option 3, which included all variables.   A very close score was obtained for Option 1, which included: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age.   Since these Option 1 variables were our most significant variables per our Exploratory Data Analysis, we chose Option 1 as our preferred model.  For these Logistical Regression models, scaling the data did not seem to help.\n",
    "\n",
    "The highest performing model for SVM was option 1 with the variables described above.   In this case, scaling the data did make a difference.\n",
    "\n",
    "Our primary model is Logistic Regression, unscaled data with the following attributes: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age.\n",
    "\n",
    "Our backup/ secondary model is SVM with scaled data and the following attributes: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age."
   ]
  },
  {
   "attachments": {
    "compare.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAByQAAAIKCAIAAADtYG8jAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAAhdEVYdENyZWF0aW9uIFRpbWUAMjAyMDowOTozMCAyMToxODo0NurhK8sAAP94SURBVHhe7P1tjCvHeecN9+T7+mMkSN5VvCaPgNE4kGTAQjjwRlpYSshzgB0EwtixsZpYi5CArWeHxmrWXmMQw8HAK2V0PyaflQ2Qxi37KLCzHijGAEeHdI6MlRNjaNiAZUEaDeBDei2towMpH72fpXnqqqquruqu6jc2ySbn/wMx012vV710VdfV9bJ269Ytz+fatWvNZkvelJ61Ne/8XF4DAGLAwwKWBdRVAAAAYLGgLwYAAADywftQ6kR/T9wDAAAAAAAAAAAAAAAAmAYoWwEAAAAAAAAAAAAAAKAAoGwFAAAAAACL5Z7u4Y/XvvD0UN4mItx/t/uuvAcAAAAuDOg0ASg7ULYCAAAAAKw2YpSlD8yyjtPS8e4TmxQL/TZfukcaAgAAACAKOk0AVhcoWwEAAAAALggPHMxuOMcGjU89OrrjhfHXHzz/+ue3X32sYE0uAAAAsDKg0wRgpYGyFQAAAADgAnDH2zXPGw2sw7krLX9yjbbMkAw3X7riz4r9cet1Ye7gX/71iP29/c0K3byxu/fFOl0YM3dkCK8/LW7ZzzGXR03FZT9t2aPyePjYmTQCAAAAlhB0mgCsNFC2AgAAAABcBH6633jbNrn1SusLT/a9nw345JrOHXe2nwqGaqPBk2d/ysyfaXpe/7nYbQd+/7c19veVJ9cOn5gIE+JKK5i584z3wycmbBj5w9+KiTydO6zKXzZo/Eb7lpDnwcH9TB4R75XWcw94Iqg/9fq3uFsAAABgGUGnCcBKA2UrAAAAAMCFoPrw3zWjk1tf/3jf82qN5/mcmjcu3/u259159JqvkL3jhb2PsH8vbt3P/n7wZszZGrc9e/KlF2joeOvRKs2j4aNHEfi9L/OZOy/29p6tMGfsL92+cel29jcS5rsPHbEx4f0/EXN86vf+zPMeOH7dDOojz7MxJwAAALCsoNMEYKWBshUAAAAA4ILwYu9xGoYdvPQhaeB5k3c+KK84ldv/WV45mLz0XctaRQEbE379wXN/9Ljz0j0i8I3b3+DWkuHfCu8/brwiTQzEyspXnpSxPPeAMA7JCQAAACw36DQBWF2gbAUAAAAAuDDw6S2jwcfPaIIMEdKuWkd6OpWHP3PO1yqef/0zu7dJQwM2eiSVrjd6R6p0T98JNi6YvPRdNlxsPi5WO0rDKLXG5/1Y6Nf7SLIWGAAAAFg+0GkCsIpA2QoAAAAAcHF4Y/exF2reA301QeYjP6G9BV59iO8Zd8/1V+/0vJ9t0dYB2WADQnVwx/BVmlnTvPfFyh/+tBYEfqV1+MSYLt5e/326PbZO0hHyRLel49vbyaBef6yN7ecAAAAsLeg0AVht5qBsFefbxp6oAJabxCLmDoydvwXi2ETUjYvG9G3C3FqVEtbtQkKeWwYCAErJbc/uG7NjXux96YWa2DPuC+KQDf9M5CxUHv7a9qvfUEsdm4/TzBqasBME/ufrjz1bp31j72w/xW6f9O6nuTwRXuzReVwPNHhQ/MfbKzH3RwT1w98O6LAvAAAAYClBpwnAinNLo9frnZ974d87T9TaP/bU7/krYQfh3z2dv2Eunx7I2ytN8qhuC/sxQib45fqJ8vpx8zXNUBT63zwxViZxv8Qi5g4soYWqCn6z+s31YXnt6aC5sFchvcLkqwMpW5XlqdtaM1u7cU/Y1vjly7GQr5QZuIAfGnb88MMPP/zwW+wPfTF++OGHH3745fvxPpRImNlKZyA89ejo/mfE3h/jxtu09bJlGlcML/bIb54pEmAuiHOHvf6rV8Q9Y/LaH42CYxATQREDCbUYzz3gqRbj3j/a8VfHaExfYVKGsCR1+90nNlkze8cLY4rr89uvRhYBFQ+eWQAAAAAAAAAAYCbEK1uvHA5o367Bf3xR3Fce/lrnDs+79UfX6fBZWoi6+dIVvqaVfq3XmeE93cNv8A1B+Dx2UsuGFr2K5avipw6xtQZFqKP31v42UJeAYqnQ2gTPe+XjfhnJ/dr2H+aHY7z+tCwCKiOuOHv3iU26fsJfiWwWcdS9z3W/NFX5mohwxC9ywDFYAqItxmdOWC1yVphoc8GwVYO8VW456rY4QvT2N7n+943dPaUDjfUlcbjhCRHmrdeZmyKbZQAAAAAAAAAAALiIVba+/vE++3v/T7TZT29corNr7zx6TSoaRoMnj+79/PnXP9+5w+s/x0bpb+zu0TUpXL7+4Pnes+b0MTZ6f7IvrMjLne2nAu0AC+rsT5n5M02PBcW1AK8/3XhFnqw3vv3jDl0DmJ4Xt2jvtgeOhTLl3YeObvnl/u4Tmz/8rZhwxw8vDubcjQaPenQqojk5zu3eu/Xo2b3SnFcVaewj9EGibjw4uJ/VDaUJAkuCpcUIsFWYaHMRVw0yVzliGeo2370+smggzRPhcnOlFUyVfcb74UOXC2yWAQAAAAAAAAAA4Ob3fvSjH924cWM4HF6/fl2axVK93dxZ+Y4XrtIcMbFc986zf5HGdrguptZ4nqswpBelt2VB7dHRt0I58sGbarTPT9CrPPzF3dukCSic+r202bZYbS3WWTfv5ZMTb3v2RKpmhJ49KBe/vEyS3Tuqiq4Fk/L4CjKwJEze+aC8smKtMCHiq0HWKsdZgrrNQv7SC6RvFRvYC5VrmifC5Ua0tHKrhBd7UmwHuZrlmbK2hh9++OGHH374LeyHvhg//PDDDz/88v0Yb3B+7xOf+MQjjzxSr9cvX75MxkmM37mT/d24nS/CjXD6jrG0NkRIF1O5/Z/llYuPfHHARvjyMD5MqpolH/mJv9parrPe8pVNaieHxivSRCJXPYdxujcJVxWxkvqVJ4Vf2vcTLBsJT7SjwhjEV4N8VW4p6vZtz558/cFzX+VKG92m8eVwI1paVysdInOzPHtCW4zjhx9++M3/t+xtEeRf7A/y44cffvoPbcJif5Afv3n+GPdwYrcRkItb1XaHjHtuvsP+vr3+++I2TPzwPjSMT6MRqP9HWh5LB3N5DxyYmySCQvFXW79Ec+X8aW503lHjFa9JS6ofJMV3EundW8tdbBmhfr3o7EJQZiwtRh4yVYMUVW556vZtz548TvNwR+98SBik8eVyE//pS5GjWQYAAAAAAAAAAICLWGXrbc/ucyWF0nJOXvoynbJy/98FK/rFJCz/YBw+Zcy+mJfgU8zEtgBeZJZZlMlL3xWn0JRhstXKI1dbDx4deW9v/6GuahG69SvHsbP5NBzubz16SIug9aqiIepGeMNNsFT4LUZDHWf3+tOhg6QimM1FzmqQUEVLXrdVQ8cYvkqzU2mjgzRZ4XBT+cOf1pi5bGmvtGhfgsKaZQAAAAAAAAAAAMQQq2zlE0vHjbdHg2+IZarVwZ00scs/apy442cbrzLbJ/ue13xcnidTf+SFmndn+yl1vLjixd6XXqjJbQHEuS7mETQmlYe/tk2B8+Wx9z9Dx5qD2cF1LsQdP73sK9P5Ye68KL/wpHc/aaziiXFfazyz/kMy16uKxos9OoSHn5Yuf9g4YvkQLUawsP2Hv+V7OsdhNheZq0GqKlruuh00dHyDAtbG8tmpabLC4UZsAitb2j9ff4z2bC2qWQYAAAAAAAAAAEAMa7du3ZKXnnft2rVmsyVvkuFnWN/xwjj+9JWZsbYmN0QAAMSDhwUsC6irAIAysOxtEeRfLEsi/z3dw2+0b73d+dJnQqcQoy9eKkQ5pv9Y7ix3MDvQpi0WyL/SlK5N4+VFBZYwsxUAAAAAIB1XWsE8a/q1aIeN3BQb2pSwNzkmA5ZcgHkweem7VOfDCxGWhNefVs9s0lZCpUSTf6FtDrhgvPvE5lI/OKDEoE9ZJOhTLjBQtgIAAACgOO54YUzHtX2+c4fXf+673ehOwdn42SAIDe+pYOUhtX6VdgBfTtio8tWf8AMb6ZkdDb6xZM/su09sCvm/9ELNY20Ovq+AucAq3lOPjvzec/tVHGIBigJ9ykJBn3KxmUbZ+mKP1ZsF7SEAAAAAgBIjjmW78+xfxK2YGSp+mgZW++BPP+e0izcu3/s2+3f6Dp/UEJ3mwOcEbb70BJ8My99lnW6uKEnYK/vwb4Nrn6iozOQbdECo2CJZCmlLUVQMcAFx1L01eXqkqDlGnRGOqRK++9DRrbc7j9OobGFMI/9Hvugf7WA+s/NkGvlve/ZEyH/bmxvcvmCmkU3BzXM1ZRwlw+FjZ9IILJp/+dcj9vf2N/mw+o3dPX9DgGgdiFahMCj3lWOadgN9yvRMI/+s+5RFMU2eKLj5avdlmNkKAAAAgMK5cvwK+/uzLTrwjb0niR3lHjz/+oOD++9sP8UVkew167kHao3PiwkLNIk1zRdc5uuHv1WTZ0eDYAbQaPCo9zgz/2I9zs2fe4+pKQY/Pridxf5MM5huYBWVDX19CeVnZkeKOIEY0gBcJNx1z8aVVjCd7Rnvh09M2MDs65/Z/X1pvQCmlF+aE+N3aC7Vxu3zPd62KPlf/3if/b3/J0U+xcXlLSNXU8a40nruAbn+4E+9fnByB1gov/9b0oW98qT5xTFSB5KrEMp95UCf4oM+pSygL0sNlK0AAAAAKI5bj1bpUzM/QlMoHGliRfCKWb/3Z573wPHrYi7P29t/yN6b5YQFN1cOaREcd8xGDlInKybPfvCm+sp9xwt7pNvlUwmcbn56+Tbm4OVtrjzdf5jF/uLW/eyau3GJGiLemRIDXEBi6l4UPvqq3fsyd/9iL83HhllTlPyvP914ZRHPwtTyy80N2SjO+9lAzqgqiGLrRr6mTA/2I8+zcTIoBaxucF2D7ECFyjVaBxKrEMp99Si23Zg/RcmPPqU8FFsnV7ovg7IVAAAAAMXBvzOPG2+zQeOOWFskFki+8qRc70NvnByay3Pn0WvMzT3XX73Tu+O3VWmhw1fuf+HJvhccM6oWGdGbt45cg0k43cTjEjVEvDNNDHABSV/3Ju98kP2d9zydJAqQ/12atE4Dy+iwavZMKX/l4c+c8wk4Td74GGsep2Z+dcPRRolgQRm57dkTVvF8lSvrPa11IKEKodxXEfQp6FPKBvqylEDZCgAAAICCqfzhT9mIcfTqQ2q5EN8ugBYBiV/Pn5swGnxj7QvfaN96u/OY9R1aLh06/7rUtE5e+i57t2vSOv0HB/Tp20IaNzG4RA2R0hm4UOSoewvYgc5NEfLzNYP05C5gJ43i8l/MrCmydOZfN6JtVOX2f5Z2oJzc9uzJ4z9j/0fvfEgY6HUgZRVCua8S6FPQp5QN9GXpgbIVAAAAAEVz27P77A3s1qOHr3veR37SJKVqeFOnyWt/NKL5quLlSepS0/H2Om1AJraFdZHGTQSHqOGlUk5nADAidU+cjPHKx6nCvP4YP2yNML9JXGk5D4ibM9PIf6VF89AXMyr2mUL+15/2Dx265+Y77K/Y56RA5lU3XG0U3xtUBqtFBxbL5KXv+hXPG75KU7ea974YrQNjuojt2lDuqwn6FPQpZQN9WSqgbAUAAABA8fCdlbz+q1dokyZ//ZRcB8RP6q88/HdN7872U4ZhIpqvJ737KYooadw4sIvKqD/yQk2ESW+KTmfgguOoey/2aLYarzA//O2g4e9QfBvfqFFuc/zn6489W3mXH9pLs3j83Rvl2b5zYkr5vZf+vE8W2qMx39H+tPn/kS9e9b7MJefT7f2tSwphWtmkRUocbZSYOCmC1aMDC6Xy8Ne2X/2GKCkxZYyWSkTqQD25a0O5rxroU9CnlA30ZelZu3Ur0ANfu3at2WzJm9Kztuadn8trAEAMeFjAsoC6eqEY/i0bVfqvnmw8wAYD9z9zvhqnB4AlZ9nbIsi/WCA/AEAHbcJigfxgnvDyogLDzFYAAAAAzB+xouqfL4mP/GILfAAAAAAAAABYcqBsBQAAAMD8eWN3T1sZ9NwDHqa1AgAAAAAAAJYfbCMAwOqDhwUsC6irAIAysOxtEeRfLJAfAKCDNmGxQH4wT3h5UYGtPf/88++///57773H/jJaraVRtgIAAAAAAAAAAAAAAEAZOD09ZX+jM1ub8qb0rK2tCYUxACAePCxgWUBdBQCUgWVviyD/YoH8AAAdtAmLBfKDeaLKC3u2AgAAAAAAAAAAAAAAQAFA2QoAAAAAAAAAAAAAAAAFcGGUrcPW2lpryC4m3c21ze5EmGZHeVcBukh0kBWX5CUUSWGNMVGMrGWU1b3OZDjM5zFEfCkUnvOFB1hGKE9lIossJo28tWZa0tRYleT81ZvVkkWlcHnQszd3NVPPo6WwzFJI/eSaVTVrOVqKnmIWmDZZzTOQv+rOi0QJYxykqi08F0MFTmalbL1nXV4q4Sqi6EWIRAdFUdpCAQAAAAAAywlmtmaksntyfrJbkXeloIQiLQts/FY9uClvQLmYdHfaG4NevdBiGp+Nap3xuU9pnxs9yfkf8HpvsNHemaGCYqWYTWswbDX68jI9pFiqHm2rijrueO1qBlVQNFIWYuNU1HwemB9WVvNVI/fDlam29BtQ49lJn/94zwEArASFftkJAksKtrBo5/JlanaRzEV8AADwmVrZSqPCgDQTD8iH2c6JMGY5acHzqus1eVUQiQEWHmMiyyLS/MWYJ/NJ8mrnITE8bHudvbq8K4jJzVNv49IFGrDX9zpe+xCvlbPG/jzSO31Y65niyR22qqzujzXNUmX3ZNyp9Q/S9JG2SOlpGjX3RYCV3f2m1z/mlSKrOchDs9M5TVV2q06Zu61ssg27m/zNd7OVslzpsTQx3oKHLfkiHQlw4rbiBPZZ9AdFyp87aXFWCcxP/smwG0gZzmBhmXHsog2aIgHapGGurIam40AIq6EfbVRW4Xy246986KPLlPLF5y1nHuPNLJA8LlnTUluvyisdW0rtLsvK7KQteT7Ms33L3QiHKEWbPEVyiu7TCUfvHJhG5Y/pbhZBfIsazQLmymrInVtapMCxYaxFK81jBBFhBP5tYWrebQmZPdMpW1mSqu2NAc1+IfgMGCPDkqFc2fH2O7N+B69c2tBb1+t+YShxqSg2u+xxkxbcJlq8whnzEwowiu5AL2ej7mx2uxFJ4lGSl0ckiRaiqstWkQxDmy9BNKWE271ET5jdH4MsmEm1PfJG7apKqM0vmbW60kIYas6iMiQm2ZREy2PVQoh6qIK2SWWNZYWYdA/6te3LFZ76mGIyMim56tLE1uRss4VPuOLVqkfo1nfhYwQn0e2F4MxETzI5UOnRXIfSrrVdWjSkKUunpCsrInX2ktVyQyU6Jjd056GQxkae06OoZSL5Y7emdx8ejPV5HB73mwPWLRqdW/KTy7x5vqIzIJjYFyMGwxopfWTQYq1vSe1pVvM4NLG0rAtwZb5p7iosa5A+5DQIkLejyr1WlHqIvr3h1dUCRzoj5iv8hEYJJPIu7e47p5hrnlWEQir7E61Hphm7MGWzhxMORkQfSMudCke22Mks1AZG4eFFK38oquiLmUK5FBeZMscUSYZNhprYGbrUSbd18/LJCb30nvQuHYazz4G+pOJ80NQiY5IcrF8VFle3zvRp5JPuTuNUTHEf768fhd+vWY2tHnj7YxEyLQNJQ9Hy502a0yqBOco/bFUPzra4lOPB9mkjyH8aRm8e3ry0t51t8CI/pYmY+lqAknqPrHwGTc9rbtWthiwof/UBH3yJBsZh6BpnkfNmc9bjrxxQ1Q4Wd4y3j1Is0UnK25h8WGKsn4msKS3zx64os5O25Pkw1/Y5tn9JTyna5CmSU7j8DFfvTG3u9kCYnux53WA3qpikLYZCe6toi8TMVG812FAL6Nirgdb2i2HP8NA3IUH08gl1YdYwWcXwvdO0lYWsNLul0esZeZQEjeeMusbg+cq1r8yWWdI9Rzg0hoCaX1tQSbAQ5FUmhAgyMn6j5NVkkoIat9wdXWWVNMgUhhkUQ4teObIi3JdOJBG17jiFR4nuUhOJG1tS6oqFLqNihIy1LFKuDPMYv4G56Uy7DjzE48h5bu77p2s9XOUhbSQRWHDyajkwE2rc6RmiXfNLa6Zp8EyucYeExYXpVy+s2HhVSKFbwxe/EekIrhz1IXAQ9ua71q75peE8CFL3vhywpMgrgUidntRoDuipFO4tuZGU1UEQFrfqJgE9EEHUJJ6s7q2EAjGSw/Dvs5o7ofh8F5rjQAwjhMB1SE5l4TJ3oDtnMbFn3L8jGxWTCiJwH1yRhFoYfpXj/pRFEErgMR4/4eTejz7IjCA845pfWiI13PObeBFCLgLfejjate/e9KfudF+aG26szFNhBBmE7UfKb0yRHC7DTi3iadnNCByJcJSFDWYvr3TYoEpGTrBg9NtUhPyYATJxlVDMRhdQt2Kw2/io5yS/TuqkxVn5LF5+E6uQMR4s8rMggjBYZJYAA8g+ErgyNHz7dcFqKIkGJ1xHzSX2/J8HRjalJW3eOtOrwdwwJxQiJ5yNPqHobO4153rB8Bs9KPJjJptsk+RkMGfSlemdEQohcGlFk0Y508y0oFVEboGtHpnzWqfD/OiGLgJpLYJpRqZYGsLC4jIIef4wMeSVizm2bywqvRhY/iWWil3+crTJaZIzN/l5XbcFEhJr3Gk64sog/4xgEgQisBRa5Akg+0iKw4bGvWmpMsyZcwLTF93pXZgjTA3TxaxR5TWFstUusUobWauWkd/IYqLrcInlSX3OOqeLwlAxW8xdzjJKOpYfNiRxMcaG7HKf6DFKkSJxB8YzGbl14QrfJYYrFpcDdU8OdHMfXYA4v5pFyJm61YOKwZXzZrBBnC6pMjLXBroAotnhKCZ1Gyoma3FwN4Ep3Uby0uqRkSFe7TbkS92rWOKeRF8MdZ1BBj0JYSFKTriuulIXl7c294lZrS4ILXQy1yOKxQiEEzWJJ1N0LkKR2vKKrLOau3ClUZnHZb4tsS5zF4F7dsWHc0IcZW5LEd2TA+7UdEDG4ja44ij36iKBIFzmQ3pQZiGp1K0r0pD7yH0Y8mizj4s3krrE2MmBNRo30YhCgdgdxLp0ipfubceGtd9k/rh/HxZPfCgRwiGwIIJ7Ztk0BA5gznR/yRHPS/6ALElLTnUJ5NcgVZjFMsZHVH4WvhaGeReBxRdNmm5I13RjhGM15IRN6J6Ccophzf954EsWhqfNQJPbTIYzUbFWCnKjQuc3Uh49/7WADPeam6CS67GGA1FptYYem2od3TdHjzMJQw4BGRni+DdBRFaBY40DC3GnY5XVIpg1V1lw8krzYc//BcJSKa8cMDkNMVmyQqlPIhyCRowVz6vkDLLKvzCZHW0yx56ceckfEwSXWcxsHQ86TaqW3NzEkbTE+lMgLFGaCOZdBCZuNMURQzMQw9q/4U7cc6LImQqB3Co/wtAapo7NbHawFIiLKfdstW5/ODoby6vmQG47x3d9O7254BnRCprTLKlc2ggEDk0CD93mpVLhk6D99XG0/FChRWFI4qKEIvnootEqjRTFPT4bOXfQdKQ0NhZa/Or1GzJVDNq6kFzwtdTS3DF/3OmXMIXJkVKFI+dDy3Yrl+XStFipLirO/Ndz0FZ1aSW2dsYKuYksjo6pk2niJYLb5OKLexJtpJVBJ2sdLSFa6vySzfDACrJldX2vUxOVY3L9aKT1GHNhHsXlanmzmhNxLTnHlfmuljlFi21ALabYAOH6kbd9eXeryZ9+KjteFxKfRFcLzIl5uDLA0mTZS0APO+mJztwdxGSjM14OpX90dJ2MeB7Sji6Zn7jMuF7MomTJnJRvO3OE11H9aanvbZ/tbG5urm22Ng/P9nu2J4lW3Xv72kbOLMG19fpQ7vA27YZ7WYjIH5AlaWlSPROyyM8Rlad6sO6PaAqCarkbvp9MuOcxDOs9NnJkdZ6Wel71JbMaWghOIC0f1KHYMBeoEs4Cic/bVFgGsHx/K3WWAJnLZpJQ7mnfHdky1nu+hLxNTRpOaTv28BcPvp1QhlRPifk+zCVQNSTIBJ2QwP7eX7G55IeYIV2mYNZcpQ5AvoRQ2efL/5Ugc/tGRPqX+VJ0mzzv5ISFjOud6eDio0aVLHaOL21F9qGZVXczJdP2VhZYTqgX1LWDU5ERvPHfFhsMjbU1//IVrtFX7ay1C7OGGWC2TXNkSmVrpOUlXO+vF6Ods8DriLaPUrj0F0AJRSqIyJcX8Vj63bp6DG0jeIffQsme8/OQCsyMhOJb3SdxDmR7NLJlNb2a0xs+H3CI1wX2/kZNR4iit1VyqpmY/DyuHGK49O1ZzfPjzHxXy5yqxQ6gXKPiYi9qNOBiCWB3weiPmF1DmrZEijiuLmMqMmajQg2Qs+fhfB4TK3bxStbGTrrhweOwtXO2dcI4P+md9NYPInlF+4PueFdPjGEFjUmOWgfrV3m6TvZSbzQ3JVH5FZmSlpjqGZFJfoF4isb7ZwULyT8QOLAOCk1DqtjHW1y07SN/T3urYZQyq1oLIS5vc6E6Zdqq24e+6MQTNIeJn9IJ9ZVXe/GYD/wUzlPeS8hKE1Z5s141+mYSbPROAgd7zWfLpTiigllzVdOwko7H//ibMf+Xnxztm7V/mSfFtsnzT05UyPjeud7ju8MyCyZj5MPSrLqbKZmyt7Ljv6Ay9jeCjPCfXhqG+U+173S8fsDfY51dmCNMQuxBG/cNcmZMoWy1jgn1Ri7MYiYR2NCGkVR/ZiwYyxMaA/ijEqMD0zKQJJlX3zoLkbRPlzxAVzXQyDGkj42FV0nNgQXxGA6i572k8OuTI6UKR86HHybDPJ1UFwdn/idVXRqGhMajkWc/pk5mL/fk4ot7Em3kqXtp3ZUYS8lmfjSyZrXQtna1IQ+fGR3BD7Aw+HArcqYZvbiIYswhRqh9YVkhno6s5i4SW/LkzHe1zM4WO4SYTNQ97osE8MI7PPP1hIm1JZTi5Oqhk7pEKrtXO6cH3ZvylsjyRCemwk0kGxPjZRnK3AyDEXTa2PM/JlO9mDnFy/rgJ8Ei0msKkzSToJPIRB1KqxaCGbwYOR5vXY1kIBWQt87GDcKc/T3VK5aTwuVXZEpafKpjmKf8BpV6b39jyo8lvJYaCXU88MPDtq66EhiG+lCWGhY+Fd1qSDdh6DHw5/+QFso/7K8caPMlDfh3EwNN5tR5mw9Vy0JLUGNbNhrc+2dIp/vMI7/ysrqoXjxiU10ksun2j5Whbl2H1RnLoybVw7rARIpcSp+ukGDWXKUGRWp4afKbUMJkz/+FM+f2zdm/ZKE8bXK+5BQvf+remV5Pti/LG50iupspKbC3SkaNMpJGE74CNkUXZo5cWHtD39ynqun5mWZmK29jzZPgNhuqoyeULX8D0Cpj7Lhs9oz8xXykGs9SHfKiXnh4FvEriT9FWkiidVWzpliRqC6M/HaBqwXSeKSHRvO1mTTtJjEW4UCt1KS+nNdAutCCpl6Zt6V6W+LyGyJfSnWsOc9fLn0Fy7AVmKeTatWg7AgaiWgxOfI/oeqSX+0NXvRyoWffVSfzlXua4rPWh2gvx8gng6rty4ylZNPkbQh3o0eE85yPetrzbZY5NEj22vpJqkxe9jbRzD8RSW9f9JqT1dxBmpbcmvmultllHgMTedRu96UzKsx+P3jAE2uLnmJmHa0eIaxPaDIV2kugbTbv6Z/orHXelY2p4uUZ2tDqf44nLhsq8FwvZjHixT/4WWERnR7LE4Qnw8OjjZCgFDPFHWS8TnRcRlXpbCzFZoXkNVVV90eOvTr3wULWipPJ4R3JQmSCHJ9uXBLXCRQtvyJT0mKsEpij/CyozZZ/WDQbx7NxTFopHfB2Rr6E8NEof7rCbab1mQwZGi0QG+7zDyZWQ3Fnos3+4Voo/XtECaCHWR9dsgyiG11qgS5zuryNQhXG5sAygOUvBX43kQ2SSF5G0EfEPIoG9feq4Y1NdS5cSeb4SlYhie8syIQQIk92NF1rylzKnK6w9pcR5Or4jL0hyXC0o98VcflfKubavsX0L1koR5ucPznFy89CdPbOE//JYAI3ToOJljFJWwzF9VZJ0Cu3VB5S6+G/sVGkvNFhcaqGSHZriV2YFiaXeYGaVkKejcXpZTogS0B7zSoosT6UeO1wRu0zl/99ibs2/DP0IOJhjuVVJkShyPMQNbn8wpK4bkPmhMUohJZI5pDuKFrhLyqJi7KLRDcSi0eXSDZfIbeJsbgc6IEYFS0wl8YyKJtfI3BBogwCixHDnvOGjSgCI2ifaHipYD7l1bLAMkNLq7OYQvmfXHXN7JeGIWzhE+54VUChW0Lzpaw0Z6ZAdCfCDpJshKmFlk6GkGX5YSmTVwKRAHvJarmhEunODXtWRx0YGWtGmEgodkbUROK0EGjSMmIc2rCFHQRoJimLeYzMZCUxMlA615LDTOhOutIsjGS6zN2Qj8CheUdoEiobI0EqSq0FDqU4miIz0yKQq5AT7tHII4lhZo/UcG8aah40VJoI3UmKeE1BObbY3ZE7UV5CF9HH3OVSRWfc0o1P4EbLA2bol0goHBvMg7wKwQIREdWa4qALHRFdrWNknIRFaotThaeLHSo8gVkczIXNnw8zllchipafyJY0IsZKwCzkVYg5ys9PMBHUjGOjI4UT9c0M5ZUOi0h4CHxwo6BoKehIaBZDXQRlZTMMy2qGQ7FHoiOYS3m1CIJ8Yljli5KQt/Z8INPQc8V92Qewplx+PMI9t2cwf378KgjeumlyKNd+eKbERpQp0YJV0UpU4AJDAIHuI7DSTLUgQt5tAltzyRJtMjbBlFk4VxWx+b9AmCTyKoY5tW9GhgkSM4i5kVchFt8mp0oOM5RXIWYgv71/CyJiwocDdHY3PsxCXs0HljohTpAGbhTkLOVNJAOihuHSIdsgcNOxZu7HoxlFY+O20tQaZrRqzKslYFGJi7Vbt26JqBnXrl1rNiMy5WTS3aye7ds+MBXE2tqaSMnimXRb1y/3smrMKYeOtmekaV8ZkZaa3EkettYO1gsshxI9LGnJmAUzrbpLzMzb4cIJ19UFluysM28Zm8QL0owX3QLPnAvYvc6eJew3DSD/YoH8S4C9l1/oixPrfRreYJYvHsv2VphM6D2xtB042oTFAvnBPFHlNeUBWYAzPit4K/bpgUhlIH2S2avBmlozxSfgF7rd1BJCqzD8ha4gL8PDtqdt7AKyQDsxzTTzlrFJXNVmfNlb4AvYvQIAwHTMvJfPjrnTYPGUMMnTQzs4Bl027ZgDAAAlAcrWAhgee6ENPvIzod0wbAS7F6VhxUVaEjIkud4b0zaNImP5lu4r9dU5D7Rz5anaMArkYNjSNwQC6eGNXvVoe6aZt4xN4iJlLqgnsrPkLfAF7F4BAGBKKrsnJZv/OGtdawmTXADUgZ/K43L4uxuWuQEAysLsthGYOaxBxWxqANKAhwUsC6irAIAysOxtEeRfLJAfAKCDNmGxQH4wT1R5rT3//PPvv//+e++9x/4yWq2WcAEAAAAAAAAAAAAAAAAgDaentKcJZrYCsPrgYQHLAuoqAKAMLHtbBPkXC+QHAOigTVgskB/ME1Ve2LMVAAAAAAAAAAAAAAAACgDKVgAAAAAAAAAAAAAAACgAKFunZNhKcxQyc7VW6LHqdC6zLV5lHhcjOSK7xEBcJDpIz2Q4LCScHKRJhRIvf5LT1ZALDWUuKmSqVKBCLhY923NXFdU4G4VIpj5+0x3XjBtQSAEZyjeINcHTdNUmf3WdF4kSxjhIVRN4TocKM3X5zptZl5dKuIrIHSPZpKigFkqbvQAAAAAA4AIAZetUDFuNvrwsB5Xdk/OT3Yq8szLp7rQ3Br26vLWQIpBiYKOo6sFNeVM+dPHy50m9N9ho78xw3LrsoEKmBRWyPBRcVYattUa/OTjnDJr9RgbNEhNlrXq0PRaez8/HHa9dTaVkYj4bpx3ukXty+yldT1c4uR+oTDWh34DyLyPDw/aIPxlz6QIAAGAKCv3EEwSWFGxh0RYqv4vEdNFbjVWKuYgnmGNUAICVZmplKzWJAWlGiKFGVA9gqdo1aojTDkCr6zV5NS+cMbKhi9fZi9FsgaKp73W89iH6bDuokHMHFXKxRBvn4XHfq6mngJVPbXR0nfWlKTqOYavKHqCxpomq7J6MO7X+QWJnzNVY+8JjZXe/6fWPbZUiS08HYml2OqfJ5XIBSP9GNLl56tXWq/IuGzN87xp2N/mL62YrZXHSU2Siv+5Oht2WfBHetL0GT4a+teFNmaYWw2d+8gei2+NyJC2Bksgv/GWcc62NeSwpjgrKXVk92UZPupkytRoSwiL7pPGp0SVKGb3mRUuBwcKS44DkccmaFnvrZ0tp3nZyMVikpbqfpfCyus/OPLN0bm1ayF+0gpakTXY3vAl9igw6g+xhypSWxRLf6kaTzV1pnjRfmuPQUytsAkNLpHqQWqBBmMp3epdzZTplK5O+2t6Q03Hk5Jhs6Zh0d/wpOTQ+XKJpH2x43ByQ0PI+lsqlDdVomzVBZhcZbna7fm1ImYnXg7orM06EwzzrMWpMugf92vZlfYZITCCEqqGbXdb+BDXX5pHQk+cwFhbMpNoeeaN21ZpczYMWjN2czFpdadEahm59Fz5GcBLdXmQ/M9HFIwdKTM21IYPIIokWDSkyUug+LiKokKHgJLo9KmR6RKrtDamWSyozYnJJdx4KaWyUBdVILXPJH7s1vfvwYKKNc71nn7jnaMY1SE3rK0wDgmmaMWKE1Fj1Lbu2NVNPR2hRatkS4MpY09xVENYgfchpECBvKpR7rZj0EH17w2vqRob5Cj+VUQKJvEu7+85p5ZpnFaGQyv4U65Fpxi5M2ezhhIMR0QfScqfCkS12Mgu1e1F4eK6KrbJXxMpC8LPXj8RRNGZc0jT58cnHpNu6efnkhF5bT3qXDn0ZEqiJOeSCQVOTbNiqHpxtXSXz8WD7NDytnSW5euDtj4V3tQaEJflgnXs6P7+6dRYzLz3MHOVnb/iNU/GKP95fPwqPDxxJS6AU8tP4efPw5qW97Wwaffl1jEK0LmGgviBg0PS85lbdGx76AyXyJFLsHj35aySMLI0Y0qO04+2nb9kLg4o9WIsx3j5KsdImKd8WmJwZYv1eZE3pDL8szQC7tK73IBdZ3Wdknlk65z4laAwizW452uSYjiOx42MOGqe1/GVXprQsmFy9lb1jGrb8ZXTM1NPfgsmm2QzKyxlpuAtjVVWFOdjQl+aldzk/bmn0ekbGJUHDL6N+MXhm82QyW2ZJ9xzhkLwown5t4cXAQpBXCySjzHoGMXh28DuZMSrr9MpiQ7j3YzbDiZHHtE4OhKT17UVRatJGPeqXejDBFUe5CpkH6OHoOaaba9f8UjkK3xq++E1YqphC8cUzvfmutWt+aTgPgtS9LwYmmrwqF2a+uPIwcIUK6YtnevNda9f80nAeBKl7Lx1ManmVA5FqPQuiOaOnXri35FJSEQRBWNyqmwT0QDQoPIuxDUcIqTDEZoTvDdJGRO78ULQAA++RzBJ3ofCVhcvcge6cxVRjyDuyUTGpIAL3wRVJqIXhVyfuT1kEoQQe4/ETTu796IPMCMIzrvmlJVLDPb+JFyHkIvCth6Nd++5Nf+pO96W54cbKPBVmkH5cWvhB6IyYolFuDN9TwiKQVzpsIBVERrHpt6mI9cMSpgvPbu1uTTFCvgQLl59FFUpLqqT5lFx+QUxYFvlZEEEYTA5LgAFkHw7cZqabWsOMicgensCe/9NiZEFa0uZbXHJ8mBvmhELk6M7Ju08oOpt7zbly7UuqB0V+zGSTbZKcDOZMujK9M0IhBC6taNIoZ5qZFrSKyC2w1SNzXut0mB/d0EUgrR6Ldk1RWPM8q3uHtIaxFp6ehEDIAmFByyudObZp4TsTngVxUc9H/riG14wrkhgWECXBlUi7/DolSouFZPkLhAkUSEQZGyeezHh5J1GGhm8WrnIpLDTP9kgN/wLND0OFmd7lPFDlNcXM1sn1o1FoTpqYHXN6U+qhR+3qwTpPkr8hHE24UTkR/iI1Pht5G5dm9pWqFEyqe9q3osrl7VqQXSxXhE1l92qqVaBqQlMoHDeWLI4LxJg1RWtb+YXE4lHsruYnj6bPjdRqZS1aqgWxH8x41fIX1dKnE+nYCD+87pU+/2sEt3FScWILJUy8DK7MrFza8EZnY3kHfFAhUSGLx88OrSGNzXNLLmUqAn1OKFWVUMlng77K92udq1KkFBTZaboTmQ7Xk6KIy1jXI5nhUaUAZb2e3DytbW9viP0YgnJJfPqyNjJZoVoZ2Usg61OcmAoLtmyMjZfB81PkoCxceuWLf5qmqP1+Sh2vQHFFk6U9nw6aEa7BmtKsLSnLSC/86uwzYYnUJsXwieV+kk3qWxt+yXChmv42JAnMU/5670QriOHxabqkxVIa+fNAwpthxDQi/DkL5RCZRcZd4TepfkPM8DYmIlkNFwBlga2RoPmaJvoMsCz5loLo4JSgKVX+Us1xx5gO2G9I94OgsRu2djwxK42NaiPNFTVD+mjXWDoStKVxqeaBpJy6Getywg9G4KL6I2/2omEmVq0S8LELHJdLo3bb4xa9ehHpUnmesKO8j62MXNK6yk5LQobMn5Z5tmkcvzEIr10vS5sc1/DGdnyipk9TbOVJy8KhrJiqt9I6JnpNZLWOPcV84rE/whHlpeVPXKShLowVjWeUTXCT3uXcmHLPVu0FNyBIRtOv8/wtPr5z5OuJV37vxkqF8kP1Q7RETqHVr0jVsGHWx5zEBRKq9Hykp7B45I2UasQZtNEflbp8zDjJPWas2l2PlhZ5qEoVkie4dUqliCsUG2ll0DHcATcxeYgK6SCtDDorXCG1VPsNaWye23IpWxGQ3keMSmhIMoW2iQ+ARqrfTEeRxeio5amJeVIErox1PZJZH1VqFHhRiBfe3a0m70ipXHg5Jz59WRuZHLA0WfYS0MNOeoqT25AQMdnojJejaVt5HtIYIvPTlBbtybG9AjmLJmslWTT2cbF4KKoH6/rjz9JcW6/727qZI+P63vbZzubmJjPePDzb70336GYgg/wBtGDS20+ZtNlSjPwFQLXczZC+LahHQraZdI5iRAh99EQ6PoGmorIaLgjqI2yYK1IJZ2bH51sqLINTcwxK5uo7k+Zem1BU7/kS8mYyacSmKS/5ewJXTGRI9ZQovSmHS2B8MIt2ICGBha41IZf8EItIVxYFAmEpI6e0zrILkrBUZGnT9LI52TrbCZqDsrXJRLThdXd8QrO+6AIsJi2lI0tvJTEeP1btaFcA9tLvuVWtYVSkti6s3uMBCg5O1etgWpdzZUplq7X5c71tx/VFYpOGDLN5lhXe+GlbVyyi0GdJZHa2aFf81l1V+Pm+7Tmk8ln1QrnIoEICQUKeh8hWBPS+TqMSPoIRLxzstYpXLBNjdkcIFqXYqijDu6JNJ8VhgfG4YsRYjL7dmbGuRzLjo0o5QkXBhvSk9WWJZHfBUJHIVhOykLbQ6wUcUZcxFXlbPDU+zZ6H2R+B3Cy4Pc/EpGsfi4k0jPfPDrQsIs3UUetg/SrP7pM9bQe5YWvnbOuEcX7SO+mt675mSib5BbS/6Y53VZ/gE5u0mVKU/AXAP1s4MNVEQRUfrx+Eqrdr9MRVVKaKzWG4bMTlWy5UH8q3h5bQN6R4ghYu8Ys4oT7Kau8J86FCh2ae8qZRVu6wypt1lNEXCaVt5QIHs9ay5VJBxCkQYrFLm7Hsyk2ONs2nvrURNAdla5OtDa+74+PtgnwDYCXNrhbwHlBQWspHlt6KY3ZM9OZ/vMXr4/YRP+MgWdVqjVTvwvxekbG/EXmM07ucA1MoW63DPNJuuya2OKc8sEKgwVdhI54SQ9P52SjFT6rR4WmZSRVsrn2xlXAJh7vnMNx98JHThqjwg4S3vRgtgB4+yZM8EytZqrhCsZFdhvTuQAyokHZQIQ0sDWmKmmCStQiEtrWrjaGCz6s6zk6OvfrTnCW3Awd8/BZZb02vPqJ4Y8QIPU7Ud0/d6SQqcJMz1vVIpntUmTs+q6V73OeJEQVzeObrCRNrQihXkoteJ3WhV8ReAjflLZHlKc5cnwMi2ZgYL8tQ5mYYDLfTxp7xETA+3tOTG35jTFE0aSvJNDAxdCmYpJlm807c816ISr23vxEo4inzvXU2XhEe2N9TWWkoh7R40y92nKv8zD2NMY+3rkbK3Z20eMoify7Cddi5mMC+KJNBLZr2pMSNnmwPkd1wnigNXgj+Gc5A0zykzrd8qAwJ7fUXW+jmAvU0X8TlR1ld1xqb6iKRrbF/Ogz11DqsMbXUCqke1gUmUuRS8enKXWlt0mYvu5ky5zbNSZnaZFfDSw2YFrges/7GwV4CWMHn+DxWkrSUgWl6q1DHpGtj6e2X1ktdZy9wUjXOv3jQV5HNLsuFhEgp1yJlYh2/pHc5e6aZ2crbYX1XGz5e1LXbypZntFYBg1cF+rx0UTStAjVK4dnFryTaIaOs5s6iMtBrTuxQ2IS/FfkD+WEr8RMm1YhRsD6SulteAehC+8KkHoDooyygVxK15w7/ACl8i/CV+UG6R8YllY61UKzi5ZPB+swDVEgGKmTRWBrSNHkewt1QE+Gy4MOodt52myT1OuM8E6foxcVrhw44ZW8uzeTFVPrjlLrmxON6UnSsGet6JF3mMbBkjdptf5MyKqh+P3j9SKwJWRsZV6ORQIX2Emj7gWd9irPWZ1c2poqXZ2hDq9s5nqZUqDDFkxtRNbmKJkclmQaW/NPjoZBiMjw82ggJSuJQjgQS6UTHYsz9ZkuGR8My9rIcSM8i845kATHL49ONS+Ka6t3Z2M/1yU2vmTbJc5TfH2P26twHc6mVkzNpCZRF/lzwOixVjXyIyh+qcFMZfhSZvW9Lii85/CRfodETE1g9iWp7V6vh4mDlZ4wcWTLoRnwo0dFHhenyLQpVBpsDy+CU9+F+85INkkheRtBfcHkUDeqeVVsam+pcuJLM8ZWsQhJVqVQmhBB5sqPpWlPmUhHpcioQ0pNC2riymxvzbdNofwCRsUN6B9MamvK0yc6GN3/Hl5JVSsuU5OutuINQx2S8Jss+bFdrI+iLh5yGYYs0qQujt0Ghe0zvct7c0uj1Iu1jIgP/9D+C8sqH8k47HFD7uOR/RyLXhndO6CuUG+ZWXi0Qv4b4hO+jaClmDumOUiz8yWMQU2RCKB51mxg/i1DZpwpEySvE45K5PPo3Ppobo6ADc2lsSa8WjmFrM4+TR2CTSnOmScdM6E6EHYhnhKmFlk6GkOX8YZLKq7LBstjIV1seGuaqrFAhVZhaaOlkCFmWCpYIeZUDkTB7Q6rlkkq8O5fsRRB1YGS4GWEifmjcaxgzKC1iG5q0jBiHYQKPQXy2uMJmMfJoqTEyRzq3Z6xpYSTBZe6GfAQOzTtCk1DZGAlSUaZqZKRrs8AikKuQE+7RyCOJYWaP1HBvGmoeNFSaCN1JinhNQTm22N2RO1FexEX0yQ2HqZKhFY1uTGSUwQ0LS16FYPVWJL/WHETiErLUOkZ+SVhybNINOjI8CjFi70cWTpmSwpVkZiGvQsxJfqNUBGYtciZNwIzlVYgyyB+xjAbMDOWVDlVpgfLBjcygzdACP4FNVDoWgm6ogrAaRvybMRLMUF4VjZ4eS8RWEvLNnhwyDdU57ss+ODXl8uMR7rk9g/nz41dB8MZIk0O59sMzJTaiTIkWrIpWogIXGAIIdB+BlWaqBRHybhPYmkuWaNOge9OuWRTsCVbxBAG73ZuOghRZpeV+pYEqOz3sWcFilFch5tinGFaRyErQJqvCCdDLJaHj0wo8WprMUF7FUJ60RGDu5NV8CDJTiceNgjRQAg3RoynmjnXjSFIpzMAwGqnVc+BM85ve5VxgMYqLtVu3bgkJGNeuXWs2I9mUk0l3s3q2P8MzYdfW1kRKVgHKraPteczvHbbWDtbzRTSF14vNzJ+FREr8sKBCzp/FV8gYpqqr82tII8w6Uyfd1vXLvfJU9rLJMyOWrpG5IOXCmH3RLPtLJuRfLJB/wdg75YW+/7BWq+HlWt+cjlK/3AG0CQsG8oN5osprygOywNJBywT8ZYNJsNeCNTUlm08VL3SfpIvC8LDtLWTa+lKACjl3UCFnAG3VNNNMHZ8VfCjIlJRNnqJY9kZmVcuFgfYfAJCamXfK2Zn1hoElTDIAAFxwoGwtMRPaGcNGsCdFDmiPv1O1V08s9d6YtgMUkfL9xPG5NDPDVuPUclIs8EGFnC+okEXDG+rq0fZMM3V47IW2jlosi5RnNj2jZMkbmbLVkyJB+w8ASE1l96RkaxJmfjhL+ZIMAAAXndltIzBz2Os2ZlMDkAY8LGBZQF0FAJSBZW+LIP8C+bdP/om8WnL+9zP/IK8AANOBNnmxQH4wT1R5rf393/+9uNr7KR3t+pv/5wbZAwAAAAAAAADIwof+yyPyasnBqBAAAADIwekp7ey19tprr4n7/3D1SfZ3ib5hQsEPQErwsIBlAXUVAFAGlr0tgvwLRMxsXeppoSuQBABKBdrkxQL5wTxR5QVlKwCrDx4WsCygrgIAysCyt0WQf4EoTeXN//N/hclycenf/CsoWwEoFrTJiwXyg3miygsHZAEAAAAAAAAAAAAAAEABQNlaIMNWmtOQmas1fvQ6Hak8xenJyrsK0EWig6zMP8bEvLLGODcx0pcFAAAAAAAAAAAAAFhdoGwtjGGrQUeMzY3K7sn5yW5F3oFFgrIAAAAAAAAAAAAAAFC2FgRNaEyraq2u1+RVQSQGuAIxJmKNsSRiAAAAAAAAAAAAAICLAZStRTA87jcH5+NOKkVb5dJGbb0qbzzvemtNoJanizXpQ/ZXQjZkKJHL1NXS9VCAUXQHWjgMbUk86YulGUWt1sLrHnzD6WMUwncjaU+FFqIS0yrSjMRQRZajLAAAAAAAAAAAAADA6gJlaxHUe+e9urxOpt4LVpyP2kfr43PGuOO1q0p1yMwPvKtkTircUbu6thPc9huBO44eoBXlYNiqtjcGPCAZ8iEPathaa5x2uCDn+2eN9ogMGZPuZuBh3DltSHXk9DEyRu22x21CaY9HF4kk8vWdVpFmIYYqMgone1kAAAAAAAAAAAAAgJUFytYF09wXurnK7tVOrX+gplb65l7l8nYtfHt6M9UMzAiT6t55oBYOghoe94MY6ntqhu7wsD1qDnwPld39pqakTIUrRo4fdDjtcRgikURe/zhZokLFKKYsAAAAAAAAAAAAAMDKAWXrYmlu+RpAWoHujc7G4ia0Fr2gpemVCmkJ1YYBVTmDdXLzVI+B6xAJMvf6DemaQdvSZlMuOmLk6FHqaU9CzwzaIzWFREWKUVBZAAAAAAAAAAAAAICVA8rWCwVXN6oNA8YpNpmtSbeKjKvks8c4E0oiBgAAAAAAAAAAAABYZaBsXSzarMzQ/NJZMDzuk/LU15eOz8QEz/CETsP86Po0y+QdMXK0KCnt2iTfeHSRKMCNS4nq31mIAQAAAAAAAAAAAACACZSti2XU3hF7hE66O+2R2g10dihN5aS7SbsCcOpbTU9tVjpsBeZ7dJSUlFBMD015YL+GNUaOf7qUSHs6JacQSW4cO+ke9NNqR4sVAwAAAAAAAAAAAACACFC2zo5JdzNRN1nrbJ9VxTaiG4PgCKecJMVY7w2aozaPb616tD0eNOW8znrvfLAhLQ7WO03h3PMquyf8jH5uwZfhh3YRyB0jo9bpeHxD2Exp5yKdio1krR5tIhUvRiJpSh8AAAAAAAAAAAAArBRrr732mrj6D1efZH//9zP/IG7Lz9ra2vn5ubwBgkm3df1yb8r5scPW2sF6WK3qIl+Mk+4mKT1TxpGR9CKVRIzZg4cFLAuoqwCAMrDsbRHkXyD/9sk/YX/ZkOrm//m/wmS5uPRv/pVKgjABAEwJ2uTFAvnBPFHlhZmtq8X47FReZcHYH4CvzU+xD6okX4wzpSQilTBnAAAAAAAAAAAAAMAsgbJ1pRgee3m2fa33tM0Csq2mzxmjFVp5byXbcvxpRSqJGAAAAAAAAAAAAABg2cA2AgCsPnhYwLKAugoAKAPL3hZB/gWCbQQAACHQJi8WyA/miSovzGwFAAAAAAAAAAAAAACAAoCyFQAAAAAAAAAAAAAAAAoAylYAAAAAAAAAAAAAAAAogBVVttLx+q2hvLFBhyBlOe8oq3udyXCYz2MIJYM1dYUnWZEvuinJJO2yZ4iqIflEmnVZLB+Uj3E5ovI5dx1wkRigy0GyJKyYCxUVCPScz91Wq2fQUo5mwaV+WimkgKxFb6ktFLPAtMlqnoHkWr1oEiWMcZCqtvBcDBU4mZWyxZ51eamEq4iiFyESHRRFaQsFAAAAAAAsJ5jZOmPYCKF6cFPeABBBryGV3ZPzk92KuAE5mXR32huDXl3ezpUZlmC9N9ho78xQ23DRmU1bPWw1+vIyPaRYqh5tj88l447XrmZQBUUjZSE2Tjs8QB6YH1ZW81Uj9wObqbb0G1Dj2Umf/+gcAQAAAADAUrGiytbqek1erSLW1M0uyXOOLgcXPENKVRaLZ3jY9jp7C1G1zpj6XsdrH0JrU0LszyBNlgtrPVM8rcNWlVXhsaZZquyejDu1/kEaVbstUnooRs19EWBld7/p9Y95PcpqDvLQ7HROU5XdqlPmriqbbMPuJp94vtlKWa70WJoo/XuMFTFs+VPcN8Mq+xir/MwxafkpUkhC5aQlwKS4eNDF5T8A4AIyzzaNMQl6D8PbZNhlFjkWkcy944g0vKl8OZmf/CKLOaGOO+Qvi/ig3KyosrVyaaO2XpU3NEtIEqq614OKrdm43Us0Bw5/DLKgyS/tkTdqV1XTZfNLZq2utBCGmrOoDEbqfAxD9cRudlkDEgqCwtZaUuPWFm9idJonhvQngqXYJRSHLXh7pDoiNVq4Pr7rjBLauhGXDDbz/NFFQmMGeg0he/Zf/uNeCO5NeZABJCT/ojLpHvRr25eVmkrPMHvRh3BnvjUoMtQeXt231b1AtTx2gXSfqtoxSO2VTuO2Qogs7VpzzJZRwr3W8gQ5GFMiY+NJpCZHy3jyx25N7z48GOszODzuNwfn446hxEl+Wpk3z1d0BgQT+2LEYFgjndw89bRY61tSe5rVPA5NLL3OKlyZb5q7CssapA85DQLk/YVyrxWlHqJvb3h195uhVwXmK9xuRwkk8i7t7jtnpWueVYRCKmsdNiLTjF2YstnDCQcjog+k5U6FI1vsZBZqA6Pw8KKVPxRVTMOoXIqLTJljiiTDJkNN7Azd6KTbunn55ISmfZ/0Lh2Gs89BTUwUFwyaemQxVsNW43R7IKxP9ryutnNFjFVu5pm03BQtJKsJB+tXhcXVrTNjGn9SXMxv47RW3m8IAIDyM882jcFedaoH3v5YePeXAZL+dfPw5qW97cwN2tw7DnvDm7u7maP8w1b14GyLl814sH3aCL3rsNd3xWLWZ4KZ8JrPh/7LI+wni3gZYMLLqzj4oFPW3kFTXYqxqP84aI509yFj4Vp3EDLWni7lyjCP8RuYm86068BDPJRM3x1dS//Keyic4FaLS8+reCyhcY/8QtmIO/M2SJUfU8iYu9btozdazG6MtARBBP71YHXHurl+HY8jOlcsZKznC13rZpoLPYSQmwRY3surFSeUK0lFb8tE00zdxQQVshCeY93L8ANjzaNmqBsLwvcrSLiu8vzQs8nPHEdGCfd+JmmOslSGiFt1k4AeiCBqEk9W91ZCgRjJYfj3Wc2dUHy+C81xIIYRQuA6JKeycJk70J2zmGoMeUc2KiYVROA+uCIJtTD8Ksf9KYsglMBjPH7Cyb0ffZAZQXjGNb+0RGq45zfxIoRcBL71cLRr373pT93pvjQ33FiZp8IIMgjbj5TfmCI5XIadWsTTspsROBLhKAsbzF5e6bCRk4ycYMHot6mI8ROyYrLrEo47TWUZY+Vjlz+GeSYtBXPKfzNAI18T4mIGVMtCRSFQQ6pfvfW7ZfzpSQAAFMLi2zR+Gx9+TPyL7xMJZuRseCWOAMshf4CZhLgECTL36WChqPJa9T1bJ9ePRjV/TXG9Z34pULOHKpe3a97pzYknVk/62z3alk8aDriLkVrYu3FJTUaiaUiRrxJxfr3mlu86UYZ4jHlR9T0+oEhFbF7F4ky4mcPZM5xPN/M6Y2kfm4FOJtU9TaQgaoUr4fkKwhVdluwlX6Oj60JI7pHmauZL/sVifDbSqmNi0duwZ35sUMHDq4h3Lx+Eyu7VyOLw+FKuXNrwRmdjeXdx8HNEy7HYjLI0NZkqgz6Xk+qApYRnidaizgxX4rOaE4mNW1zmu7qPpP5UgwKUj8Xk5mlte3tDPsGq7BIbz9h+01KdskI1N7KXQGwXk9Rd2lJhwZaNsfEyeH5m64AKeULiGkaTDJmTtelOgqZ9a7AmOWuLzHLU01Zf6IStWEPE8kHMWZ0Mu4dH/aPr3CLWKi9zTVpeiheyvrXhV3YefFO2ZElxid3hsZEwAGAa5tmm8Xcd1X8WQ/Hya0St0jS8mbqbOcsfMGFlEZp+22/wtTZr6bczAMvAqitbTd2LiWOGuW5M23gZIyv+TKqHgUGb45ELerX3zR0z0J1+CVOYWBnioVg073xokY64vHITl/BQDodufZyJHbUb7ZE2WIzNQDeVCvlXK0Rp+adJTMJzFIQrukzZqw12WUst1X35kn+RSSx6K7bMjw3KVrHj3GsDfNare0a3nlTKGZuDFUHLYT/HMjSngmyVgdRtQgFFdWDOuta5lLCrMcpqTiQ2bq7Md3UfKfpTA3pmeXGJF9vdrSZ/qvjzS3UhsfEkB3otM/pNW3XKDkuTZS8BPWzj4bZEmrkLiMlGZ7yczB1QIVkU1zCaZMmcrE337IkZfEWs6FzEo0aVJN85vrSlV8sYq4WRJWkLI5rJe9tnO5ubm2x8u3l4tt9LJSVtrb2ogzgBACAgQ5vGesraet3fsbUkKr0MHUe6hnfO3U0G+QXihaR6sG4ojWmmgs/J1tlOmpdfsBSsurJ1FkQmhItnxX9KBv7oxvaYOPwuNakSnovmgGbVGxNc8mQgb9X8o7X5+oOZUkh0NErmg91A3UesYv2ZJfnKwpr5WYOaohqglFOSLaOylYivvqM6IJVAtMljlOjuktPhVDMx+dWelVFixXCp6LOa58eZ+a7uI2O3QrlGxTU+G5HWlyWA3c2r8UxbIkWccJcxFXl75yk6oPk8Jlbs4k3RFM+CSdc5LrNa1XsnXPDzEza+PDM+EcVYLYSsSVsIUUmGrZ2zrRMGy8eT3vpBqrqqK/cbfboq7MUXAADSk6lNo0/jR62D9au8QzzZS71D6ezI0nGkanjn3N1kkV8i3szG+2fu7qa+tSEmfIAVYNWVrTkGjXI+BycyYYcPhDUHFsQzRErC0GOSwq9PrAzxhIfq5D0d0w6wnQlPwJlYmnVS7w2aIzkdKEMG6tA8fTbO8keF0QyJSXiOgnBFlzV761s02B2Sqkes+MiZ/ItMYtG7iGR+5qDi3GvVgF4cjNlVSaWcshauGFqLRjlGys/Mj0PWEhTa1m6ga/X4KuwIfoCFwSfVRpZQ08lvouRziBHqFVhWiFmEWc1dJDZuyZnv6j7Sdiu08cPpze5xXySAF97hma8nTKwtoRQnVw+d1CVSEXsJ3JS3hC5V0sOdmAo3kWxMjDd3B5T/MYlrGBNxipf1wU+CRaTXFCZpJkEn7jkwMVYCSsr2ZXljEmOVngUmLT2FC0l1TQtBDz4mLr2as+eqOYjb5wQAAFzMs03jPbu3fnWXr/hgcVPHy6/yM8+OI03Dm7W7WVjHV6n39jem/QAPloFVV7by1XB+VeYzLuK/4dA4V3PPhrehMaZwoNYC0pwJ/l2CLrSgqanjTyt7iNUYzuU3RKIM8dCgUw3Vhy1aS2fCRfIHJbT5iRx7ZM0rgSvhKUlOrJZrKTMwipbcTUuGOBKeuyCs0bli0WuIAXWJtJGCijR38i8QQuWiZUp80TuJZD4ja1BO96oQ+dMX2j0pvpSzPl+rQr8hnhaRY7xQcjwOCe1A6EnkCru2WQfmAqnkvHZVL3Z++n0z/5pVvVfQm7Ks5g7S9B3WzHd1Hy7zGPgj2/Y3wKLC7PdJ/yQersTaoqeYWSc+4M52Ox6+l0DbDzxrF5O1zruyMVW8PEPn2gGpwG0NYyIx4uXsBRywiE6P5dH/k+Hh0UZIUIqZ4g4yXidm8GW1msj0sGA3G6cdNkaW97FWOZlv0nJStJD0KJ+N/byc3PSaQVOTFBcAAEzLPNs0isw7kr0/i+34dOOSuM5PyTqOzL7mKD8LarMlo2JxtQ6CTVtZP067OnC7yZDeVeLfB8Ey8ZrP0p07yYSXVwloy8bUOW9kRrMdJMZtonvNgR7IgJ9gLAnMpbEMyubXCFyQKIPAYsRRotQ6Hf8kXt2tETxzrMKwxRvgiM6a8JDbuFtbpFEH8k5zrAcoMbwpNAGZJd1RPNEoBEbCXeaCLNER9tCke2YSCo9bmNFqIVhidsJcy6uVh2VaOAsFWlmofLYXICeS+QlBCbTbOPf0VHJUBEY4dOOjBR6JbSVhaZZXAleOEbaMCuWRdptYgtKBUShmhImEYmdETSROC4EmLSPGoQ1b2EGAZpKymMfITFYSIwOlcy05zITupCvNwkimy9wN+QgcmneEJqGyMRKkonT0m4xoisxMi0CuQk64RyOPJIaZPVLDvWmoedBQaSJ0JyniNQXl2GJ3R+5EeQldxDSM0QuBcUs3PoEbLQ+YoV8ioXBsMA/yKgQLRERUaw4iIYjoah0j4yQsUlecVqsgolozFGCMlQ+zlFfpmVvSUsDiklchihZShUf+QtaxcVGA3JJhPinnakgVOuV/WX56EgAAhcAaCnkVYp5tGgVosxTRaER9MkN5FaJo+Yl4Kx4bI9Twxvkqh/yDTpD7TdPesLL0N7n6dLA4VHmtvfbaa7xcvf9w9Un2938/8w/itvysra2JlFxoJt3W9cu9mI/tw9bawfo4zRq+NCRGt3DmLGH5M4RzkR6WYmt8qaAJjmf7K75cMVxXKdFH2wsp0Fnn95K0HgbLKHMOlq4VuSDlMl+Wvd+E/Avk3z75J+wvG1Ld/D//V5gsF5f+zb9SSRAmAIApQZu8WCA/mCeqvHBA1pIzPjuVVz40310t7uMrBAvc4jEaXdmYs4Tlz5ALB62R8VfIrhbDw7bX2cOyknlB2y3NNL+XsfVY1RZvpv3mHEBPBAAAAAAAQJmAsnW5GR574T2k6r0xbfi3xqm2N4rct98SXcmYs4Tlz5ALCD+FRu7xuUIMW8VsywdSMKF9R6tH2zPN72VsPRYpMy8UG0XsHDrLfnMOoCcCAAAAAACgVGAbAQBWHzwsYFlAXQUAlIFlb4sg/wLBNgIAgBBokxcL5AfzRJUXZrYCAAAAAAAAAAAAAABAAUDZCgAAAAAAAAAAAAAAAAUAZSsAAAAAAAAAAAAAAAAUAJStFwE6WCTuvCCy52eMqIuiSAzQ5SBZkmGrWFEBAAAAAAAAAAAAAJgOKFtXn0l3p70xWMzRypXdk/OT2RySXO8NNto7ULcCAAAAAAAAys6wtRY7/yUTQWBJwRYWbaHyu5hdJHMRHwAAfKZWttIMxIA0Uw3Jh9bOaQGg9ZsFw8O219lbiKp1xtT3Ol77EJUGAAAAAACUnDe/+am7PnA3/33quV9LQ8XLu8JK/ciN1dB0/Fcvc++e99Zzn1CGd/+3G2SUwrtFkoWjjy5TLmNLMZ4UTsqzLC40Is5Fbb0qr3RsKbW7LCuzk3a58gGABRHfotJnixCtodVQepA+ZKOU3qUuB0O6shoSmoUIwOlybkynbGWZUW1vDM4l447Xrmbsw4aHR9tj7nvQ7DcWkQWrzaR70K9tX1ZzS80ql6KwyIPujAfAy8kaFBm2utKmNdR9W90LrvuPnF0g3adeRSq7+83+gdULAAAAAAAA5eDNb37qj7/0y0+/8Ku3fvetT3u//Op9SkkqeajLrMSPOWBc+tCH7YYsqL/49n1f+eWv3vrllz/qff8vPnH1TdKfPvLVn3ND7vJ7j1L4Vu8v79594zI3JO8WSRYLjS79wSEbXG4fpVjGNmxV216H+6HxZHQ4QeP3HW+/U5P3K0F13ZIca0qtLkvL7KRdrnwAYFEktaj1Hln5DJqe19yqWw2F+2GrcdpsqqcvvUtOUykbtZXaUcNJd1PrOoKl1Vbvc2MaZSvX43XGgdiV3ZNBcyTnGrL0soIRummGKCTSmlXbI6/f8I3qPT8rqP07vZnYnYIsTK4fjTRdKz05Sjk+7tT8woqhcnm7Njq67pcLD5AmysYE1W+f7XNjvUbHuB+1j9b5g8G19WGFOz04yue4c2o876zSaMIBAAAAAABQNt76Xz/4ped98pFH2PW/e+Sz7O/3b/DJp1He/OY3v+d5H33qPz0kDQjNUARFalPvww9e+Zjn/Xz4v3791m/ekC49764qMzTRw3yo+6v/TmL43r2bvynP5FY21O43B8E4mQ0uk/cjGx73vea+cFbfY4OMszE3D6DB/clumjmN1gGsgIaxPmq4QobanC7NveY8MpuI7PQRMfkPHJGtHnEW0qc0QJNURauZRcWncnIJbPXInG92uyKTLKG5sAimGQUBqewXCAurSwBAIsktqobQCIZWURuGdNPc31vnN2HSu0yAL+a+mthbzJsplK0hPZ6gvtUMNKajdvXA1KLRFp7jTk1omM2+k2VQNDgwJeOzkbdxyc/USXVP04CSGjWFetvQtqpCjw1KfZwIiHcvn+bK7tVOLTRVlepFU+04S3NZdQ1x5dKGF/v8AwAAAAAAsFDeGv9cXjE+dPd98sqC0KXed+VP7pIGhG6oB3XXh+6RF4//1096fJrqc9/84ld/HtLVWsNkiKC43rYcTG6e2oYRYW0aQ1NGkidzdfh0s3eiA1hCnzYSmvzRb0j3waQj5nzHuyodhwc3NKAxR8Q0gO4fy/GNGm3FppoHkqyI5sS6FId7cFH90fkkPNMloq60CxyXS6N22+MWvXrKdFkEs+YqzYUTk/BkltKw0eoyfY4BcHHJ1KJyVY1U5Sh0w/jTg9K45N+kws1E2JCE9o52hKHxgcXqfW5MuWdroMfTCJRf6ssk6chcxSQbXPM7JpgFlQrlr+rh6ItqCjRta9CZxgVl2w0nzr32UhVRnvIHx39GiEbfeOAxHxoAAAAAAKwGN/7fr/7c8z5W//e6AtQwFBNXxXRUbULrI3/91guf9Lzvf/VLNIX2//M5Ta9qDZN2HvjL6BTaxUKzRGyYy04J56CRxhJTYhnAmrO3+OSPYGmdcq9NOgrWbvKBVNLMEE15SaMtoX3IkOopUXpTDpfAmOkSHWyFBBbDw4Rc8kPMkC5TMGuu0lhRaiSo7PPlPwDATnyLyifBhr+PaYYJB7UnuqTvUgLt05fNkPcd28EHFrE7qdX7XJlS2WpVc7l2nna0c36DO14/wDT/GcOVnf7XP6qI0jwe1VdqHy4zB5Uvak5NelLM6k0DAAAAAACARfHy9e+zv5/+rzt/IO45puFdj/fEXqt33/WBR0iLyqEzrx79/kefuiFUrn8RHJxlD5Nv/Op5n/3WD3S17ArA52kUiRrAjtpVmvfBockf8QSr2FPNbqHFulyzyDWdlsm9M6Oye8InrzLk1K+wypt2bYuM4pW2NVAOc7LlUhxRway5qmlYSXPjzwTLmP8AACtxLar5eUWiGSaoWtO7ZPCvPqGvLyFD/+EPraHmWL3PgSmUrZFJiITeyIVJOP7Pli2gUFjpkOLS11W6vh5HYf3p6Oj6UOtMswYV514rdHqcjXrCa1nwUTQCBeSqcAAAAAAAACwcYx/V3/yKFvVXo4v3f331f3yb/RNbu/pEDT+88wN57NWNr1Cwlz704X+6wdx87Mv/38/d5T3y19/R94S1hnnjr/74S7/0Pvutt7r/TpqUA22+pIFaG6fQloRGh6SFDg3UwCQ4Z4UTO/fDXE6fZooJDYRZ0nVda2yqi0RO/xpsiKlf4XOk2GjLMoqX6uGwcjhFLqVPV0gwa67S4FFqeGmdrFDXZM9/AIAgdYuauIUAKWr8Fcr00YMe1OBhT++SE1ETEcowcbWz1fvsmWZmK29j9R1rJt3Nhq+e5ihbrreWUyIJlRXMiz+Zldpq6M0Kht5ZjHqnFJe8sPhVGkjb2m6wB0LrTLMG5XQ/astzRumbRviR5bsy+w6o7zQ65AU9NgAAAAAAAKTkrn//Z/f5ClChGOWL+m/81V0fuPuu3X8Sjt78h+Ev2L/PfsI4GstmKOH7A/B9ALgy9+e//g2Zir0FpDLX4p1F+uj3S6hpJcKjSzZooJv4hee6ipaP3/lwhXlNWDNJowqbA8sAlqtCwzuvpoMkkpcR9EEaj6JR1UZbM9hGwJVkjq9kFZKoEXpoFK8QebKj6VpT5lLmdIW1v4wgV8dno0DBa5kZF5f/AIAo6VpUahkiWwiYhvqjTh899Kl3aVyOW0FfQILwhmhoM+SNj69s8k3tLufLVNsI0Ncm+tQklNBra9Wj7SADieZg/4zb0scl34JnBXmi1LMbsTyA3HidcdzkYZAD0pKqiaH1Hm3cLsqLCmvQjM5NdkAPHStQ9TxlDSrOfa2zHVSTSC/J15B4fi2jjQiCKkYK+kU8NgAAAAAAAKTlDz73P7/zWe97j9591wf+8nveJ7/zI2NRP0ceY/WV/6zrQC2Gb37zU6SiZT++bwDfB0DsLfD9vyDzR7768/u+8sv/+TgpW6Pe33rub2hXAe/bfykD+cDdf/bNt7hVGTDf+2nQkOJ86XrPX2/ORwrR4aSYS+lPmEqaIWobwJJc20e+WIz4IGjgI+dpHax3aBAVwRgR+wbsX1h7kY1sKSWED4KSy/OOJVaJz8dt+vA+gKdgpE/FyZhL8UQFs+YqM/SkqISIMUX+AwAcJLaoDK69DG8hYDW0ksplfSvQNColkNWQGp+rfs/hHwXlcDlX1l577TVx9R+uPsn+/u9n/kHcTs2ku1k927d9YCoIlmvn5+fyBjhhPdXB+kIq18yZeR1bGfCwgGUBdRUAUAaWvS2C/Avk3z75J+wvG1Ld/D//V5gsBZf+zb+SVxcE+zBioYMLNmhreNGJJ4WxiiMnSpOmDi7tuBdt8mKB/GCeqPKa8oAsUH7qex2vfehaMLLMDA/bXqpPJwAAAAAAAIAY/u2TfxL6SYtVZHL9qGzDCDr6ZLp5rfGUMMnTYx7fQRvMAQBASYCydfWhSdWnauOdlWHYapx2UqwsAgAAAAAAAABFZfekZPMfZ61rLWGSC0Bb8Mxw73kAAABzZ3bbCMwc1qBiNjUAacDDApYF1FUAQBlY9rYI8i8QMSF0iYZUiuhU1mVMBQAlBG3yYoH8YJ6o8lr7+7//e3G191M6IP43/w+dkgkAAAAAAAAAIBMf+i+PyKul4n8/8w9RZSsGhgAAAEBWTk9pT5O1W7duiXvGtWvXms2lOa8PCn4AUoKHBSwLqKsAgDKw7G0R5F8gS7rVqVXZipmtABQC2uTFAvnBPFHlBWUrAKsPHhawLKCuAgDKwLK3RZB/sSyp/FC2AjAj0KYtFsgP5okqLyhbAVh98LCAZQF1FQBQBpa9LYL8iwXyAwB00CYsFsgP5okqr98T9wAAAAAAAAAAAAAAAACmAcrWrAxba5vdibxxM+lutobyOhcsgPiIYhxMhkNhnhgIS83adHKGSAyw8BjzpXFuYijzwmMEAAAAAAAAAAAAACUDytZsDFuNvryMZXL9bHuvLm9yUdk9OT/Zrci7DEy6m9WDm+K6sru/NNtCrCi5yxEAAAAAAAAAAAAALBtQtqaHpiamU7USp+2duOmWc2Jy83TjUoymr7pek1cFkRhg4TEmYo2xJGIAAAAAAAAAAAAAgBUCytbUDI/7zcH5uJNKZSbnM5pry0lbG6wk15aVkzMf397wyn0Sm90hM9dWo1/3bYRPmtbaHnmjdpV7TpxgW7m0UVuvimtdCopJqYpdsdvE1gO0khijSHg3iDOLyloLUYlpFWlGYoSKgyHCYZ4TcwYAAAAAAAAAAAAALDlQtqam3jvvZd0YoHJ5uzY6ui70dMPjfq1WO70p7iY3T73mFgtwQvrRjcE5Z9w5bYT1esPWWuO0M+b2+2eN9kiaM0bto3VhMe7U+o3WsLJ7QurgGnNOa9cru72EFez1nlzjPmwFUlBoo/Yh1xa6YneJrQJ0kRgjY9Rue9xm3PHaVaU2TUAXiSTy9Z1WkWYhRqQ4pLkgMWcAAAAAAAAAAAAAwHIDZets4drWszFdTm6e1ra3N6TudXL9aMR1rcPD9qg58NW4tMmqpu0jhsd9r7kv1XT1PXNmrbKgiDxfkZuDSXXvPFAmB6G5Yk8UOxFXjBw/6Mru1U6tf5BqWqkhEt+ttn+cLFGhYhRWHAAAAAAAAAAAAABgCYGydcaQ1o3r/CbXj7zty7tbTa57JV0rX1ROE1y9fkOsPCdoV1hdS0cOtOXnXIunKG5deqVCWkK1YQDtRUC4Yk8UOxlHjBw9yksbnlRXJ6PnB+2RmkKiIsUorjgAAAAAAAAAAAAAwBICZeusIS0daVvHZyM6qqq6TrpXrmvdvixmQfJF/waLWG7O1Y1qwwDaiyCJacXOHuNMKIkYAAAAAAAAAAAAAGDpgbJ15tS3mt7pze5xn+8aIGa6Hp75ulY+Y9Lf1dVGeErl+EybelkctKFsR2z0SvixuGJPFDsZR4wcLUqaQ8tzLg26SBQgqbcTmIUYAAAAAAAAAAAAAOBCAmXr7KlvNUftdl+uMeczXft9Na+V9kEdtXf87UBpnqV5QhYpa9V2ocMWrdePJawfTY3SVE66myoWV+yJYqfBGiPHP11q0t1pi71tkxEiyY1jJ92DflrtaLFiLBMswf4pYtNAwWQv/bRQ6CECmaVlKBF8trKQKJ9suq/JcKiqx+ySmRh4jAMlYYFQFiZVjTRuAAAAAAAAAACACwaUrVOSRgFDCksv0K4ad55X2T3hh92TzkisZw8tx6/3zgcb0v5gvcN8x8P1o42QGiRJznpv0BzJSKpH2+NBU2psXbEnip07Rkat0/H4hrDV9sYgOL4qAS7SqdhI1urRJlLxYiSSps7MA1Ihb6hDzkqNsWXFoMmqt6nkMzfn5TsKTwWrSmKyMyur6sFNaTpLVIxZmZuEAAAAAAAAAAAASAGUrRkJ60RS6UjqPX1DU/OOoEB8fBsjYPIibS958hymUMzarXRtaNHoPP0NeW1HxcFloDs/AFvshE3sgGli9LzLvl2iLtDIB00ki0e7SDMQQ7sNmRPJOTMXhodtr7OXlK4SQlOYDfVqs7mhb2kxuX600Uz8JgEAAAAAAAAAAABQPFC2lh5jhT5fHZ9iJ1IL47M80/2miT1fjDOlJCKVQAwqSzW/mubatrrsDyHmjJKRjz+LVEzJ7dIafcI6O1f3ZzjRLCJzrn3M6arp2drStK2T60fe+rq8sSGS4TvnWw6oiOXKeOFk2N2stkceTXwO3F/3k28RN0XIhC3Jhlfuk+Ay6PGEYme+ohIq9HhUWYiIKFiJFroWr3OurM0NhemuPyoCEXV8/QEAAAAAAAAAAJYcKFtLT72nLdfPv559eOztR2afJjNF7DljtGKqjTSyKWymFakkYhTA5PqRf0abpN8+2/cn8bJ08rLm0NYMQfpG7bbHLXi90BR1nGEr8MdcqD109QBpFwDfX0xEbviU3KtGBlbXPX/vB9K1bl++JG6s0CF1ap9eOiCtVvPnyZrnoFVpX4oa38PAn5w8ah+tix0NmE2QDkmakBOTPGyt0a4c3H7/rNHWT2wLx16JSqhwlQVj1D7wrvrmfirMeNvWvaFj3LjqD9/ZI8in+PoDAAAAAAAAAAAsPVC2LgHa2vgU69kd1Hs5feaOPWeMlnX3ISF0Ii5jySBSScSYFeOzUXiOcqBkHB62R021mWtld7+pKep8C9oMoabOThNMqntaHSHVo1juz1W7/pYF2kYNsRHp+Lvqchr9YFtdCYvq9Fh4HJ95hhLZAteJihAmN09r29sbUkNKciacg9b01eRB6jSSQ05M8vC4H0TCd0zQiI/dwFUWHEs4sfFK4mWz1x9KoteXhcOIqz8AAAAAAAAAAMDyA2UrAIAR7MXLz5eiI9Z8Gv3gCKrAmVe5tBHSelYqpIdTC81phTvHotolYiMyMA7IOh/QCXDmhFAmi1DoDY/7yRtdkIqROxfTYHe3mjwdXCccpM9GgnViyIlJJgd6HpMyVJEUu46rLAhLOLHxSjLIpt9V1zU9r+4/Un8AAAAAAAAAAIDlB8pWAEAEU7vJSDd3l+v21EJzWuGeRJ6I6r1BM6ymq281SaE3PO4nTE3lkJ6PdKLjsxGpZqvrpCHlGtGkWbFJpAg5Z95mJXtZAAAAAAAAAAAAYGqgbAUAGPAZh8GBUyaajpMmOpqazeFxX98+lCa0coy5jQGxEWWlTodkddPpWrlulknkOxfzUQ/Ppte1JoWcmGTuQNMjqzzMiqssHKSJN4NsehrJmZptHFt/AAAAAAAAAACA5WcllK00hSv2pJUJPwU7vU4nq3udyXBYiPJIyRCXOnJUwBkz06Q3GQo9RCCztAwlgk/KExLlk033pUpkpslMDDzGQVF1RifhoRAqQUestBvnqL3jC0tBBZL75ylNujttywanSsvG0ktL5DmkclRbk1JGSNFiI3Iz6R701Rawiuq61273zdXsblgGjALnpEbs9/tRXWtYv5iC+JATk0wlo7YyHbZUHrqIkdBaFi54vP6JX45407hhiDSq4j7o6zrVhPoDAAAAAAAAAAAsOZjZWiiT7mb14Ka8mTmkrthQZ+2UGmPlNB1HH1IEmno/mvI2Hep4q7mViPVArTTMt84oSCXonGHJEsMPiyc9uFiKrpJW63Q8vuUoP24+VPlofb9/llX1aHusVvvzAE/FVqW6x5iIDIwDsnjQUXd8C9H0U1NJcRg4N+80hH4xVnEdJj7kxCTXe+eDDWl/sN5hvuNxSOgsCxcULz2ZhCveNG4YruJmxNYfAAAAAAAAAABg+Vm7deuWvPS8a9euNZuJY/uywMbr5+fndEXqqrP9mIE7ObDqZxxkda/I7TGKCspzpW7YWjtYLzau6YOyEA1dM6HL9kazebq+pxwws8Ozjf4pT9yUsunepwxqSlyxz0gqVjsantJmBQ9LQPb6s9gMvJgU95QvnnT1x1ZXAQBg3ix7WwT5FwvkBwDooE1YLJAfzBNVXisxs7VyaSNYPMwG9Cx1nNBUr+u0Nl2g2bjdSzQHDn8MsiBVQnvEJ+H5C4Ntfsms1ZUWwlBzFpXBSF0AX0rtz5eLD9OIerPb9fPBumJb92c4cQlpiygrW7Tfph8TneO+vi5vbIhk+M5pIXYQMd2xG+FkGC0RVzUQpAiZsCXZ8Mp9ElwGPZ5Q7MxXVEKFHo8qCxERBSvRQtfiTZ4rW9/reP5ab1AaqAxVXeBr8NV+pwAAAAAAAAAAACg9q7GNQL0nJ0tx3dXG4Jyg5a6aHmrUPlpX53IH+wYG7vm6V80DR3fAXQg1CBkfbauV8cLrmNbO1viKeS6Owy/Rb5/tc+NePVkGlTqd6MnprjBDUY/abY9b8LXM4biGrcAfc6F2XtQD1DM2JiI3w8O217lqpKm67vlLnEnXun35krixwncA9ZWzdA5QreZvQ2CeuVMNlQjDWg0UaUJOTPKwtabOgN8/a7S1Q4QisfP11qaECldZMEbtA++qb+6nwoy3nbRHJy32vsrED1cBsFjqPW2XAV4D3FP2AQAAAAAAAAAAUDZWa89WroH0D86p97jeUdHcl9osvrcj16END9ujpr/paWV3v+n1jw3Vk+GAuwg0Xtp8s8ruiRkXEedXUwgmymDHOOFb4AgzErW0IFVbTZ3EI5hU97SEBBnlytjYiHSMPTcbfS+8eySL6lQme3zmWbbONOA6URHC5OZpbXt7Q2pISc6EM3cs1UAjOeTEJA+P+0EkdFQQv5DEx27gKguOrTLHxeuAKq6KIhlyblH8g2LhzYlPhuIpPag/AAAAAAAAAAAuAKulbLVoIBWOU8p14+p6SP/FD2qSx8Fw6PhtckE6Nt/cMTPQ6ZcwhYmVITVBKGmjjp5jXqlQ5qnF6LTCnePI2NiIDIwDss4HdKKPOSGUySKUzMPjfvKyaVIxcudiGuzuVpOng+uEjayNkGCdGHJiksmBnsekDFUkxa7jKgvCEk5svAAAAAAAAAAAAABgHqyWsnUWmGpChpiaRdM7CXU2t03n6vA7D3JGzXV7ajE6rXBPIk9EdFB6eHJrfatJOsvhcT9haiqH9MSkEx2fjUg1W10nDSnXiCbNik0iRchzKtbsZQEAAAAAAAAAAAAAFspqKVtzTAtVO3QyIvM3+dRPzYEFoXSlqZp8XmZACr8+sTLkIDZqTcdJkyFNzSZtU9oJtg8lYTiOjM2QxmTqdEhWN52uletmmUS+czEf9fBsel1rUsiJSeYOND2yysOsuMrCQWHxAgAAAAAAAAAAAIC8rJaylTRjagfNCZ3XHn/6D+1sqbk/6Id0j9LBjr/gneYa8tXvdKEFrZZw6xovl98QiTLYESpBh84vNurgcLCdtmWDU6VJZPlHS+Q5roxNmcYwlEy1Bayiuu612/20K+1ZBowC55Tx/X4/qmsN6yBTEB9yYpKpZNRWuMOWykMXMRJay8IFj9c/7ipFvMmEajnHZmZAtSO2DsQ4mAyHMR5LS2KSGSppaRwnkimQQmLUoPCIIsMsF3qO5a6T6kmx5D+z00wSnykfP+cFGfKfYhAkeDIFy0rRNa14EiWMcZCqJvCcDhVm6vKdN7MuL5VwFVH0IkSig6IobaEAAAAAAIBVYcW2EajQ4e6nYl1/moO8E91zB+pscFrTzWca1nvnAy/YuLN6tC3MpcZLvMY7/IbJKrOEVILOGZYxUdc6HSG5LS5a3++fZUWJUqv9XUKmTKN5QJaWXzp8m9H0U1MpqwPn5p2GXiIpiQ85MclUOTak/cF6h/mOxyGhsyxcULz+phZp4p0NLHvybavARtfVg5vyZrXQk5Y7f3QKCSQn4oS483nuibIwZlMnc30JIeUTNQO0kIIQbVCaVo35pFZKeXL7KeQTTamZT+ukvnmBEOnzf5FNHAAAAAAAAEVwS6PXkxuRLgVMeHl1QRk0o7uHxkP7fmb0AqYkeynNglwPCxPd42o1DZtZNlyVcHkrZ6Lki01asbHPPi2Lb9hVGqdJLPnlT4oRCD0/HC1Y5dINeYsIkk4684l1Pr82wbIyTXaVBFcS0iaN52+nU9PdOvN80cy6vCj86CPAmTafp0bJFgt7HuRVmAErY/64NFNKqx4whYo+xooYNP3t2mu6eYIvDjOUV2HmKD8xDhKh2Y0HHd/YSJqCWcirMHOTP2RpE5M7ySj/crDs8gNQNtzP1JzatNjmzucitmml6FOm6BNzsIjXmEhcriTHBxi8UkSFd7wyMdy+4gplGlhY4gIHZC0v9b2O5y/tB6WB1ieq9Y98X4hp9+AtLTTbzsefy0VmKvl8US2x2R0yc22+13XfRvikiWPtEZ8AbVk7qsejr4Q2zR2zyTRHhgubOZm1utKiNQzd+i58bBHq9kJUZqInjRyoFGiuDRlEdkks0eiBaGEwbDLpRGPUw5IlpgIJr7Vlbv206N4lyiWZhfKtUITI3aByaTVGk0dFLdxbs1R3HgppbBRcKCt4Eoch7z48mMqljeiWKHT+34ArejSsLg2YN6+5H57nF0z+ixFDbXEj4NPoQ9uLE1bB4tCitJawK2NNc1dBWIP0IadBgM4aq4fo2xteuU8iY+tkiuoTSORd2t3fCHaaMdE8qwiFVPZHXo9MM3ZhymYPJxyMiD6QljsVjmyxk1mokYzCw4tW7FBUKp/16AXKpbjIlDmmSDJsMtTETn7oYph0Wzcvn5zQG/RJ79JhOEMdGEpk9s6vRR9jNWw1TrcHwvpkz+tqe1nE+IpnnvIz2INWPfD2x8KNWk01bFUPzrauktl4sH3aiFYCF3OWXx93RdadsXrVOBUjVgAAyMU827T45u5itmnl6FPy94k5mGOSWY06WOfJOj+/unWmL6+LS3JcgDvsvYjbjvfXj6q6L/crU5wvRmxHPz1yUisHM1uXjXTTMxRzmzZysTFUFhmKZ4YwQeRVBuhTT1j8wIyn0rcOalZwRU792ia+GnHXInd8iyCUwGMIQwyn+8BCRzfVw9HNtWt+GYQSujV88RsRf3CVQlTTm+9au+aXhvMgSB8ViLoQWF0HbnTr4FoPgyWgxtAid4cmb6IBisuIz7Qwr/LKhQhfjywqg7jR0q2k1hwllVcQhMWtuklAD0QQNYknq3sdQ2xG+N4gbUTkzg9FCzDwnpSxAmXhMnegO2cx2WqsEUTgPrgiCbUw/OrE/SmLIJTAYzx+wsm9H32QGUF4xjW/tERquOc38SKEXAS+9XC0a9+96U/d6b40N9xYmafCCDII24+U35giOVyGnVrE07KbETgS4SiLdDAf8kqHvfVLcQgWsH6bihg/ISuWGl3mccc+BcUR4OLl5ylIE34ooYISyG+VS8FcU+pcjuzyLw/LLj8AZaMMbXKAxepCtmkl6lMCMvSJOZjva4x550y/08oMkIWnOzN8hYLQXpnifIW9FYYqL8xsXWpoblMGDTz2QZsLlM2KGXwgmSdyD1iF2tRRbN3pp66yu99UJ6gJjNl4dKwYv5AoC75Rr/OkN2JS3dNy0XSvzRnmmR7O7Mn1o5E6ia3eUw4M4Ul2fbZf6NC44DYxyXGiRoiXIX3+JGaCwhEjRSF3A57cPK1tb2/IzaAp92JP68uSjYXjR1zZvdqpiRPpYgvIkqWZykufE5qYM8VT5PT4+PqUjOuxUuR5ZlNXYxFgfI1NfFSLap1cUK089Y9J9Mn6yCemwoItG2PjZfD8VIcxUuHSFuXxT1MRtd9PsvYIO8iQObEPdSFi02RxjcqljfjN1KOwPPYs+8sTYSvW7LCcEXMzJsPu4VH/6Dq3MIgJMMpc5edz5v3SczNhzkJzf5zMV36GegnabJl1lA6Z3RjglRoAMA1zb9MkUauL2aaVp08JyNIn5mDOrzEbwQlDLOZm+Hh0gTvJoQDrvRP1jkfvGKeaL/crU5wvIkWhTAGUrQAAJ+FvPQM+CYy3l6YmlrSwulqCHGhNGR/0KrJ0IZUKtbBqyS+t5xXmbHjtC+BaADE+G7m0VLoI1XVtQB6SLbhNTLJTVBdpZXCTJhN0rDFS2XDti+jQdreavNdld6NEQaZPQk608NlrgkcSxxaQTZ5s5UUqOaGkopyZs67VrGhTMq3iNuaxEmR9ZrNW46QaO7/WyQ1Lk2UvAT3spOclucEJEZONzng5lH5NX811rZmfpsxoj5D/CDvIkjlxD3UhYheAe5AStar3BhtHDX5Q5s7xpS29ogbEBDgLMsjPyqm2Xh+2xPYNlkGMKKnqwfocB/jZ8l+++jBOts52ggdr2KKzYrXRGwAALIQsbVpA2AptWl6K6VMEi+gTc5ApyXvbZzubm5vsFWDz8Gy/F/aWlGR3XLRDgbev+0rzymTzJUuEYSuUqYGyFQCQi8gKgtn0DLwZ9s9Tp9UE0ly1jgNfw1B48xghIclOUWdHEZlAqg7SXY3PRqRDq66TJktpXZaKbHUyW3n5Kj5N18q6bJ7pJkVvtORURTH5eVwxYkQ1a/Mg8zObsRqnqLGza53SFnoRm6pnTEXe1oDUtFzbmj0P5/MIWLGLt4BGOBuTbszAwWJV753wpJzTtIwzywehmABnQSb56cPMUetg/SovjpO9yNZwosqO988O5lJnGFnzX6O+tUHNDkdX9zf6dJWj6wUAgGnJ16ZFrNCm5aSgPkUy/z4xB5mSPGztnG2dMNhLzElvPZqu+CS74poMW5s73lV9vion/pXJ5UvDUihTA2UrACAzXP8TLAyIElYQ0aArF7SwgA2c/WG+JRzRTg/Ci2MZMZomXXgKM3m2X2KSU4hqkl0GN+5M0HHESEvkT292j/tchyiUiodnaXStRSYhE1rdojdEEjy5gEJkLS+RMd1A1+rxldoRLCqp6eCTaiPLrIPT92LECD2HLMnTr6VOVODmf2bTVeOkGjvb1il1oVfEXgI35S2R5XnJXJ8DItmYGC/LUOZmSHVbLPpOG3v+R0CrQvQIZ5t26hQv60OdHRa1Xnf43M0Mok9iJmnEzBXhUOK2L8sbn0RfIeYqP9Urb/3qLp9vzOKmYudXJpV6b38j5ZeJBea/jl7x2ZPWHMTtfAIAAC4W0qZFrS5sm1aSPsUgS5+Yg3kmmQXuaYGbMWs4kmyNi6tMj7euJrxqhl6ZUvqaBVC2atCUiMI/5NgCTYyIZovEftOIcTAZaufVLg+JSWaopKVxnEimQAqJUYPCI4oMc66Q/mcULJOlKm2mhdQhSkE0bNEqz1hY22+fvqdpCliuqXBCDxE155HOgi+P9dtunuXChxBemR+kU0AlJplhFdWatHwyhEiTCYqYGGlI3G772+WQvP0+9VHxHVIhSchLvyESTntMSeVnmgIKYS0vRbjguFKv7Uc3R0ht57X1wzOZvFV900on+nNYUBm5HiudTM9spmosiK+xiTWhwNYpDr6XQNsPPOvzkrU+u7IxVbw8Qxta3c7xNGVDBS4e4eSNPQ1ixIt/qKeHRX167L+KDA+PNkKikywkTVAUOjGDL6vVRKaQBbvZOO1cjWRTTIB25io/i8w7knWPxXZ8unFJXLNYNlv+uyobAx2k3qBujvKzPKetD3hckyFVp7m3/QCAVWe+fYogxurCUY4+JX+fmIM5Jplen8/GMl3sxdRrqmSlSbI1D7nKtFfnxiwQfQjiemWK8TWPjv6WRq/H50MsCUx4eVUUA/0Y26KwBTp9RLQ4juZvhHGZl59EyRebtIJjn0lViyHXw5JYdSlTfPzMMTKKXEvbju8xlJParXQdyRcVCo9Fk0CzsKwplWhCGiHbzN2y+Wi+lJXmzCWqNGc3RphaaBlkMA0TMyExRg4FE/g273TC8tgCDLvJBgtJXrkQ4VON4hgJ0eRRMoTk0W61zGMmdEeBRR0YSQvlXBKh2BlRE4nTQqBJy4hxGCbwGIhuiytsFiMPWUmMzJHO7RlrWhhJcJm7IR+BQ/OO0CRUNkaCVJRTtU4m5CrkhHs08khimNkjNdybhpoHDZUmQneSIl5TUI4tdnfkTpSX0EX0EXa5VNEZt3TjE7jR8oAZ+iUSCicdLAh5FYIFK6KuNQeRMIUAtY6RlRImhksKq1UQUa2ZNcAyyM/xI6NAdQeDTmChjgzWYRbyKsQc5TeEjEbGfEnb0LNDMEN5tZwsu/wAlA3nMzXfNjnBigvCuEBtWjn6lPx9Yg7mmGQVFQVpWick2RKgEM0gqKhBokKvTLG+QmJEsyMvLDhxsXbr1i0RPOPatWvNZlSekrK2tiZSUhjD1lrDK3rivC3Q6SOieU1H2+PIXGiXeflJlHyxSSs29rmnpfiHJSuszh+sL2PFBHMmua4usCmgqM/2Z7e4atJtXb/cK89TUjZ5ZsTStU4XpFwWzeL7zemA/IsF8gMAdNAmLBbID+aJKi9sI8CGWYLNYG81NqJea3XlQm8x0ZiMJGrmMZltdrtBAP7k5UxoIaugRcgyOE3CITPXpktf922ET+aLzt4dtas2WfR4dGFNcy10Hc2R4cJmTmZa7oVufRc+tgh1eyEqM9GTRg5UCjTXhgwiuySWaPRAtDAYNpl0ojHqYckSU4HQnR4ic+unRfcuUS7JLJRvSwUlWyujA7m9JADLC20e1NmblaaVMT47lVfloGzyFMWyt06rWi4AAAAAAACsChdc2cqGXOrY2v0ztbca0W+f7XPzXl2oxzbEhONx51Q/om/UbnvcYkx76mXWiekh86ADjZ3AlLDR1k57GLWP1oXFuFOjHQwruyfsik/SjszRGbaCeMi93MKN4j/aVjOmQ4mT6ELSMce+g5hs0XMvdJsiyVFRnUmLkWHUPvCuSgueP9I8QqpMUFhj5LsY+jvF0ZbMtZp//AftnGds/6GlhWdP+mxcKuo9/khwXfEaT+ASJgIACXtMWT0+2o7umVggw2MvtHHSYlmkPDzDbYQ7jDwseetUtnoCAAAAAAAACCN2axVcuD1baQ8HbasH2qiE3wZXHNNZcBtypjRoBpZ9IjjcXyhkda+CMh04JVTu7TIw87FhZrjXBbDhCjMkvLol9yHZtNvEJMeJ6ouhrjPIEEmCEbIuko1UMQpzdsV3oxMRWgNXoTFSJmE6WIWTVwCUG9RVAEAZWPa2CPIvFsgPANBBm7BYID+YJ6q8LvTM1tChxzQ7UV4yzCPR9Lvqes3zpy0a/p0HFodVZqRQI0gAr98Q02sIOjpXBc3IIGE8lQpNg6G1kxxaxi7Md/ebvgCuyZzjs5FrjWWabCGC28QkO0V1kVYGN2kyQccaIz+o/Jj5ppXG25d3t5q8LrC7UaIg0ycBAAAAAAAAAAAAAJQA7Nm6aCITLmdzSgdXXqoNCfisSUFdzmam/QFSqxunIyHJTlFnRxGZQLp20raOz0akmq6uk+6V61q3L8+iRAEAAAAAAAAAAABA2bjQytbwVFSawulA7cfJMGZ6av4jm3MmwgXQQo6QQcJ4aBvRTrDfqSUcoW8cNLnC0MCYa2nizBYniUlOIapJdhncuDNBxxFjfavJ8ql73OeVQMx0PTxLo2stMgkAAAAAAAAAAAAAYGFc7JmtpB5TJycNW7Si3UZ9Tx0o5Xn85GJNp+r7n3R32qNsulY/5B3/wA+a02me/sElPJBGbgkVYe2shtLoTbqbKhyKUZvFGdq2QMAPfwqSv+n7iM0WJ4lJZlhFtSYtnwwh0mSCIiZGVlijdrsv/ZK8/X4/UddaSBJADqguZzlsJ9F9jIPJcCjNWW3LEikAAAAAAAAAAACWigu+jUC9F6wcP1jvyK1UI/Dz40+Fs9DJxbVOx+MW+U405iGrU5Fp7XxoFwGScEPax0ioEPrjyDr4em/QHMlg6OT9QVMoLil4IT+HrKLbGLiSH5MtMSQl2SWqPWn5ZDBJlQmKmBhJQk9pV807N0UkAcwBVlD5NvmYdDerBzflDavfG8HHBgAAAAAAAAAAAKwWa7du3ZKXnnft2rVmM1GdVxbW1tbO+VFfC4N0KPGKuaIZttYO1ucZIVgNFv+wlJDCn19XgGFzuj/bh1LdDuoqAKAMLHtbBPkXC+QHAOigTVgskB/ME1VeOCCr3Bir7Pkac+znCUCBXGePmETfS4K2y5D4xmSmHkZ6Mjmb3SEz17yGAiTNanvk0WRt33Nld7+pNgcBAAAAAAAAAADAKgFla7mp97Ql91hjDkCxjNpH6+NzYtypBfsvb/JnTZqfNsKbrA5bfP8Lbr9/1mhrZ7hFAuS7RNQ8/dA3fuicfioaAAAAAAAAAAAAVgUoW6cg9x6OWaBIFNC0AlAozX35BNM5cN7pzYnnDQ/bo+bAf9ZoGqo6wEwwPO4H/uiAM34hsQQYJeYgOwAAAAAAAAAAACwzULYCAC4stfWqvFJMbp56/CQ2n0bfM5Sm5EDzx5WqCkuANqrrTkUsAAAAAAAAAAAAlhgoWwEAwIQW/RvMfAY7AAAAAAAAAAAAVgIoWwEAIIAv8Y/bUDW8B8D4TNuzNSXkB2fdAQAAAAAAAAAAqweUrcDEOHI9BYnuYxxMhkNpPmxlihSA2UG7sI7aO359ZHUzVDnrW02vfyCNhi3aZiCW6A6toZ0IAAAAAAAAAAAAsCpA2QqmI/cpYXTk+8FNeVPvDTYC9RYAi4TV6XHHa1fllq2nnXGohtd756y+CvuD9U5TGjvh2tnG2lpLHrM1uX40qm1fxsRWAAAAAIALA33B998GpyYILCnYwqItVH4Xs4tkLuIDAIDP1MpWmrcYkGZ2IvmItHPU+KXzDlaT+l7HM898B2CmhL4TGLd04+MbGg7qPWV7yT8Wyx2gdN2rcwvStTb3A4cAAAAAWH20QZNF4yPGQgatodWQO9cCk+Mne/BRU3eYZUGTOe3gMD5vOcJJeQabJM+0GW9fJmVL6XItqJqdtFhYBgCYH9MpW1lvXW1vDLgegcFng+Xpw4atxmmzqR3pDRbM9eA9zP6+pozJTJW5en3b7A7NN4hQgMxXtT3yRu2q8lzZ3W+qtdkAlBeq5qrOT7oH/Wzbrw4P215nT+hdAQAAAHAhGLaqrP/nB3AOmv1GZMCkPuNyBk3Pa27VrYbiPfpo2z/MU3zZHR76JhS8fAe3ReoIsyzQ6DJI23j7KMXKt6S85a9uO95+Z6UGm9V1S3KsKbW6LC2zk3a58gEAsPRMo2wlLUOtM5aztRiV3ZNBcySnJ7LXANbVado36vZIM0dKNlpSq9QVFE5zf2+d34ASMGofrYuXnHGn5r+vcf2or1kfd04jbzKsrGnFNbffP2uwYlZEAmRVhV3xQ9+DqYCsB4w9mAiAUlDvabsM8IciaAQToS9LnauY1goAAABcJIbHfc9f1sJ3hzc2cw8hxlihD7OBIf9sG36XqPf8V2pSKZ3epBfqxEitES0S2gq/OQgGB2zEENy4SM5bUjCf7KaZ02gdwApoGOujJpSQoTYDWXOvOdemnwjITh8Rk//AEdmGh1lpSZ/SAE1SFa1mFhWfysklsNUjc77Z7YpMsoTmwiKYZhQEpLJfICysLgEAYI5MoWy17jtImxOK7p0xalcPhI6N6yZYQ0cLa0nJ1iSdneg7J92d9sYgg7ICzB61xrlyeVu+r7H3ulFTlRNNQ/XV6hL9RYe/6fALiSXAKNFzhAAoJdSQKbI1XuwlOHnUAAAAAIBVIno0puNtmOAv3f6rs09gSGF5RztSkRTRJJFDMUJLjNQa0SIhiW3zbEPaNIamjMyUtymIDmAJmj3rmHTSb0j3waQj5nzHuyod1yJL98IjYr67/7EsSDXEjk01DyTlK2WsSzEU56IGo/PQDJtIJbMLHJdLo3bb4xa9esp0WQSz5iqfxyDLi2cpvZlbXabPMQAAKIAp92y1rp4N9GXqyyTp5qwdH1StZcSynQ1/r+OfXyV0BLteoqEXHa5UVVgCtBF8iQcAAAAAAGAVofkFbvj8hbDGUTMcn408bzvQJAV7BshXdH1qaEA0UmtEC4UnzYK59QHhVJrF520qLANYcwown3QSrMZT7rVJR8FEYxoTJU4m0ZSXwdb+GVI9JUpvyuESGDNsouOzkMBSux+fS36IGdJlCmbNVRqCSo0ElX2+/AcAgBkwpbLVqhlzadai7RxUrUsFLfo3mFWPDwAAAAAAwGrC5zA4SNhCQOLPd9GXjPk6rPH6gW3ldDjS0m0hUAxxeZsLNYCloyZ8aNJJPMEqdtovIBFaFMg1i1zTOU8NeIX2djvlE2rkBNOwyps2eouM4pW2NVAOc7LlUhxRway5qmlY6euB/2RkzH8AACieKZSt1LRFWl69kQsTVcJSW+7PlqSGUD8vCZQKXtpxG6qGq4Pr03Qc5MdVewAAAAAAAFhGosMmxxtvwhYCRNJKMKWAjY20dFsIEMbqdI3Yheep8zYfagDL1/wHxM45MZfTpzmWiUqNJV3XtSYsty+Oitgea7AhNk2gCqbDBmiWqVRSPRxWDqfIpfTpCglmzVXSrksNL03qFpO4suc/AAAUzjQzW3kbq+9YM+luNoxPpMqWfzvV9ncNfYElqCE0z0sCZYLvN99WB4JSN2l2jPz1yN+SiLa35xduom9G1Fmm3HAAAAAAAACAJUFXI3I9J9dP8el32iRUGjFFVvaHDfm6aDkDgoLiQywWkh8Oqb+EvtEeKWGNqASER5csWXQTv/A8Xd5GodGMzYFlAMtVoeGdV9NBEsnLCLrOnEfRqGqlNINtBFxJ5vhKViGJqk6hUbxC5MmOpmtNmUuZ0xXW/jKCXB2fjQIFr2W9bFz+AwDALJlqGwH62kSfmvgnKUb1aNtUljYH+2fclj4u+RbUDvPvT6auDpQcvpZDncFOO5GHOkbWc6racLDeaUpjJ/zNqBF0+fRqaO3LAQAAAAAAWGLqPX9NNH+Ltu6iRnqhyMr+qGFl96r/Sq42aGXjKxk6G3Z5fviuSK0RlQJzvEGDy6vxijgiMW/FXEp/GWXSINQ2gCW5to98sRjxQdR7g6ZcvekaFEVGxGTA/k2nAs+WUkL4ICi5PO9YYpX4fHwfGvNJeApGmgo/ay7FExXMmqvM0JOiEiLGFPkPAACzZu3WrVvy0vOuXbvWbBbVHE26m9Wz/YwndWeBtZ7n5+fyBpQN1kEerDv6ZiszrzAXGTwsYFlAXQUAlIFlb4sg/2KB/EuAfeSx0PEIGz01PHGa/kxYxcEWpUlTB2cegM4LtAmLBfKDeaLKa8oDsgDwoc+P6vMlX5yUacOk4WHbW71N+gEAAAAAAADlYnL9qGwjDzr6ZLp5rfGUMMnTY574UfjxaAAAkB8oW0FB0AoeteqHb0qe4bvpsNU47aRYJgQAAAAAAAAA01DZPSnZ/MdZ61pLmOQC0LaQYLj3PAAAgLkzu20EZg5rUDGbGoA04GEBywLqKgCgDCx7WwT5FwvkBwDooE1YLJAfzBNVXmvPP//8+++//95777G/jFarJVwAAAAAAAAAAAAAAAAASMPpKe1pgpmtAKw+eFjAsoC6CgAoA8veFkH+xQL5AQA6aBMWywrI/6u3fidvQOm5+64PiPqGPVsBAAAAAAAAAAAAAACgAKBsBQAAAAAAAAAAAAAAgAK4yMrWYWttszuRN06Yq7XWkF1Muptp3LtQ3lWALhIdZCU5QCZcrjQmuk+MuvAYY5gMh/k8hlAyxKWOHJGdS+DEhEyT0pmwQilKI4mqLWUQu/A2YT4sqdgAAAAAAAAAAMAUXFxl67DV6MvLuVDZPTk/2a3Iu3IxuX62vVeXN1mo7O4vyx6/k+5m9eCmvJk5k+5Oe2PQi8nTMtcHG6uXojj02rJK6QIAAAAAAAAAAMCMuZjKVppwlVbVWl2vyauCSAxw/jF63ml7J9fcvcnN041LMXqowtNSKpypGx62vU4u9XVZWb0UAQAAAAAAAAAAABTPhVS2Do/7zcH5uJNKD1i5tFFbr8obz7veWhOohcVilfGQ/ZWQDRlK5DJatRg5FGAU3YEWDkNbzEz6YmlGUau1uroH3zA5RnPuniuN3ah50pRYI+popvioGA0bt3uJLbEM3VhYMJNqe+SN2lUlu80vmbW60kIYas6iMjgydtI96Ne2L+s66GgCKWCVj67SdOXMvJlvilx5bjMnM63IQre+Cx9bhLq9qNrMRK8t5EClS3NtyGC0ALZobBFJQ5dfLQ+tU7LJb4rERqLwEyXRYoyaCs8y8Qzuwh0XkSQ2AAAAAAAAAACw0lxIZWu9dx63HDpEvRfoIUfto/XxOWPc8drVQMMwah94V8mcVLikpNkJbvsNXRPB0AO0ohwMW9X2xoAHJEM+5EENW2uN0w4X5Hz/rNEekSFjQloi38O4c9qQapLEGHXcaWx7PGjNvLLbSwhYRa3LNmgamaJi1LNLd09JMfQ5hCOxZHy0LYJjCK/j3RPSrddYnnFxXBnF6LfP9rkxqyKJMlgzdnL9aGRqJq0JVLhKkxHvcW7MM0V6nuv1JKYs9CIL3cYUtMD2iFVCtUURI4PRAtjS5XqWGVa/Zh62XfPwUyY2TQNlTV3l8nZtdHTdD4fXBJrh7IorpdgAAAAAAAAAAMDKcpEPyMpDc19oXyq7Vzu1/oFSZvjmXDkRvj29aSp40jKp7vkKJEYQ1PC4H8RQ31MzdIeH7VFTbatJ+6lqGp30ONMogw6bp0JpaYh6T0sXw5JdRlr41rD9YyMpcYnVdjagSbtGXERsRjW3fNeJMtgZn410CYi4+uAqTU6cx/kxxxS56klsWQRFxnGUYLigCdcjZiVehoR0xUVk8RubhzopE2tGYY3RnjpyoLStSuvuiiu12AAAAAAAAAAAwKoCZWsmNK1O5dKGNzobi5vQYvL4RfupqVRIaTH0V+XS0mZicvNUj0FoTxhk7vUb0jWDtqV1q45cpEijYZ4Oi75O4cgu3Zh2RzWS4kwsKX588+j8Qk5sRpnCxMqQGkcCOa7S5MR5XCgzS1FMPdG9GmURCjO4TX4iHI+Yk7QyRIiLyOI3Ng91UiY2FIVDWt1YpU7Ttipdqyuu1GIDAAAAAAAAAAArC5StZYbrZtSq3HGKeWK09Nkgw/4BS4cjsTQfkqBF6FwTZNO5XqiMusgkFHT2Rywnc4loJrWaz1slbavStXLwBAEAAAAAAAAAADagbM2ENisuNIlrFgyP+6TR8JUYNOmPCM8rNcyD7RXz4kqjFiWZh5ZuJ5FjWqielsiExxSJFUrXQXTxf4aMipWhEFylubxMlaKYepK9LJIL2vGIOcldHzJGlCMPM9RqF67U1bdI2zq8fjSSWwS44pqq6AEAAAAAAAAAgJUAytZMjNo7YqvSSXen7WseZonSaEy6m7RUl1Pfanpqz9RhKzDfo8NvpIRiLl34PKAUONMYHKRD5tl0rWIxsr+FJEuMc42/RKRFuT/oh7W7rsTShRa00hfreqCUGZUogx0qngx6ZVdplog5pshVT/KVRZqCtj5iYa0hJ2d98LFG5ILnoX/OVro8TFmrXcSljkkzaje0p94VVw6xLyS8ZiuyFJMG5bogIQDmMGcURUJp9sWYDIfTy0Pp51VND1liJlm5LApLjDMjmszoRYhEB0VReMYCAFYOaocCcrZI1NgIEgIwG/9Fobe96O/SE01m9CJEooOiKDxjAQAXAyhbFWna6Vpn+6xKvT0/iVudd5OTpBjrvUGTTg7nER5tjwdNqQCq984HG9LiYL3TFM49jx+j7kmLNVqzHFraO00aa52Ox5flW9OeGDKX7VSs60+Te4nuHYmlvBFycijfRCYIPZDoKxMzSpBVZgmppizT/ly4SrNEzDFFrjzPVxZJBe1+xLTaoshZHwhnRC4oD/19MFLmYVJiE4hLHWWHuZ2zI64cYl80qKmkKsD3XmCIfMz6Cs9CoVxXAbj9l07nzUSvHtyUNzNhxdX87OFLuWlHepcAAFA86O/Q300H+jsAwLJzS6PXk7tdLgVMeHm1vIw7TfH+MA2DZnT/RCf5YqQtJpPiKCQtK0KmIjGZwmsMUz8spUsRWFVWoWF3w56G6OOQpn01oWCaA3kTutMgC04JnkCVyOyptUPh8FQbAdqSrFwWRVFJSIM9mRyXGHMTT8m2orBqJK/CDDo1vu12Le1bj6qXCkvGcUch8/Gg05Q7fNfCXga+TdSKwyzkVZj5yS+xW4nEOesq8yKvwsxZ/nGQ0751mgCZobxaTqaXn3IpUrzZ2ycKJshe805DlclcWr94VCKLao1VY2sEaEuyclkURSUhDfZkclxizE08JdsUsKKSV2HQp6SVX2K3Wv0+5Vdv/a6Y3z8+9cmP8mg++tkv/2PE1vL75ZeFe51Pv5BkRb8bX/nsfdL0Y5/8yi+VOfP4rU9/zGYVH+Avv6UH+B09QC1dYSu3r+98Vhr7fPI7ytdUPxaUKDjMbF0o47NTeZUFWsugZpHyBb/ptxLNF2MaZhfy8lHf63j+iuwkpinN+bF6KQJg/gyP+150+5lgQgZNA4oSWTMQ2jGcz8MO7UxNsNjYyxqNEFJAUW92u+zhjcapi+XPKRLuh4FNMNnITIUR0ri7WW2PPJrlzcxDy/LIH7s1vftEMqFyaSO6a7o1yVaXIcxIQ0JJNFMOWelicafCkR6c743MWl1p0RrqTgJSJDMU7XVrkXGUS3FhLSyrqAxTPBk2GWpJSJOxK8ik27p5+eSE3qBPepcOw9XCgTH8YwOtcMaxvG2ciuFewLBVPTjbukpexoPt04ZexsNW43R7IAI92fO6qZcqz1F+gc2KPfybm4c3L+1tp2qedOYsP2ulqgfe/lh4DxZ8JAUI0N+hv5MW6O/iQZ+CPoUxxz7lzW9+6o+/dPMKKRxvXHnja3+8+0/SIomPPnVDaBL/8an7PO++6oelOcNh9dZzn3jkq2/UhT73H//s5lfv+9Rzv/atWn/5q3s+Z7MiHAH+03+77y/9AG98557v/8V9f/WysGHc+CtK1wvM443v/NlNzSrWF6ErWP/6IWlYGHJSKwczW+fMoBn9bpEKo2/NEkbOGCk+oxWIkjstKwplWcocyV2a6WEBy6v8lCtFYFVhVUZerR4pGtJU0Bdw/bkK3xukjFQ+tCIYfiND1K+1wIR7P2DNkSFMYK58BkFY3KqbDOgBCqIm8YTc020gtC+Tdu27N/2pO92X5oYb50ohxwg+iMcXgN+Y4jlchp1aRI0rRM1i1WFplVc6bAwkM5JgWaLfpsLiR+Y9y/eY3DVsQ05tS4vKIX9C0mLiL4P8zCQ5fIcQdvmXh2nll5kq7/LDysAolvC9QcpIyRlDBMNvZIj6tRaYcO8HrDkyhAnMlc8gCItbdZMBPUBB1CSekHu6DYT2ZdKuffemP3Wn+9LccONcKeQYwQfx+ALwG1M8h8uwU4uocYWoWRQBC09e6aBPySZ/QtJi4i+D/MwkOXyHEEx+pRCc5nfjKx8LVJlvvfBJz7vPmHCa4kezQT9mnxJrWn3r05raVExZ1Sa9aj+3lREgOdOkNX05o070VdhsVv2n6htmti6Sei/9po8G9GVYkSWMnDGm2Aond1pWFMqylDmSuzTny+qlCID5M6tp3hmOsHPTHIjHtbJ7tVMTp9wND9sj35gs9pvqHDXm3p+1RCfbCREm1T3toQ/MrehzlCbXjzIfvFggWrnw9ouSYKSdkh6aUMXP81MH3zH5a9uXKwk5VnQK/SLQisyBpbBcosYW4gILqQzQNDuNyqWN+O23o7Ca4lFFCaBTRzcGCe9Yk+FxX5vqwp4dVtxi6tFk2D086h9d5xYJzFn+VEnLwnzlp6mDkamZYaIBAh/0dxro76ZmJfs79CmZ5EefMj1vjX8ur4gPf/ij3i/H2pTSFPzTjW97H/2zB/9A3uqErO6qfsz7xQ9+/Ca/efMfhr8w58Mq3FZmgB/e+cHv/ufjvrOX/39fcwUo+MWv3qJ/yb6+/xcfuPsu9vvEp567IY2KA8pWAAAAYD4UMki0UMSgVnvtZu+bHr1w8tdQeeQZh87i8NNgW+VUqZActGCSQ4soY6jvsRETH9DR2G1RY08adflpDC0g05NYXQ8PpLXRJ8nPx56Zc2wqtCzzi8yBJWqnqHGFWHgSLhzhYdSwRScSqrF+FFEQ1YN1Y+xW7w02jhr8kMKd40tb2zQJay5kkD8xaYsgg/zsCamt14ctsZB4s2XX7cx4XLzUoL/TQX83Jejv7KBPWSzL1qf8+je/klcBv5pwpWRKbvzoe959V/7kLnmrE7a66/Helz/686/9MVdl/vGXfvnRp55WSk/OW899wrf67OdMK447rpd3P/UX3/b0AB+6/Env51/r3WBpeevl3b/8HjN64zdCz6uI+vrQ3fepXVz/8c+8rz5q7GZQBFC2AgAAALPHOTxgb75qr7Eokc3JoqOgmRJZzRQ7p4C/xftHR/OlVHHQ8I1Gn9rYM2UmFEpdbqE08AehKTft4pNjaPSpxp6cNDm2iGRasIuarRBBBibd0DBKVwGw0T+7Clc+UTvH+2cHZvWo9+QSkhM2qjuL1fIURxb5k5M2fzLl/5jl6lHrYP0qfxBO9my7+UUCBBL0dxHQ35mgvysC9CmLZfn6lA9/6G55FXB3xaY5dfDy9e97H6v/+6hi1GL11nOtr/3CE6rMG9/5rPeLL33RVGXe9fiPuNVT9/3i23/53yKzSh1xvfXy7t1/8e1ffvSz3/rB5zTJH/nrf3zhk7969JG7PvDI//C+/OmPed49H9Km39p9/cHn/udbP/rrh3gUf/C5z33a++WL/5BF9ZwMlK0AAADAHOATWyJL34JT5IwNOBSRkUtoEDukY0iKmCSjhUlvixQmj8pfOZgGWpfGxiy+zPRmGYsYfXaDsWfaTJgJYggyCNZP6mmntEQmVNW3aPQ5JPnF0rC0OVZMMjUdBBVZtmk4TlGzFuJFgmWarkBiuZ4p0yeRKSt6RRD7u9ln7VTqvf2NYIGuCZXY9mV5E8s85U+btCzMNf/p6fbWr+7ymW/MKT1w/CogGiDwQX8XAf2dAfo7Yq5tmg76FM5c878cfQpf2i/W10viVuJHSL+HAIO2LPjoU/+JqzLveug/f9mxZcFdD33u6a98zPve9dBRXda46NAtPjv1xg+6/06a+fzBI3/9A75l6g8u//p7P/c+fVk5iPM1Y6BsnQL6Upf0XW4ylMf5pXE8a+jr3eI/AmWmELFV/pehIArDnyAA4kHpg3JAO4157apWbqxKVvWNxFLB3tc8fxDLh66FjD3pW7xoaWm/KTkYpPHyqL3jC0ytcVKtU+MZlrZGn19p8BGP9mbLR59tP7qFEOpi1ChOpF0ORVz5TO/O7YYmf44cy4+KSBRZ4lZgJjGixhfiRYZl2umx/143PDzaCGU65SLlo/2dJdMwigW12fJPhJ4MWwf6BnveRFowZ5uN0w4bvsn7eOYo/0yYq/wsMu/IV0ZMhsenG5fEtWLxGVJi0N+hvyuUFe3vmGDoUxbIXOVnkS2+T7nr8f/6Se/b3+QzTPnM0/DUUbG037GaPsMeAgyh2FV7tv462Cz1xl/d9YG/etmP4s0bP37x595H7zaDtQT4T//tE4989ef3ffqFG8acVpM3b/zVnz36/Y9+9lv//RFh4PZFYgQpffObLMZs83xTAGXrLKHXigP5zYK+dMznWyWIZaUKgnbYCV4dQCIofbBgqAqycuPbYhHVttcZZ/44X++pQGhvKN8/63ISBzoxbmqdjseXPulhMoHHNGAmc7HULvYJYrWSDcaE6+rRNp3Fqg81GXzkzKLxh3s0+pzLMRTOtFNuioRzSGyRRp72U2Gj54kBpcfcTC5bjk1FrbN9FqkG6XGImlyIF5nK7tWt4x2eOTvHW1ezZHrM8kCqm+Elh6xi7q/LqNaqB55fLwk2JhQWm5vH6/tZurX5yS+xWonx69paeyRrWmoNzVzlZ0/IvnfAI6MdDsOxzXy957LD8g/9Hfq7oljV/g59irwzcLTJhNUKfUoGHvnrf3zq0ov33X3XBx558Z4v/+OPdmzTVO28Obnp2kPAZnXX471vfeWNodyz9QfeV17wN0t95D9957M3/wfJwK3+Znj3U2FNaDTAN7/5ze/R6V6//B7tFSD8BqrSl3dVaN6VF4IZrHG+SAyPZwX3+IObX3nhhq+iLYq1W7duyUvPu3btWrNJzWgGWGWqBptJ11K0suTjbF/rLDX/WWaEs2p6fn4ubxYCya56KRuJDuYMa4kaXo4OasEUInbZyqIwzOfJweIflsVysUt/ubjodXUOTLqt65d7oYdhgc/IPGuxNe0A2Fj2tgjyLxa7/NTcyUGPZcRDr7t9eS0JXAnL0DgrbBgN3xrmwGu4IxKsSF+M/g79XWlAm7xYVkD+X731O3kDSs/dd31A1LfpZrayLpx/XpLwL0apvyQEsB5eUmTvwzo0Vi05xjcRmzmZtbrSojUM3foufIzgJLq9+JzCTOiNhz6wyNvgK4vm2pBhszu02BhEI5KGLr+skASb3fDGIBzymyKxkSj8REm0GKOmwnNQMbgLd1xEktiEPXq3OUfJIi7smeaQSjc2Mj+UgTqaH2WZMmojMD1u3YIfLBrZFesCkCKjDHOOyHmUPrjIjM9O5VUpoA2qOnvzGHkySpZ2AMBFgo6pprmdDDqdSH8v5tTl0UWCQZMNkPw5hMNW47TZDJ3dEza0hW8NMyaiFQP9HQAAgMUxjbKVtnSpdcaBgrSye0Jz8cVeFJPuJuvmNZUZvVKQyoA0kLSmwtdWzAQWkVID0xuHr5/QzflyiUBx0W+f7XNzkSD9VvfFvYVFp/cbpXQei21v+HqFGn1vDk3Gj5Fh1D7wrkqLWiB1gC0iaWX1S1+0T8WL1/n+WTv0HVuRMrFGFKRF3onGaE0drZvR9iVnLxujGr1tuOJKI7buN2URR7FmmluqwJjca5kfqjyKGGESo3YlSheJU13XM/dikCajUPoAWBgeexm3OpsZrGrzdXtptwabmhKlHQBw0eCHO8kmiO8gGbdaWYyxpF6Obpr7e+v8xidimBi+EaaP1XBVQH8nbwAAACyCKZStXGMW3liCdnNRxwWO2tWDda4x43NeW0NSx5JyQcxlVSpIrnotVPuqtHkEfcCVWpDhobYzO00KU2cwMkKfdYNbwxf3pilaiEl1T1O08B15tDMTQ8TL4HeM9kBiI7L41V+8+JsXv7CQMrFmFNYY7akjB8EG5H7NccWVRuxcRRwlKQmaVPGZb50TECuMJepUidJEEoQ34L8AoPQvcumD6aj3VEXWoM557msqKdJ5HbzMsacdAABmjzqLSBG8RkTgPb98UaDzgDbUW4AkapgYvh6mwmq4MqC/AwAAsECmPCBr45Kl0whG/s2B7FW4psH6UiE6H8JXyBbB+Gxkl80zXkSq65rGxHxD0W7p9UUphAna6MhITKVCUalZvNomtHbSyhAhLiKL39CLF1frWEmZ2FAUDml1Y5U6iltqW5Wu1RVXKrHzFHEUSxKcOZAx8yVOYWxeHImKLRRGQiJXEJT+RS59AAAAYLmhL6Vu+KQD8R03pao1TDR8LcwAqyEAAAAACmBKZat1jO9SPSRMv0qeh7ZAaDMAA/PbJNfBqIXvNHd3RswlooTE5oNPyCNtq9K1cmYS19TYpZpbKdsoZ0atJCh9AAAAAMwQ/iHVgbayP6eqNRr+xdtCAAAAAFgwUyhbrctX6ROpY8ZZzPwvAb0YJLlJScxkL31/w5j5cRo8obG7IrJUkzbEV4BQsLFkl0GSMaJwESUKliaxibhSV98ibevw+pG/YMkVVyqxCy1iHWcOZC1lQSZhHIlKKpTsiVx2UPoBF6/0AQAAgGUj/HLrWB7IXji0lf3UxftrW2hNDT91d+fIYtj14sK/gFsIAAAAAAtmmpmttJmmcZjmpLvZMD6RKlv+7VTb39VXKQxbgXfq8yN7wOaEL1r39zXke5KL/Qn4hvGB+UG6xTPC144vKU1xi2wvq7QhPBP4le3FipFPBoU1Ihe0ha46Z2fYSnTPSJPYGOJSR9rWdoO92fkmrrjSiF1sEevE5ECmzGdkFSY+Ua5CKfArxbKA0r/IpQ8AAAAsHfzlVi7g43pO/k6gdfcc83WBNnD3oTU1/LPvib8BG0MZ7lbs4RPWV5BcL0kAAAAASMtU2wjQfquDjXZVfFxdo0MWg6lfRHOwf8Zt6Sxt30KoFJjxZndS3wq80wpd3fNUMNH48d8EP8hbrrZxmcfDfXm+pFFB671BkyeJQZkwaEodq9AaGm9ReWXgOCNywd7S6Fhz7uFgvdOUxnEkJTaBuNRRdhinCbniSiO2K6IpslfikCpz5jOyChObKEehmPsyXBBiMwqlDwAAAIByUe+pTp66cus7AZ95knNlvyt8a5jTRAQAAACAZNZu3bolLz3v2rVrzWYafVwaJt3N6tl+dl1Hati7xPn5ubwB4IKS6kHDw7KizLyZnT+oqwCAMrDsbRHkXyyQHwCggzZhsayA/L9663fyBpSeu+/6gKhvUx6QBQBYKMPDtoeZCRcVlD4AAAAAAAAAAFAyoGwFYHkZthqnnatqTTm4UKD0AQAAAAAAAACA0jG7bQRmDla4AJASPCxgWUBdBQCUgRVYcgj5FwjkBwDooE1YLCsgP7YRWCLUNgJrzz///Pvvv//ee++xv4xWqyVcAAAAAAAAAAAAAAAAAEjD6ekp+7vEM1vfeOONe+65R94AANzgYQHLAuoqAKAMLHtbBPkXC2aBAQB00CYvFvQpYJ6o8sKerQAAAAAAAAAAAAAAAFAAULYCAAAAAAAAAAAAAABAAUDZCgAAAAAAAAAAAAAAAAUAZSsAAAAAAAAAAAAAAAAUAJStAAAAAAAAADBLJt3NNUlrKM0Chi1pF9AaWg0Nx5vdifBvhCBNHd41QWySAAAAuMjMpLcKuitL8Jl6q8Bx0APaXOpmuv/5AWUrAAAAAAAAAMyOYava9jrjc8ag2W9oSlJBvUdWPoOm5zW36lZDNs5snIqQzgcb7aoYQQ5bynDc8do7FL7V+6S7c7TtO6z1G4sYgAIAACgpxfVW1o7JGx76fRAFL7qg9L2VtQd092vNATdl9OrSaI5A2QoAAAAAAAAAM2N43Pea+7sVuq7vdWqjszE3tzLpHvRrnT1zZOgbTm6eerXtyzwkr77V9E5vsuErmW5cEoaVSxv8v4EKs7J7ciLk8CqXt2vCOwAAAMAorrdydEz1nt8HVddtXVBsb2XvAcvar0HZCgAAAAAAAACzgo8P16vyjogZCw4P2yN/qKtQhjRiNQa//Kayu9/sN2id5KS72TjtXHV5NxifjdRIGAAAwIWnwN4qqWMih0pxqojvrew9oI7Zr7HoOZH5uXMBylYAAAAAAAAAmA/WqacKPq1oK7TgUTOs92jppRg/rh2c1rg9GfMlmWu0/jOsarWHaZ2SBAAAAAim661cHZPcdLXRbw78CamKpN7K0QP66P1aZfdEbiFAexjILXfmCpStAAAAAAAAADAfaOaQC6sGNGSo7W63vzESZjR4Pd4io/H2UdWcxWMNU2zLF1HLAgAAAIIpeytHx+T3YeP1g9DBVWl6K1sPKHH1azTF1usfz13bCmUrAAAAAAAAAMyKyMpH1+r9hEWZYfw5QPoAtbJ7tVMbHV1X2laLd3nESGROEQAAgItMgb1VbMdERPZXzdhbmbNg41xGN0eYC1C2AgAAAAAAAMDMoHM8/Gk1fDjJx4eT7qYxrYeGppEFlFZDzrDVkCNZY3g8uX6kbVkX8U6RQtMKAADAQnG9lb1jYiH54ZidVTTM+N4q6AGtLoetYIUHpSO6O+zsgbIVAAAAAAAAAGZHvTfunIp95mhE2DOHqAI+HowsoAwb8jGvCkgOLfVt7GgZpYog4p0MPG/UrgrHjAVsZAcAAKCcFNdbWTumyuVtGbrZWaXsraw9oM1lfWtD3Yf0sHNj7datW/LS865du9ZsNuVN6XnjjTfuueceeQMAcIOHBSwLqKsAgDKw7G0R5F8sbGh3fn4ub5aQZZcfgLKBNnmxoE8B80SVF2a2AgAAAAAAAAAAAAAAQAFA2QoAAAAAAAAAAAAAAAAFAGUrAAAAAAAAAAAAAAAAFMDa888///7777/33nvsL2Nzc1PaAAAAAAAAAADIwsbGxunpqbxZQpZdfgAAWCXQJi8XqrxwQBYAqw8eFrAsoK4CAMoADgNZLJB/saAvBqBY0CYsFsgP5okqL2wjAAAAAAAAAAAAAAAAAAUAZSsAAAAAAAAAAAAAAAAUAJStAAAAAAAAAAAAAAAAUABQtgIAAAAAAAAAAAAAAEABTK1sHbbWfFpDMph0N/1LBZlxI24ZsZaBbHYn8h4AAAAAAAAAAAAAAACWjOmUrZPuZqPfHJxzBt4BaUsru/tNr3+sq1OHh+1Rc6su72q1Wp+7VAyP+81mU94AAAAAAAAAAAAAAADAEjL9NgK19aq4qPdOdiv8YsvUtg6P+16ga/U29vebo6PrSts66R70m1tb8g4AAAAAAAAAAAAAAACWkemUrZXL27VRuxpe/29qW0O6VgazD7Stk+tH2rRXAAAAAAAAAAAAAAAAWEqmnNla2T05HzRH7aq55aqubR0e92udPVOZStrW9iG3Hx62vbA1AAAAAAAAAAAAAAAALBvTbyPg1Xu0Y+u442lTXOt7nZrQtpKudfsy315AQ2lj7dYAAAAAAAAAAAAAAACwZBSgbBVUdq92aqOzsX97eZsfg+VSpkptLHStAAAAAAAAAAAAAACA1WAqZeukuxnsHTA8bI/UYVlyO9ejnQOXMpVrYxuNfnNfnKoFAAAAAAAAAAAAAAAAy8xUytbK7tXtI9qulWicdsYnmuKUa1tHI6cyley90MlZAAAAAAAAAAAAAAAAsKQUcECWj65pJYRdz1Cmkplvwu2Vdb0XCQAAAAAAAAAAAAAAAACWhsL2bAUAAAAAAAAAAAAAAICLDJStAAAAAAAAAAAAAAAAUABQtgIAAAAAAAAAAAAAAEABrD3//PPvv//+e++9x/4yWq2WtAEAAAAAAAAAAAAAAACQgtPTU/Z37datW+Kece3atWZzaZSta2ve+bm8BgDEgIcFLAuoqwAAAMBiQV8MAAAA5IP3odSJYhsBAAAAAAAAAAAAAAAAKAAoWwEAAAAAAAAAAAAAAKAAoGwFAAAAAAAAAAAAAACAAoCyFQAAAAAALJZ7uoc/XvvC00N5m4hw/93uu/IeAAAAuDCg0wSg7EDZCgAAAACw2ohRlj4wyzpOS8e7T2xSLPTbfOkeaQgAAACAKOg0AVhdoGwFAAAAALggPHAwu+EcGzQ+9ejojhfGX3/w/Ouf3371sYI1uQAAAMDKgE4TgJUGylYAAAAAgAvAHW/XPG80sA7nrrT8yTXaMkMy3Hzpij8r9set14W5g3/51yP29/Y3K3Tzxu7eF+t0YczckSG8/rS4ZT/HXB41FZf9tGWPyuPhY2fSCAAAAFhC0GkCsNJA2QoAAAAAcBH46X7jbdvk1iutLzzZ93424JNrOnfc2X4qGKqNBk+e/Skzf6bpef3nYrcd+P3f1tjfV55cO3xiIkyIK61g5s4z3g+fmLBh5A9/KybydO6wKn/ZoPEb7VtCngcH9zN5RLxXWs894Img/tTr3+JuAQAAgGUEnSYAKw2UrQAAAAAAF4Lqw3/XjE5uff3jfc+rNZ7nc2reuHzv255359FrvkL2jhf2PsL+vbh1P/v7wZsxZ2vc9uzJl16goeOtR6s0j4aPHkXg977MZ+682Nt7tsKcsb90+8al29nfSJjvPnTExoT3/0TM8anf+zPPe+D4dTOojzzPxpwAAADAsoJOE4CVBspWAAAAAIALwou9x2kYdvDSh6SB503e+aC84lRu/2d55WDy0nctaxUFbEz49QfP/dHjzkv3iMA3bn+DW0uGfyu8/7jxijQxECsrX3lSxvLcA8I4JCcAAACw3KDTBGB1gbIVAAAAAODCwKe3jAYfP6MJMkRIu2od6elUHv7MOV+reP71z+zeJg0N2OiRVLre6B2p0j19J9i4YPLSd9lwsfm4WO0oDaPUGp/3Y6Ff7yPJWmAAAABg+UCnCcAqAmUrAAAAAMDF4Y3dx16oeQ/01QSZj/yE9hZ49SG+Z9w911+90/N+tkVbB2SDDQjVwR3DV2lmTfPeFyt/+NNaEPiV1uETY7p4e/336fbYOklHyBPdlo5vbyeDev2xNrafAwAAsLSg0wRgtZmDslWcbxt7ogJYbhKLmDswdv4WiGMTUTcuGtO3CXNrVUpYtwsJeW4ZCAAoJbc9u2/Mjnmx96UXamLPuC+IQzb8M5GzUHn4a9uvfkMtdWw+TjNraMJOEPifrz/2bJ32jb2z/RS7fdK7n+byRHixR+dxPdDgQfEfb6/E3B8R1A9/O6DDvgAAAIClBJ0mACvOLY1er3d+7oV/7zxRa//YU7/nr4QdhH/3dP6GuXx6IG+vNMmjui3sxwiZ4JfrJ8rrx83XNENR6H/zxFiZxP0Si5g7sIQWqir4zeo314fltaeD5sJehfQKk68OpGxVlqdua81s7cY9YVvjly/HQr5SZuACfmjY8cMPP/zww2+xP/TF+OGHH3744Zfvx/tQImFmK52B8NSjo/ufEXt/jBtv09bLlmlcMbzYI795pkiAuSDOHfb6r14R94zJa380Co5BTARFDCTUYjz3gKdajHv/aMdfHaMxfYVJGcKS1O13n9hkzewdL4wprs9vvxpZBFQ8eGYBAAAAAAAAAICZEK9svXI4oH27Bv/xRXFfefhrnTs879YfXafDZ2kh6uZLV/iaVvq1XmeG93QPv8E3BOHz2EktG1r0Kpavip86xNYaFKGO3lv720BdAoqlQmsTPO+Vj/tlJPdr23+YH47x+tOyCKiMuOLs3Sc26foJfyWyWcRR9z7X/dJU5WsiwhG/yAHHYAmIthifOWG1yFlhos0Fw1YN8la55ajb4gjR29/k+t83dveUDjTWl8ThhidEmLdeZ26KbJYBAAAAAAAAAADgIlbZ+vrH++zv/T/RZj+9cYnOrr3z6DWpaBgNnjy69/PnX/985w6v/xwbpb+xu0fXpHD5+oPne8+a08fY6P3JvrAiL3e2nwq0Ayyosz9l5s80PRYU1wK8/nTjFXmy3vj2jzt0DWB6XtyivdseOBbKlHcfOrrll/u7T2z+8Ldiwh0/vDiYczcaPOrRqYjm5Di3e+/Wo2f3SnNeVaSxj9AHibrx4OB+VjeUJggsCZYWI8BWYaLNRVw1yFzliGWo23z3+siigTRPhMvNlVYwVfYZ74cPXS6wWQYAAAAAAAAAAICb3/vRj35048aN4XB4/fp1aRZL9XZzZ+U7XrhKc8TEct07z/5FGtvhupha43muwpBelN6WBbVHR98K5cgHb6rRPj9Br/LwF3dvkyagcOr30mbbYrW1WGfdvJdPTrzt2ROpmhF69qBc/PIySXbvqCq6FkzK4yvIwJIweeeD8sqKtcKEiK8GWascZwnqNgv5Sy+QvlVsYC9UrmmeCJcb0dLKrRJe7EmxHeRqlmfK2hp++OGHH3744bewH/pi/PDDDz/88Mv3Y7zB+b1PfOITjzzySL1ev3z5MhknMX7nTvZ343a+CDfC6TvG0toQIV1M5fZ/llcuPvLFARvhy8P4MKlqlnzkJ/5qa7nOestXNqmdHBqvSBOJXPUcxuneJFxVxErqV54UfmnfT7BsJDzRjgpjEF8N8lW5pajbtz178vUHz32VK210m8aXw41oaV2tdIjMzfLsCW0xjh9++OE3/9+yt0WQf7E/yI8ffvjpP7QJi/1Bfvzm+WPcw4ndRkAublXbHTLuufkO+/v2+u+L2zDxw/vQMD6NRqD+H2l5LB3M5T1wYG6SCArFX239Es2V86e50XlHjVe8Ji2pfpAU30mkd28td7FlhPr1orMLQZmxtBh5yFQNUlS55anbtz178jjNwx298yFhkMaXy038py9FjmYZAAAAAAAAAAAALmKVrbc9u8+VFErLOXnpy3TKyv1/F6zoF5Ow/INx+JQx+2Jegk8xE9sCeJFZZlEmL31XnEJThslWK49cbT14dOS9vf2HuqpF6NavHMfO5tNwuL/16CEtgtarioaoG+ENN8FS4bcYDXWc3etPhw6SimA2FzmrQUIVLXndVg0dY/gqzU6ljQ7SZIXDTeUPf1pj5rKlvdKifQkKa5YBAAAAAAAAAAAQQ6yylU8sHTfeHg2+IZapVgd30sQu/6hx4o6fbbzKbJ/se17zcXmeTP2RF2rene2n1PHiihd7X3qhJrcFEOe6mEfQmFQe/to2Bc6Xx97/DB1rDmYH17kQd/z0sq9M54e586L8wpPe/aSxiifGfa3xzPoPyVyvKhov9ugQHn5auvxh44jlQ7QYwcL2H/6W7+kch9lcZK4Gqapouet20NDxDQpYG8tnp6bJCocbsQmsbGn/fP0x2rO1qGYZAAAAAAAAAAAAMazdunVLXnretWvXms2WvEmGn2F9xwvj+NNXZsbamtwQAQAQDx4WsCygrgIAysCyt0WQf7Esifz3dA+/0b71dudLnwmdQoy+eKkQ5Zj+Y7mz3MHsQJu2WCD/SlO6No2XFxVYwsxWAAAAAIB0XGkF86zp16IdNnJTbGhTwt7kmAxYcgHmweSl71KdDy9EWBJef1o9s0lbCZUSTf6FtjnggvHuE5tL/eCAEoM+ZZGgT7nAQNkKAAAAgOK444UxHdf2+c4dXv+573ajOwVn42eDIDS8p4KVh9T6VdoBfDlho8pXf8IPbKRndjT4xpI9s+8+sSnk/9ILNY+1Ofi+AuYCq3hPPTrye8/tV3GIBSgK9CkLBX3KxWYaZeuLPVZvFrSHAAAAAABKjDiW7c6zfxG3Ymao+GkaWO2DP/2c0y7euHzv2+zf6Tt8UkN0mgOfE7T50hN8Mix/l3W6uaIkYa/sw78Nrn2iojKTb9ABoWKLZCmkLUVRMcAFxFH31uTpkaLmGHVGOKZK+O5DR7fe7jxOo7KFMY38H/mif7SD+czOk2nkv+3ZEyH/bW9ucPuCmUY2BTfP1ZRxlAyHj51JI7Bo/uVfj9jf29/kw+o3dvf8DQGidSBahcKg3FeOadoN9CnTM438s+5TFsU0eaLg5qvdl2FmKwAAAAAK58rxK+zvz7bowDf2niR2lHvw/OsPDu6/s/0UV0Sy16znHqg1Pi8mLNAk1jRfcJmvH/5WTZ4dDYIZQKPBo97jzPyL9Tg3f+49pqYY/Pjgdhb7M81guoFVVDb09SWUn5kdKeIEYkgDcJFw1z0bV1rBdLZnvB8+MWEDs69/Zvf3pfUCmFJ+aU6M36G5VBu3z/d426Lkf/3jffb3/p8U+RQXl7eMXE0Z40rruQfk+oM/9frByR1gofz+b0kX9sqT5hfHSB1IrkIo95UDfYoP+pSygL4sNVC2AgAAAKA4bj1apU/N/AhNoXCkiRXBK2b93p953gPHr4u5PG9v/yF7b5YTFtxcOaRFcNwxGzlInayYPPvBm+or9x0v7JFul08lcLr56eXbmIOXt7nydP9hFvuLW/eza+7GJWqIeGdKDHABial7Ufjoq3bvy9z9i700HxtmTVHyv/5045VFPAtTyy83N2SjOO9nAzmjqiCKrRv5mjI92I88z8bJoBSwusF1DbIDFSrXaB1IrEIo99Wj2HZj/hQlP/qU8lBsnVzpvgzKVgAAAAAUB//OPG68zQaNO2JtkVgg+cqTcr0PvXFyaC7PnUevMTf3XH/1Tu+O31alhQ5fuf+FJ/tecMyoWmREb946cg0m4XQTj0vUEPHONDHABSR93Zu880H2d97zdJIoQP53adI6DSyjw6rZM6X8lYc/c84n4DR542OseZya+dUNRxslggVl5LZnT1jF81WurPe01oGEKoRyX0XQp6BPKRvoy1ICZSsAAAAACqbyhz9lI8bRqw+p5UJ8uwBaBCR+PX9uwmjwjbUvfKN96+3OY9Z3aLl06PzrUtM6eem77N2uSev0HxzQp28LadzE4BI1REpn4EKRo+4tYAc6N0XIz9cM0pO7gJ00ist/MbOmyNKZf92ItlGV2/9Z2oFyctuzJ4//jP0fvfMhYaDXgZRVCOW+SqBPQZ9SNtCXpQfKVgAAAAAUzW3P7rM3sFuPHr7ueR/5SZOUquFNnSav/dGI5quKlyepS03H2+u0AZnYFtZFGjcRHKKGl0o5nQHAiNQ9cTLGKx+nCvP6Y/ywNcL8JnGl5Twgbs5MI/+VFs1DX8yo2GcK+V9/2j906J6b77C/Yp+TAplX3XC1UXxvUBmsFh1YLJOXvutXPG/4Kk3dat77YrQOjOkitmtDua8m6FPQp5QN9GWpgLIVAAAAAMXDd1by+q9eoU2a/PVTch0QP6m/8vDfNb07208Zholovp707qcooqRx48AuKqP+yAs1ESa9KTqdgQuOo+692KPZarzC/PC3g4a/Q/FtfKNGuc3xn68/9mzlXX5oL83i8XdvlGf7zokp5fde+vM+WWiPxnxH+9Pm/0e+eNX7MpecT7f3ty4phGllkxYpcbRRYuKkCFaPDiyUysNf2371G6KkxJQxWioRqQP15K4N5b5qoE9Bn1I20JelZ+3WrUAPfO3atWazJW9Kz9qad34urwEAMeBhAcsC6uqFYvi3bFTpv3qy8QAbDNz/zPlqnB4Alpxlb4sg/2KB/AAAHbQJiwXyg3nCy4sKDDNbAQAAADB/xIqqf74kPvKLLfABAAAAAAAAYMmBshUAAAAA8+eN3T1tZdBzD3iY1goAAAAAAABYfrCNAACrDx4WsCygrgIAysCyt0WQf7FAfgCADtqExQL5wTzh5UUFtvb888+///777733HvvLaLWWRtkKAAAAAAAAAAAAAAAAZeD09JT9jc5sbcqb0rO2tiYUxgCAePCwgGUBdRUAUAaWvS2C/IsF8gMAdNAmLJYVkP9Xb/1O3oDSc/ddHxD1DXu2AgAAAAAAAAAAAAAAQAFA2QoAAAAAAAAAAAAAAAAFcGGUrcPW2lpryC4m3c21ze5EmGZHeVcBukh0kBWX5CUUSWGNMVGMrGWU1b3OZDjM5zFEfCkUnvOFB1hGKE9lIossJo28tWZa0tRYleT81ZvVkkWl8IKRv4yKQ7UJLmEKF3LhrZCeoqKaCIU9P8nUx0977nxILJHCiywFQQrNmLOac5jlvOUHAJSd3G1mPCpYreWkS9E8DTM2p4lCZm2fs7qfUS6lRxd4Tj2sgNlpJrnzITHDs5YIAABkBzNbM1LZPTk/2a3Iu1JQQpGWBdbRVg9uyhtQLibdnfbGoFcvtJjGZ6NaZ3zuU9rnRk9y/ge83htstHfwJgk4K9xTzKklZ2O+Rr85EI3HoNlvrNwwjWVk41S0kOOO1676I9ys5oJhq9GXlwAAMC+Czm542B7xNvtkt46xUl7m1MNK0HEAAFaJqZWtrAnmHw0FaYYe5MN8IxdhzHbYUl2vyauCSAyw8BgTWRaR5i/GPJlPklc7Dwn2iux19uryriAmN0+9jUsX6GW7vtfx2od5pgSAZWP+bcJFa8mHx32vphol9mzVRkfX2WvL6uQDV0zsC3VEZXe/6fWPeeOR1ZxBk5FWd8Q87G7yN9/NVsb31smw5b8yh6dqxViJ7HRM7oqxcpJDfh5NQDRCh/yB6aZpLE0VWZKQWf6k6CbDLpPTMgoJUhWJK8YqM9pIypUPmpNATqshQ6Q3lB6r4WKYW5tJ73y19aq8WzIuWg9LUCUNdxwr1MPK/wkU2b7FN32i4eMY7XN2yiNzbE/qpOg+xdE7xPoKWWaQvkS8+c1P3fWBu/nvU8/9WhoqXt4VVupHbqyGpuO/epl75/zTf1MuP3H1TWlYcqZTtrKKUW1vyHkecmZDxo6c6taOt9+ZdVNaubShd7jX/SqtxKV3FrHMREI20Rcg4Yz5CQUYRXeghcOQcYqguhFJ4lGSl0ckiRaiaiKsIhmGNl+CaEoJt3uJnjC7PwZZMJNqe+SN2lWVUJtfMmt1pYUw1JxFZUhMsimJlseqnRX1UAVtk8oaywox6R70a9uX2SCepT6mmIxMSq66NLE1Odts4ROueLXqEbr1XfgYwUl0eyE4M9GTTA5UejTXobRrbZcWDWlA+gf23ACzwVZGDM2YEdi4zBWmA59IFQ+1CTE9hbiwV5hCWyERkf2ptAUYI5juPBTS2HheKAFaesifdkuYQfkk5Sej3rNPhk/TGsfIzxAJdzVf1q4wPkBGymTqhBQT9S2pPc1qzhge0xTg8czf7BbBpNu6efnkhF56T3qXDkPVKwZ6Yz7w9sdibQWt2lDEWPGibJzWrFkZY+Ukt/z+pG4iJKJL/mGrcbo9EKYne15XW4msrzE5HzQTHyFFPvmd0dHQfPPw5qW97Wg2Tro7TH7ucby/fqSPb2KsMjNsVduekM8xYZ6Vc/VIxMaQrZDVkKBcbzZDybEaJiFaDVezY8l604FPJEWqzST3RptPTrVAtCjsprzuCTa7au6lCtbvGsiLMJSSaKEZwdlCiyemqxWEbpV7I1ds8ly0HpZh7ThWqIeVF3EU3L7FWbGG5+Bs6yqZjwfbp/mX6pRH5tie1EnR8rO6cbDOZTw/v7p1Ziz5iUk1I6aTXQbe/Oan/vhLv/z0C79663ff+rT3y6/epytJiYe6zEr8mAPGpQ992G7IgrpxmQz/8an7PO/7f7H7T2RDmta//N5nvyXd/2jnD7hp+bml0euxsUR6qDk0ag1j0PTrCrNllnTPEQ6NFlTzawsqCRaCvMqEEEFGxm+UvJpMUlDjlrujq6ySBpnCMINiaNErR1aE+9KJJKLWHafwKNFdaiJxY0tKXbHQZVSMkLGWRcqVYR7jNzA3nWnXgYd4HDnPzX3/dK2HqzykjSQCC05eLQdmQo07PUO0a35pzTQNnsnBwNTiwvSrF1ZsvCqk0K3hi9+IdARXjvoQOAh7811r1/zScB4EqXtfDlhS5NUSEWSynv3adagUlI3LfBp4IJb6oOJyOSi8FRIRWQJxBCjcOwTznWvmymcQhMWtusmJHriGnllJpJHfllHC3I9Fs3AEOCVGqAz/Pqu5giRLm0clhOW9vNJhwyMtSSyJKVPIcsflMsZKZSJzY+QtEWNFFCq/KxLCKX/I07jTtDpzCFFs/gc4/ERNWVS6+HpqYqwUdvmjMM+BbyrTSFDWDLYaMkQI9FezthomIOUnT1wkS5BRUTPCA1GhijvzVsSgR6ZfU975zulaWpATbqwudEMjBN2JIzQXPBgj+FDsAnVruA+cm9dh33GIAKXPFAEK937gmiNKrO9cM1c+gyAsbtVNTvTABVGTBNLIb8soYe5HpVk4ApwSXqfktYuZtW9EbHBMusRE2uUvjczsNj7qOclvBujM2HBMySXA5Fd6yRL+bnzlY0zCT36H337ns+za44pXy4+rUL2PPnUj0fCtFz5JAXEFK3dw31d+qdmW+sfkFgU3xczWyfWjkZh7pkFTG05vyu8Mo3b1YJ3XI383L9pHh9UuUZ0WuHdOsPDtaqemzfvyzb3KZfrIbd6qdGVkUt3TvlCEgmryTSmjkrgooUiE2BZJhhhaTuiGVyF/VSbNGlIiMSwpTYzFcMBdjNQaam31OFXDyDejOL9ec8t3nS+lClfO0wJVlWJan8ovEqRaXcZnI8dy/9j89y0cVZfmYXnetvzceD5ePwh/kXfXyfh4VfXgOGqLrfhin8Qw8TK4WobKpQ1vdDaWd2C2xJWRqwlKappykdhT2BrYmbRCvk/tqYwN0CJYpsdEn19Jj3Po6SyGSXez0a91rkpRE0gnvyWjONNmyHS4ws1qvjKIbkTB2td0zStN2fJLMkSMFatptHe59W05xiqGvPIz+g1/9pa50tItP3sYWU0W01knw+7hUf/oOrcwYI+pFx5LOJlCfkn66Oq9E/WUUTJPg1lIMVZZCU0QZ4QfIp7mox2Z+/K1xWrIjNVm9xpWw7TMu7ey9k2OjtXVZ8Xj6oByhWaRNhbffdoOMRFLx7H8PWw2lrmHDTHT9i2u6Zuw2p+zESuNzO6eKJbi5a9vbfAtpjgs+KZ1Szxb0lyd7HLw1vjn8orxobtJc+rgrf/1g1963n1X/uQuaUBYDb2Xr3+f/f305X/H/v7mV8yB92JLbiPwZ998i1wsAVPu2WrVhwS1tOm/B/K+cU5NVQq0voE9VYHAoYYm/8uTQaVCeaDWplTbI2FOaFEYkrgooUg+umi0w06K4nar1JwpjY2Ft5iqqWLQzj/kguqfbx5RrwmcfglTmBwpVThynmLXguVdOxEr1UXFmf96DtqqLh8bBENTcqNpKwUxdTJNvERwm1x8cU+ijbQy6GSto2A6rGXkaoJSNE25iKkPAouD2bRCeojyqYwN0CZ5tseEBsniwWbvsrMYCU74qkr1epNMKvktGcWZPkOmwtVDZzW/6LBKX1uv+/u4GQOpGCtaX+5QksVYzQT69OhzsnW2EzRXMfIzX4ONo0aVLHaOL23JJiVEzGh6FuSKjtaFevsOpbfTKgf08Ieh1xL/M/GYtW4NynyrYdGq1kX0VrYWj6Eb+x0rdSV6w+n3WfG4OqBcoTmkdWIZfrrkkc4S0CVekR42M8vcwxZOTPtmtxLJrB6sZ/5yVxjFyMzqvbMnmi0RIet722c7m5ubTIrNw7P9njVtUV/OTnbVuPH/fvXnnvex+r//sDQgwoZvPfcJ0qj+xbdpWut/f4RMfvMGWVzp/UrMov3Fl74Y3Ra2lEypbLV2B66+RzVtFw3eKvhH9vKZvQunhCIVRGT2v2iJ/TaMNsTi7bCtEXP4LZTsOT8PqcDMSCi+1X0SgYmrCUpumthYnluY5N5dKxeFt0LZAsz2mNAgmcaCjpHgdPnJRBH7K2bRXRT+mKcIMEcyXd9lspqDKKQaO2odrF/lRXayp+0L57bSlSaNPl0pTzFWc6C+tRF8qIxJGqPeOyFjZsGeGNIPhpl03QPtGZAjOtrVdce7qk9l9YmxygkvWAv+VwyuAvSfupDhsPBZrUvZW6WhbO/V6GGnYml6WHkxO2LaN5eVeKrH+2cHC3pOi5I5vieaHVEhh62ds60TBuv2Tnrr1oyNSTXH6GRXDDlZ9b8aO65GDO96/Ed8Mf4Ln/S+/ZfmGVmMu/79n93neb8cr7yy1fg05EOrMFwzG1xK2PmjDQ/oxWbGgtE8d9Zi+z0d/xzto2UgSTKvT4SzEEmcyyygAFNMcMkxVIuNhVdJzYEF0UIPjAXYnBR+fXKkVOHI+fDDZJink+ri4Mz/pKpLr0+hvjfy7MfUyezlnlx8cU+ijTx1L607UAwJZeRqgpxNk5iRHSF26JSL2bRClqcyc4BZHxMxFuw6Zt1MkZ9seNWg8zsyZn4q+bP0vGkCzJHMUA1gsQgxspqvNCzRWpqprFK9Qda3miNv/eounzHFQqH3UH4VZ6WXodjOTenMYqziySl/DDFJM6Fqu31Z3vjYllLGMaX8WaPj2tTjrauWByfGKhOhx4gR7q+tryUWw5usIZBaUD4Zjx9ptHNkMUyrVClRb2XrWMNZl9g1cLgvSweUL7SMWIafLnnSoUnsdxyZA0zToejMrIfNSSr5LRnlJE2AuXpYeeGGlZ1eBwts3xKavkq9t7+RYfcKjbLInLonClG4/FS/tBDM4CUJSVtO7qrSnq0SvuT/vqo+d1Xw66v/49vs3ycfocmqPlZDwSOf4Kdm3fzNr+/60D3cZPmYZmYrX0qgnwTHByJqv0OGsg3OFhdk1LAVzai948u10x7l2eIjI6rb41nEryRi6Y8vyRzHKcWKRHVB7QlEpZ1qzEUdtuZr0/KZ3CAxFuFAFi7rL1vyM2NIy0YNIW9L+SuJbARdfkPkS6mONef5Lkj+HkLDVmCeTqpVg7IjaCSixeTI/4SqS361sYEY+YWefVedzFfuaYrPWh/0JCvyyaBqO5gDrjJyNUEu84Uwm1bI8lTmCNDdYRHh54WPBdtFd6mUAq8zzjVHLF5+TraeN0WA2dFrgN7CZDVfaVjtPT2Wp+pPhodHG6E3SKrOVKGDx5rDvHlHsmVg/o5PN9TAO8ZqBuSSf9japFWZoqSHVOW0oo6TX3hhsBAap5ZdjjMPOXPmvyRTdL42tVfnPljIqrGOscoMf4zkmwnfbZNnrfb6wV9L5ANPDviLi8Vwl+tABTQZj+uLxBnbAmWYZdBTht6KFbq1Y+VZJxtOJl/KllCEFu2A8oUWhfdHQQPN2nN+xVHxinaeV16XPOlYnR52GlJ0iGXoYeX/GGbWvkWtWFCbLRkVi6t1kHfT1rLIzOTI1ZMWLT89LmdjKSRrKL1mNF9tSYvpZJcDMdv0+zdusOt/uvFtf0+AG39FW6zu/pNw9OY/DH/B/n32Ew+Je07U8OXdT8ktAn79m1+xvzwovg/sL1/8h7f8DV5tytkyMtU2AvRdZ7DR5tsxEdWjbbMTbw72z7gt7S3lWwhtBjPmbb+ow/7n1uQOoRBqne1ArkyrAW3QK1Gc2PXeoCkSJ7Jo0Aw6rVqn4/FPzoVIopi/SKwujDun4uu51aNVpERfIRLdcweeXyVpDQivdvXe+UAkikNJFtVRvFuJF0iH3zDpZbYl2ZnzJKL/LB2sd+jMSk5KqVYNVjDqVcdSTPb8T6y6zK9WDw7WbXnpCj99ueskFZ+7PmhJVuSRYXLdcpAhmBmOMnI1Qc6maSHkboViehzrU5kYoElchyUIPy/0mmFsj1cA9CjJ95QA4wF15UOy/IwsPW+qAFNiyKzVAEOMrOYrTWX36taxOJiI9G1p08wq/b53wL3RXnO6vxgrgorIsVdAjJWTPPLXeyf762c7oqQbRxsD45uDU342cBURbW4er+9bdHxJSylt5Mx/whqdGIWsrbVH8pnyH4fhcX806osdZwlN5RJjlYN6T3Ua1BhGU8SS7LeXNLVe5KPVsGAo8FL0VrzLsLz8kEz+ngZ6nxWPqwPKF1oUKlA/+OrZPmufFdbhp0sexYXoYVOw9D1sCopu3wQ2K1bd99dlVKzh9vI/z2WR2dkTJVC0/PWeCo+F6O31wvlqT1pcJ7sc/MHn/ud3Put979G77/rAX37P++R3fmRsFMCRp2B95T/TgVc+FsOHuk974iCs+772i499+R95UCL8X3zpkbs+8MhXf/7J7/zur3WNbYlZu3Xrlrz0vGvXrjWbuXuXEKx9YX3MDN+9WXU8Pz+XN4tl0m1dvxx5mJKgHJrZy8rKiLTU5E4ye/u3qwJzUqKHJS0Zs2CmVXeJmXk7XDhLWFdXlEyPoLWtW+BTuaiKX8KeF+Rl2dsiyL9YID8oDPSwgiXvYdEmLJYVkP9Xb/1O3oDSc/ddHxD1bcoDsgBnfGbf0X6BQKQykD7JNLdCffvki6Qu+i6btB7EXzUG8jI8bHvaxi4AxDBNK1Sy5p32w1pIxb+A3RwAAICZgh5WgB4WALBsQNlaAMNjL7TBR34mtCjMRpZVCCsv0pKQIcn6qqMLtB4zDlojd+pvnwXyMGw1bJvkAWBlilaoRM0777CqR9sLqfgXsJsDAICVpaAR0JSghxWghwUALB2z20Zg5rC+DitcAEgDHhawLKCuAgDKwLK3RZB/sUB+AIAO2oTFsgLyYxuBJUJtI7D2/PPPv//++++99x77y2i1WsIFAAAAAAAAAAAAAAAAgDScntLGJ5jZCsDqg4cFLAuoqwCAMrACs2Ag/wJh8i/1LCQ1KwcAUAhokxcL5AfzRJUX9mwFAAAAAAAAAAAAAACAAoCyFQAAAAAAAAAAAAAAAAoAytYpGbbSHEnJXK0Veqw6HQdpi1eZx8VIjsguMRAXiQ7SMxkOCwknB2lSocTLn+R0NeRCQ5mLCpkqFaiQ5aTAGpgb1ea7hClcyML7tazoKSr8ybXn5/+/vbdpbSVY8zzTX6C+wu2mpVPg1ubSUAsZpummqEE+szDF4FvUxl0ztAS9sTYemsZ00WCYAm8kBgqkZrrKdzFMmaIxHKxkLs1cusBaDAx3ozLUkYquuzkfYPb3euKJt3wiMyLflJJS8v/HwSczMuKJJ96VT8YLuRpM2mvnQ2GJNF5kJUhS6MZc1V0iHu5bfwDAbjlEv5TG9rohZRpX0sZ4KHiKMN41RJJCN+aq7hLxcN/6AwDaD4ytWxGPLuf6sh10bt8+3m47+s7LZnoz7i1mA33roYSQZhAja/fhu75pH1y9+nkymC164xuMv0FQIcuCCgm2YW/taP/sqeWKV6nL+XDxIVkM55cn92IlMvJyNVlT+taTaNw179RV3RWt+4EEAPgkYLzbFox3Zd0VGO8AAF62NraKvkd/5SHKdMUUgvVQXIDbcbUc+r5Vtmftnvf11b4Ixhg/jqPJXY5lCzTN4E6Myo/HVLf3CSrk3kGFPElaNMqcBNnUxS/zqG87K9GM+svnV/GT53TyQfTGy+G9MlB0bu+H0fxF9hNV3QVVfiAdH/H0Qv5wvRiVND9Qdrjwn7ubeDrSP4QvUj+DN3HyJBOXClfDBLI//TUyvPsoJdIfLsA+9S/KZE/SqvMPf/5HP/md35X//ug//b12tPzyVj2y/7Qf5v7vfyl9CpgjF/Xr//T75PiHf/5r7XDkYLxrFox3Bx7v2tAnk6MOFApVij2mJW98rETjOocV28mY3hqYUc9ThbK5Jn3lBFIhkhxJJBxTLm1nbBVp7o57+ruX/tJTLfWb6c3ztfxMJEL355eeomkpYhwaLkhpfZ9L50uvf95V117zNDleTKemDpXMxNek1uqMU3JEYB4jYzN9mPevv8qxQpMjhLD1+mIq+iLeDLIBCZ68gLN6IFy642W0HHe9yWUBmBi/O7mNpvrBKE7dGh8GR5yGP1fZL1y4euTBqsl8OzqoLNKwaGhUnj94EglQIVPiNPw5KuSR4SsOAXMWJE9C7hbXgyFTSVN9fk47Uhf+uhFqX1wJ4xgYZRJURP5xzScwRzHuPSVp7TQNSgBLD4Vjt4QrylCUn4LB7MM7VaowHwQ5+gtUwkM/ALw9W75AQclkcjbfVxFLyeBKv01WdRdU+oF0ZGymo+9f397oZ+vb7MtjqnqF6KsJUYrFkOVbPOo+vF89kft6cb3i88fEL+TLlfqJvL4/f2a/r+ld7uLx+5e768pZvEf9FaIqXq76Hj3NrDkib3GLy/70L87kYNKq8A9//kf//N/+6o//+u9+/f/9xz+OfvUffppYThX/YioeqX/Cg+DLP/4nFOoXX8nxv/7ZT6Por/7V7d+IB7+8/V3l+Otf/bt/ZkX9/dMf/s4f/If/h0I2D+toeFG4/U+o4/IUnuvBkKlUGO8w3nFKJpPTovGuJX1yPBLDzUIJfbuLprW2qtjr+HjxcC6ffHw8Xb2nZhpXoGmdwwN3js5bjOntQZTWOFL54p0MT71KwmIofgVcDaL40VgCKRDPfqqSw6HNENHfmbnlH4teem55m/nBmM2cXCiC+hWnrglkzsnfT+KpeEj3EuXR6YrSYX3ychAS9NUBqagzzyCBzA55pzPGZh3z5EX5NzG7cnL0cR8XCyFtzXNVlEzbbEB+ycUkVxLrK+WewOXwHOPu7FpeWk/pWyeUvElrlVMoRj03mPHNruWl4z0RyYMfBqGavmoXbr6E8jDxhQpp1HODGd/sWl463hORPHjrEFrrqyMiyU+e0+w6leH2Sch9G6QQT9HbuEIeQu2Le2FiilEReYQEBCr/AcWMd+ZuQyYiPH7tTU24cAbPrCLK6O/LKOVuYmEPAgK3xJEqMPdV3S2kWdk8aiEi7/UVR7xUsSSJJFZOYW4YkYk2D0VUqfx1sleSI+vg+kt0Jci4e1Pj0A79iUCAUNI0Qn9rJM3594s//T3h82d/KW//8k/EdSQNr55/0q4a/bM/+4Xj/tc/ozB/8h8dRy32p3/6Kxnq9/7dX3rD5v0T3nVKUuh06yuTeHadeJDYJyH3bZBCrNREpI0r5IGK2jrTNdfeqmXFFKMi8ggJCFT+A4oZ78zdhkxEePzam5pw4QyeWUWU0d+XUcrdxMIeBARuiSNVYO6rultIs4I8EunTV5yW9Mmp+/VkmBHp15+zz7S4cWWS6WE/+S/kcU2q6pwTf3H+HxaRniRBVM3ySoSep1PquikJiZv7VEQWzKiWYMtri5mtm9fnZWpOmvrUs/quLdnLcffhXGaE2d2ENtFRmScc05/M1u/LqPcl+xntlNh079gX/M7X636SXSJX1JPO7dOkX2LimVnOkJYTxpPFeUJoFYl9TotI5IXGE1CusbC7b9L0uaVdrcyipVqQO41BVi2zeoW+g2jPjvzUIg75dYSR3OZpJcktlDT5OoQys/OlFy3f1/oOGFAhUSFPi7ziCFW5KlWxNHntSOJrL4H2VVhjczEh2biWK9CjWKUWweebUMtNNcRmoHkh8/7kSataQDn9PRkl2TZDtiMkt6r7yUDTmxiiK63ak4paGaV/Ohs2ohEmE2QGszdbytQ+V2zuTF32qb9A7cke2DtzfmkmoJVfArpn/XPITVoFfr1mc07/8e+SSTTAr//v//yrKPrp//Df/0Q7SH75+lfi7x9//e/UrUGJpTmw/+jf/J+//i83/1g5NwrGuwwY7zDeVaUtfbKoS6Ig1HTWTTx9fJ4/v8oHFdhrWgZXPbmzhUTEPDSbXlSjcZ3zBu6GdG4nlJPu+JnTQGS/aFq7htysYVFVVJaTVDSRUzZVC+pgbLlnKxs1E5LED01zloNwfqck1xOf/N6NnQ7lh1250h0vlTvBamimQvlwa3RN8oSkmo0c4SyegLLDsr+eBbSDDZU6Fb9xLzPpO8fszqOlnYNspUrpk9wGtbLkFYqPsjpwHH8gTE4eokIGKKsDBxVyZ3iLI1TlqlbFsuQUvcLjIdS+imtsHlyiHtdyBfo0r9Yi6LVZvX3u6N1TvHkKFezPm2JK6e/JKMn2GbIVgY6vsjuw+N8lVWl2H8799YoWH0b321v2GqCC/rSmMHT8JV9P+Hb1ftNk/5dLrfzPkJe0HfGL/522Avi9wb/8J+peb8P6r/6CprX+r3+gHDW/vP3X/wfNY/2f/4V22BW8f8J450jEeJejvyejJNtnyFYc6XjXWJ+86D1fdinUzcuXK/6GtT+q9M+Du+v3m4uLi7OL0cXj+/3sUIXh15nIDtxt0Xn3UMMOIz92JZOQVOumE/l0ZmVNrQJRQ+0IcvawOkgFrcWWxlbvAOTrK4k866Ha5qHkZ7NjRlYou+UEzfI9LTJzulWzMT+rbTPZ2+9qSUArw6kXymcGFRK0g1CVK66K4teafOCSuxlZ4xTU2OpUE1itRdBrM719Bt49t8tPoYrak6qKmaXxFl1CYI1khj7BVHUHOWym/vcy1RGs798fMmVEe7ndRE98sszhqKI/NzNdzukqNNAOrnrJnMidUiP/fZRPWmPoGaz/y80/UvfRT/6n/yLX+//1z6K/+Nf8jKx/+PM/UhbY//xvnDmwewTjnQPGu63AeJdLg33yYPYm8/iDRpv33Rm1g1Tqn+PRzfvVm0Co+zY7L9d1N09IZ+/A3RKd94GsawHS8yvNwLA+f5CDgtfUShiPgvveASpoTbYwtjofowxkqg596QkZYakfpV5029HsGKAp8GK8MEmlGXMWlplURXfwgbIi6RJ2tPUg/Sfz432oZrJwljpnyRnSuPyc+YaMYq3yCsVHdR3K+wM5oEL6QYVsFQXFEapy4aoo11pmaH68DLWvEu0oB8+4Vllg1Rah3j6ngXk+W+SneKGjL+9VM7+U/lV+AJQRWCOZqRogYlFqVHU/aUSiWZqprII/bX2k1hum6Qxm9z2+aFm+r71cPVWscmH2qT+vg6JrEy1ne3vxnvM/RINJ+0mXNlfV/Le/o40CunruKuPvn/63vxD//ewP3BmsxB/8vjw16/t/+3t5+4t//8//7a9oC9dpamOBnYDxzoFJxHiXp78no4KUEXjM450QzOS2pU+mXL/+qm9Ks8+0UMVhwt2YK7ALnUMDd1M6t5NUExEEXjN9WwhI5AoD8bpNjVx/E5BT2T1HVzfXAPfANjNb5eKF1MFwtK1LYqq2T9NnjieGC/oa9VksrQo76MrsklcacwYbWfR3sRhEFBnfUrcYuRmQ2UonHrnaeqAasRzfmBpBHyNlBaAL9vGMOhvZlWXbpYJam93TiGqIDq3kW/eHcg0tpBXHWyhe9erpYJMMHFAhUSFPi1BxhKpcyP0ghNpXmRobxjOu1RAYHjeJdNOQb5/jpodRSkE0WdcyquTrL6n2A6CEwOrwGsA7k6ruJ42ovasXfUzzJn587qV3HRPVmSp00qw52fcy4f9iZI59Fq9o4sey6QLM+9psIEMIn6yzqMse9c9BJI02alVVJ6Y6XLbutEP/BvnJv/zDn0bRX/3iF+L6b37xF2ajgF/8+5/8zu/+5PZvlKd/+L/i/1f89ye/b7cF+OXtH/0nZV39+//2d+KvDfU//tXeLK2qJ8d4x8B4R2C8q0Rr+jTVIQtE/3y5qrXaeI9poXbwvjYqb75Hw5qdSfM6BwfuxnRuJ7KJ6O9n0qAqW4hotG7Hn2o84rl5unl9ll/s1Nc4BU1l519bJNRjH9PWoz8YsxlLXUkWQy2IoNwwUO4MF/bxMDmRzCwBIN9OcAnzmI/wq68OiKkDhvR9FpZi4ZHuKMUq3MSTW35S8djbwvhFhPZ5KSFWX6We1CwU0NwYmB+noBN37exJL5PjPPW55+mj8GnFvDHthAvdKdmJeo5MJq2cDqmH+0doqq/ahshiJ199eei427JChbQymbRyOqQetgqRCH11RBQWhyBQ5YLutQkVffZC4dxabVj7IsiTgYXVpCQalLN/XPMJTIlhtyyThAvdkbCsB1dfJ8LamFikyDRuFEwhlwL91UU2o1Ly2K1fYB3SOieSXYlV3Ym07CNDpElfpRAZrupCf7jIpE5lSH/iKw+RIb78WEy0PJKYPE+y1pLkceZhVrBw1Fcp9qS/gaqBhtcRJ1RWjzboX5jJgaQphCM/3D/v31/+iRIi+NlfKse//hnd/cl/lB5+8ae/J25++qe/SoIYR8nv/bv/mnIx/LM/+8V//bP0oVt//NdcTuif8KhTkoJSbXMiVLo861i2hdxr4yjDbrMXCufWaoPxzmBikSLTuFEwhVwK9FcXn3K8E+H0VYo29MmJDiKIL64c/Tl7TIuNikRmQ2YQ/vRViiZ1TuqIhVeWoM6ZcNkkCUd91VqSqmXVl05JFlA63aSx6uhJND3Vrsxj1l8LEXqqi7MfP34ovQXfvn0bDrOVpB6b6UX3/b6BRUMhzs7OVEpOAcqt5+t9zO+NR2cP5/Ui2iLo52bnbaGQFjcWVMj9c/gKmcNJdexHTaX2tZmOXr/OUn73N65lOFQd9+ZDIQfMKBDm2Psi6H9YhP7KZHmk/O5PfucTjcUY72qA8a4i6JMPC/QH+8SW15YHZIGjY3A3icyqnyLEj49ktYuc941dHmsQP46jI5rsvmdQIfcOKiTwsk37Wr+Ht8I/ALSL1kHqeMvyAQAAgAeMd9uD8Q4AAIqAsbXFbLynKwqKtvvJpXP7NFnpzXIKGMzWk2jcVZF2x70mTjf4dMSjmjvffBZQIfcLKiQIsEX7il+i1C5XB0OOm93n64PU8RblAwAAgBAY77YG4x0AABSyu20Edo4YHjGbGoAyoLGAYwF1FQDQBo69L4L+h0Xoj20EAAAW9MmHBfqDfWLL6+znP//5b3/729/85jfir2A0GikfAAAAAAAAAAAAAAAAAMqwWtFWK5jZCsDpg8YCjgXUVQBAGzj2vgj6HxboDwDgoE84LNAf7BNbXtizFQAAAAAAAAAAAAAAABoAxlYAAAAAAAAAAAAAAABoABhbGyQenV1MN/omiPB1Jo9ep0MkS/gPYYNbgSEKPVRl/zEW5pU3xr2pUb4sAAAAAAAAAAAAAMDpAmNrY8Sjy7m+3Aud27ePt9uOvgOHBGUBAAAAAAAAAAAAAGBsbQia0FjW1No97+urhigUeAIxFuKNsSVqAAAAAAAAAAAAAIDPAYytTRC/zIeLj/WklKGt86XXP+/qmyh6HZ0p7PJ0tSY9Fn819IQcNXqZul26nhKYhXtgcgRsSTzZi7UbRW3XwvMAxnH7GJXy00zaS8EkWjW9Ku1IDVtkNcoCAAAAAAAAAAAAAJwuMLY2wWD2MRvo62IGs2TF+XL8fL7+EKwn0bhrTYfC/SF6Incy4S7H3bOb5HZ+mfiTcIFerId41B33FlKQlvwoRcWjs8vVRCrycf9+OV6So2AzvUgCrCerS22O3D5GwXI8juSTVNrz4SqRRsbe6VVpF2rYIiM51csCAAAAAAAAAAAAAJwsMLYemOG9ss11bp8m/fmDnVpp3KPO1+t++nb1vdQMzAyb7t1HYhZORMUv8ySGwZ2doRs/jpfDhQnQub0fMiNlKUIxSozodNrzcFQijaL5S7FGjarRTFkAAAAAAAAAAAAAgJMDxtbDMrwyFkBagR4t39fqJrUWvaGl6Z0OWQnthgFdPYN1833FY5A2RILco/ml9i2gbWmrGRcDMUp4lDztRfDMoD1SS2jUpBoNlQUAAAAAAAAAAAAAODlgbP1USHOj3TBgXWKT2b72a6m4Sr56jDuhJWoAAAAAAAAAAAAAgFMGxtbDwmZlpuaX7oL4ZU7GU2MvXb+rCZ7pCZ2O+/PrNsvkAzFKWJSUdjbJNx+uEgnsfSk0/+5CDQAAAAAAAAAAAAAAXGBsPSzL8Y3aI3QzvRkv7W6gu8NaKjfTC9oVQDK4GkZ2s9J4lLjf0VFSWkM1PbTkgf0Mb4wSc7qUSns5I6dSSW8cu5k+zMtaR5tVAwAAAAAAAAAAAACADDC27o7N9KLQNtmfXL931TaivUVyhFNNimIczBbD5VjGd9Z9vl4vhnpe52D2sejpBw/nk6HyHkWd2zd5Rr98IJfhp3YRqB2joD+ZRHJD2Epplyqt1Eay3oA+lZpXo5AypQ8AAAAAAAAAAAAAToqzHz9+6Mso+vbt23BoDW1t5+zs7OPjQ98AxWY6ev0623J+bDw6ezhPm1VD1ItxM70go2fJOCpSXqWWqLF70FjAsYC6CgBoA8feF0H/wwL9AQAc9AmHBfqDfWLLCzNbT4v1+0pfVcHZH0CuzS+xD6qmXow7pSUqtTBnAAAAAAAAAAAAAMAugbH1pIhfojrbvg5mbLOAaqvpa8bohVbee6m2HH9blVqiBgAAAAAAAAAAAAA4NrCNAACnDxoLOBZQVwEAbeDY+yLof1igPwCAgz7hsEB/sE9seWFmKwAAAAAAAAAAAAAAADQAjK0AAAAAAAAAAAAAAADQADC2AgAAAAAAAAAAAAAAQAOcqLGVjtcfxfrGBx2CVOW8o6r+OZs4rhcwhdXBm7rGk2ypF92WVNL22DPE1pB6Ku26LI4Pyse8HLH5XLsOhCgUGPJQrIko5kZVBQAAAAAAAAAAwA7AzNYds5ledB++6xsAMvAa0rl9+3i77agbUJPN9GbcW8wG+nav7LAEB7NFb3wDcysAAAAAAAAAANBqTtTY2j3v66tTxJu63SV5z9HV4JNnSKvK4vDEj+NocncQU+uOGdxNovEj5jADAMAhiacXF2eCi1Hpz1+0AoXhLL3YxCMpziswHJcNJZ5VGxdq6K9INHVSkKe/oCjU7vVP5b7AjTEkML/Upkmyq+kPAACcJvu0ut0dhbRdWkk1DI33yQL/wFHc8UrR/kdB9pf/ecN9/TERtJoTNbZ2vvT65119Qwt0NanK+5o0CPYk7F/DPATCCegBTVocL6PluGsXAPvCkttoqh8oR+Ytq4OTOoPjaFv6xVR0ICkRJJutR3ZuffEWRscCCXQ4JZZi11AcPvH+SDkqNUyuwfiuqKFvMXZIB597/egy0oQDryH0XPyv/5NBCBnMBtACCpL/WdlMH+b96692binPMH/RpwhnvlcUObLGy0N7/Stsz+NXiIe01U7Qub0fzh+8QQAAAOyBzXT0/evb24fgbfblkXfR+QwXFEbBll5spjeXq+s1ua7vz5+77vgTjCseiVALGezj7S6alt6uqrb+4qdY9yG6X6s4bQrEePVw/iTdPp6u3rspgYFQ+9a/P1FRSRZD/pspX2Cg1OJR9+H9SiZ7vbheXfrHcgAAKKLxPq1Wd1fQk+fQuP6CwMBR2PGKVFyu+tWmIO0x//OG+9pjImg9Pxiz2UyW8XEglNdXeawnosnpH0uLob2UzrY5ME/cf8pZ+eYeUs6sdVlfjntO2MTd9caukwD5UDKNP7rW4W3wlJzklsXF8yofjzQZUF7YJ+rOvU1SZWJKOUvf/Hn2hsUcxklLIiIJz8Vyz9ydX+cTiC4UCznzfKFr7sZ8cAkpPwWIvNdXJ04qV4qK3peJrpu9yxGVeqAC5/rX8hNnFpA5cmdF+v4E+TR1FQDQavx9kXhzcrvkcj2yGBHsgOAg5PEHjr+cuFLy1pNhRo1G9acI/T5dgSm9ckLtWf+EVJg8gSktg3j9HftYhrEYgGbZU5/GKd/d5fbkir3pHxw4XDJKCkEUMNRxHzz/RVRcMUfPlNLlx0TQVmx5nfqerZvX52XfrCkezJwP09HwXm+u2Pl63Y9W3zcRLUFeDs12jzSPLJq/OJ84HA/Sx9Iu7O19sfPpaOtGJy4iL2w0vDK+C3XIJ36ZJykb3JHlphy5eZVLMOFuDlfP8DVN/Iwma/08NwODbLp3TKUkakso4fUKIhRdleylUMvnV6WkDEhzNesl/3Oxfl+y6lhY9D78mZ8rKmm8lnz/uiF0bp8m/dRU1fxS7nzpRcv3tb4DAACwTzbfV/pKIrrk0j3y/FKvV3BWDw5mb3akoB9wq2QWTF5cgyta5qCmvmzi6ePz/PlVPiigrv7il6X9BecyuOqZAVOKH+qfOUReqP3qnyBG9YivfikQ6C81h41IZmpaFgAAlKLxPo1TobvL68nz2IH+4YGDk+l41YkdVc/N2Gf+5wz3tcdE0H5O3djq2l5cAr+NuDPthulYZ2SbtL+9BJfzSPogo4hxD8xAD4YlXGVydciHYmHBpZWnHHl5FSYv4akcTt0agoldji/HS2bKzc3AMJ0Ohbc7K9CyfZechNcoiFB0lbKXGfxET63NffWS/5kpLHovvszPFeWr2Hn+mW1WjOqu8bSolCt2BwAAAA4PfWE1vF293/h+J9Iyzui+5KsiHZn4fNmlUeLm5ctV6V969RAjU/98YHaUc+2Og7vr95uLiwvhfPH4fj9L1M8NtVf9GeH34ixFpaaG+O7DeeUXfAAAaIacPq1SdxfsyXdMWsm8gUPi7XjjUfdAhyPXyv/scH+wMRHsmlM3tu6CzFxx1VbMj7KFsT36fksHwh41pRJei+GCptU7M//qZKDslS9XOiQtMtgpjUQnZzSSwS8x9xGnWH92Sb2y8GZ+VVFbVAOUMgAAnC6Dq156nQydmnETPfFpL0UMZnKTOTFCiEDvpT4l1oa+Fj+PHs6f5OD0dsf2tYtHN+9XbwKhx9vs/IFtQpcTSrBP/S2baQXjg4un1NTP3/X9O081AADsjZw+rVJ3l9OT75SskvkDh8DX8fKpKpdzumrMGJFPjfwPDfcHGRPB7jl1Y2uNeWB2BbEgMxtRTkRjHjyoPoCMhKlfZSXCGnJ1yCc9VY6Cl2PbOXPBhBcQTCxNGBzMFsPl+Eb2phUykEPrDCZra7DKZkhOwmsURCi6qtk7uCKDX/z6vNSLKWom/zNTWPQhMplfWVSef1YN6NeBMzG2qJRL1kIAAADNI7po/gtLTsHxrtmpgHzzerl6MuOFoXxcNOBcf9U3udTUn8bE6PzpVi7ZEFJoHJNXchBjEhzx4VApdq6/IbWoU9BAgXYGs/seNnUCANSg8T7NUqm7y+vJc2le/5IDh9vxyl0MNWr705JfLveZ/4LQcJ+i/JgI2s+pG1vlimDTFDd0xnf+lw7a45T5f5int2NUHpTxT0DT1+R3FbpgoqnTkq1VNGJr+wyFTVGoQz6ik0omg8YjWoXsIlUy5hza4USbgarmlSKU8JIUJ5blWskMzMKSe+HJkEDCaxeEN7pQLLyGONBoQxsp2EhrJ/8TQbXfMWnnF32QTOYLqooK+reFKFtfamOi/FKu2r4AAAA0iOiiVy/6mOBN/PjcS20tR3029dpqrNeI1ytaC6n6/ZhGBDu2mDev2UCKEcGTX1S5cSlpAiHhcjURb6b6Pp9a+stg0bP+ASPCvax6X9Q1/YR5XxtdNt+jIRuhgqEE+9Vf43n5DQvMLbWzi5EOJJ6NHrBpKwCgFo33aYZK3V1uT55L8/oLif6BYycd7x7zP2+4F5Gb3K82JoL284Mxm+kF4UeBUF5fFcBW8NqD3siNJp5pnNtC/8wDF7IYajcicdfOWpQvrCNcUaiDwuMksar0JxNzKDr364gXnq0MX7wJgei8CU/5zbv1RZr1oO+YZy5Q4wSzMAXFQ7qjeLJRKJyEh9wVVaIj/NK0f+GSkicfuNEyCZ6Ygwjf+urkEZmWzkIFKwubz/4ClGQyv0CUgt3m+adWKbEROHLoxsCEZ2I7SUSa9RUAAByOYF8k+nPVRfeHi0x3rHr+/oQNHpLFRAdyg7GBwsDHnWBciXt/mIlLIR7qqxS19BeYYPTYq0v6gcT/8BD60wjqHUDDAgOlRjiPfFLFA311nBy7/gC0jWCbarxPE1Tv7uwTis0nVDzQVyl2oH9Il4KOl16TNM5IKhGO+irFnvJfSXJIlEx0qD4mglZiy+vsx48fsmyJb9++DYfZmtBSzs7OVEo+NZvp6PXrLOfrRzw6ezhfF0xXL01hdAdnzxq2P0Mkn6mxNFvjW8VmetF9vy+7NOZIQccOAGgDx94XQf/DAv0BABz0CYcF+oN9YssLB2QdOev3lb4y0Hx3u+5YLn5vcIvHbHRtY88atj9DPh20/MRs13BaxI/jaHJ30pZWAAAAAAAAAADg2IGx9biJX6LU3iLRYLaeROPumaQ77pXeI7oEnuhaxp41bH+GfEI6t0+T1SXfB+ckiEfYwgcAAAAAAAAAAGg92EYAgNMHjQUcC6irAIA2cOx9EfQ/LNAfAMBBn3BYoD/YJ7a8MLMVAAAAAAAAAAAAAAAAGgDGVgAAAAAAAAAAAAAAAGgAGFsBAAAAAAAAAAAAAACgAWBs/QxsphdneecF0fOL6YZdNEWhwJCHYk3iUbOqAgBAPRrvOWsgekTVzdfvVCtiYzwUPEWbOG42//35Sa4Gk/ba+VBYIo0XWQmSFLoxV3WXiIf71h8AsFsO0S+lsb1uSJnGlbQxHgqeIox3DZGk0I25qrtEPNy3/gCA9gNj6+mzmd6Me4vZQN/ulc7t28fbbg5QH8wWvfENxjUAACjBDnvjQyNe0roP3/XN7hCvUpfz4eJDshjOL0/uxUpk5OVqsqb0rSfRuGveqau6K+LR5VxfAgDAHsF4ty0Y78q6KzDeAQC8bG1sFX2P/spDlOmKKQTroZgAt98CzRA/jqPJ3UFMrTtmcCdGu0dUGgAA6J739dW+2H+M+ySbuvhlHvXtYCrGn/7y+VX85DmdfBC/FpbDe2Wg6NzeD6P5ixxgq7oLaAIQXj0BKEWJFyHmxbxpJbPsnJevXJ+nYjDDeNcsGO8w3gGwPfljGRuzDKPY6yg8e0UFRr2Ws52xVaS5O+7p7176S0/FxMePz9fyM5H8bgZza9Nspg/z/vVXOTgQrO4KShQWBeDepIB0MxBoP+Q4muono5iH9vpXvJrG41eIh+RVhEa7+YM3CAAAHATWX/Huyu0Akychd4vrwZDpKztfev3zrr5hnaqVSXJkKHURJ2JZpPaHjPJgn3AljGMqxiwqoqm3e/cJzFGMe09JWk8vuuNltBx3yZ0SwNJD4dgt4YoyFOWnYDD78E6VKswHQY7+ApVwf0b5ilKQL1BQMpmczfdVxFIyuNJvk1XdBeJFfbgQvwlP2TwBQDPEo+44UhPmAhMIRWvumncl0wvFIzPLTr586XVeHp+iT7Q+F730fLxtYR0NF+z2P6GOy6OK68GQyROMdxjvOCWTycF4B0DDFI1l1KskLIZRNLwaeB39ovyj3hHwgzGbOQkugvqVvk60QWaStL6Kp+Ih3UuUR6crSoX1ictDSNBXIEgqU5PiEcjCkHfWl68MXDd7lyMq9UAFzvWv5SfOLCBz5M6K9D3wg8YCjoWjrKv+/opdp3oq+yTkvg1SiJWaiLRxhTzIXto4q7E70d6qZcUUoyLyCAkIVP4DihnvzN2GTER4/NqbmnDhDJ5ZRZTR35dRyt3Ewh4EBG6JI1Vg7qu6W0izsnnUQkTe66vjBPoflrL6O+2G2ozTiAjhI9OOHI/Wg8en2wp9ogIE9U8k0pXRgl27USZPQu7bIIVYqYlIG1fIg8x340zXXHurlhVTjIrIIyQgUPkPKGa8M3cbMhHh8WtvasKFM3hmFVFGf19GKXcTC3sQELgljlSBua/qbiHNCvJIpE9fHSfQ/7C0XX+nTVB7cBpICm97sY5eUY5I4aOguR0cW15bzGzdvD4v+ZxJCX3qWX3XlubluPtwLjPC7G5Cm+jYvHI/mdH8/Iw4sCXr92XU+2IyddO9+/iwm7d2vl73k8IKQt7U4hGBLfRcUfRNIkW+f7su42nST01Vles27I6zNJd1ybYO6HzpRcv3tb4DAIBD4vRXqYVmSU8sR0LbH4bct8J0qsF+3uOBlg1aZ1o1KC+KOuEiTEjWvecK9ChWaeTi801owPIMR9uzmV5czvuTJ61qAeX092SUZNsM2Y6Q3KruAAAvqQlzgnQjIh/R842erafn+8mVXZd0Q73RSnVGPp+Zn8nN/WbGeJfB041jvPOWCMY7AE6L4rGMIftF09oN1tEvyjvqHQNb7tnKRs2EZCAfLrRBVQ7CgTzXyzhoH27figXQHJ0O5a9dN9MdL5V7PjSyaWtrYmDPE+W2D0Wef/bjIPOrUP50FE3LQrvisJpEuwdhtAMAtAXe/9n+Sf9EkKhXZUXIfVt8nbCDx0Pqx418pSGKOuF8uETdvecK9GlebeSi12b19rmjd0/xK0+oUOEHSyn9PRkl2T5DtsL7I09Q1R0AUAJq/Glo1kR0/UQzV2i6itlxbTD7oOWVov1H5qXT63Mwk94UDytjVGwG3j9hvHMkYrzL0d+TUZLtM2QrMN4B0BC+sSxBfuxKd1deR0EiyjPqHQNbGlu9A5CvryQcI1qC2axhff7Q7PALMsjBim14Ue5HF/0+ktbWxNZaXVS9qCWZeeIwygMAjgsz0NnXXj3YhdwTxLuOfOCSuxlZ4zTeCVcTWG34oNdmevsMvHtul59CFbWRlJ1oU4Ithj8/JQTWSGbo22VVdwBATaRpzoOx6iTz+qgTeLmSHcD1s9zAU3rw+LSjjOC+tztLFQPjnQPGu63AeAfA0REaywh5nlD67Havo8SKCo16bWcLY6vzMcpAVunQl56QEVbDfhiA3SBKh4Z8M8rLb+ClGFyRtTWmoVzP+a4qKs8/K3RqUE49kbXMbGLggQTh0yIAoC3w/srTP6mXzQVfbykJuYtOkNZaZtj27S9Lekg3vXRRJ5wPk0jdO70MVhZYdbhRb5/TwDyfLfJTvNDRGpyqmV9Kf09GBSkjsEYyUzVAxKLUqOoOAChNqhkJ0r9pfVYe/l7aoZXYsksttAc13kgx3jkwiRjv8vT3ZFSQMgIx3gFwaFJNRBCwz+RvIUB4RflHvWNgm5mtcvECP2tMdszcKm2fps/Etz8GRBDzXZO+yoXKBdTE2UOXsDVTFpa8KgNZW8eXoh2wkaWqqKD/ZXKM6k2m/VEtsx5EYxw53yozxlkAADgYqr/S+7HRuKd/jVPHxabw2I4r5H4Q5O5vZu+0eGR76fxOuAiz5lV17zI3agjMH27Sv8vk2+fYHbC2h1IQTdZVpvhYSgyXnozKoeZQng+vAaz2VnYHAJRGNiNtc5Tvm7IViYZtBgfqz0yDJw/0NuX0efb1yedT+lBQr+6fOVQPjHcZMN4RGO8A+IQUjmUSb+NJO/pE+Ue9o+AHYzbTCzwqsBhqQQR9ezLQRP/hwj62x4clSwCkb74egAcvRgTQVyAHUQIsX1lxCVe6o4KhQrClESgFGZKVYpEoBbvN8z8xz2wEjhy6MTDhmdhACJFx+gqAdnOUdTXUXwV6TKcfC7nXJtUt2tvshcK5tdqobtnpkQ0srCYl0aCcs9074ROYEsNu84YP7sHV14mwNiYWKTKNGwVTyKVAf3VRMA46t36BdUjrnEh2JVZ1J9KyjwyRJn11nED/w1JBf2opCttepJPTFWisG+sEWDPL+mQulVqj8K+vUpBAV08F7wG4cjzakHttHGXYbfZC4dxabTDeGUwsUmQaNwqmkEuB/uriU453Ipy+Ok6g/2E5Av2pFShsW5BOSXuhNpRpJz5HjyjWAD1CWodQUl2c/fjxQykt+Pbt23DI0rEVm+lF9/2+0j4v1Tg7O1MpAbnEo7OH83XFZSDHwc7r2MmAxgKOBdTVtlBp6NhMR69fZym/1EM/Xx9k9DnU4ODNh0IOmFEgzLH3RdD/sED/YwLjXQ0w3lUEfcJhgf5gn9jy2vKALNB+BneTyCzzOS3ix3HU4IIoAAD4xDjLG+WanvJLdNbv4a3wD8Dm9fkwg0PL8gEAAIAHjHfbg/EOAACKgLH19KFdhFd6d5wTIh5driZPn/DLKAAA7IDBbD2Jxt0zSXfcW5SfKBO/ROnN7g/FhraH6j5fH2RwaFE+AAAACIHxbmsw3gEAQCG720Zg54jhEbOpASgDGgs4FlBXAQBt4Nj7Iuh/WKA/AICDPuGwQH+wT2x5nf385z//7W9/+5vf/Eb8FYxGI+UDAAAAAAAAAAAAAAAAQBlWK9pqBTNbATh90FjAsYC6CgBoA8feF0H/wwL9AQAc9AmHBfqDfWLLC3u2AgAAAAAAAAAAAAAAQAPA2AoAAAAAAAAAAAAAAAANAGMrAAAAAAAAAAAAAAAANACMrVWJR2cX042+CbOZXoxifV0LISA/ohwPmzhW7oVCRGrOttMzRaHAxmOsl8a9qWHdG48RAAAAAAAAAAAAALQMGFurEY8u5/oyl83r+/XdQN/UonP79vF229F3FdhML7oP39V15/b+aA48O1FqlyMAAAAAAAAAAAAAODZgbC0PTU0sZ2olVuObvOmWe2LzfdX7kmPp65739VVDFApsPMZCvDG2RA0AAAAAAAAAAAAAcELA2Fqa+GU+XHysJ6VMZno+o7u2nKy1yUpytqycvBnMcyeoDElcTGPhzlajv5onKiRNax0vo+W4KwMXTrDtfOn1z7vqmmtBMVlTcSh2n9pcoJfCGFXCp0mcVUzWTKJV06vSjtRIFYdAyRGBC3MGAAAAAAAAAAAAABw5MLaWZjD7mFXdGKDz9bq/fH5Vdrr4Zd7v91ff1d3m+yoaXgmBG7KP9hYfkvVkdZm268Wjs8vVZC2f379fjpfaXbAcP5+rB+tJf345iju3b2QO7gvvtHa9czsrWME+mOk17vEo0YKkLceP0loYij2kthUYojBGwXI8juST9SQad63ZtACuEmlk7J1elXahRqY4tLuiMGcAAAAAAAAAAAAAwHEDY+tukdbW9zVdbr6v+tfXPW173bw+L6WtNX4cL4cLY8alTVaZtY+IX+bR8F6b6QZ37sxa+4Aiiowhtwab7t1HYkxOpIViL1S7kFCMEiO6c/s06c8fSk0rdVSSu9XOX4o1alSNxooDAAAAAAAAAAAAABwhMLbuGLK6SZvf5vU5uv56ezWUtleytcpF5TTBNZpfqpXnBO0Ky6105IEtP5dWPEtz69I7HbIS2g0DaC8CIhR7odrFBGKU8Ci/9CJtri6G5wftkVpCoybVaK44AAAAAAAAAAAAAMARAmPrriErHVlb1+9LOqqqe062V2lrvf6qZkHKRf8Oh1huLs2NdsMA2ougiG3Vrh7jTmiJGgAAAAAAAAAAAADg6IGxdecMrobR6vv0ZS53DVAzXR/fja1Vzpg0u7r6SE+pXL+zqZfNQRvKTtRGr4SJJRR7odrFBGKUsChpDq3MuTJwlUggmbcL2IUaAAAAAAAAAAAAAOBTAmPr7hlcDZfj8VyvMZczXedzO6+V9kFdjm/MdqA0z9I9IYuMtXa70HhE6/VzSdtHS2MtlZvphY0lFHuh2mXwxigxp0ttpjdjtbdtMUolvXHsZvowL2sdbVaNY0Ik2Jwitg0kpnrpl4Wkp0h01g9TiZCzlZVG9XTjoTZxbKvH7pJZKDzHg9WwQSgLi6pGGT8AAAAAAAAAAMAnA8bWLSljgCGDZZRYV527KOrcvsnD7slmpJxG8iEAAD3jSURBVNazp5bjD2Yfi55+/nA+EaHzkfbRy5QZpEjPwWwxXOpIus/X68VQW2xDsReqXTtGQX8yieSGsN1xb5EcX1WAVGmlNpL1BvSp1LwahZSpM/uATMg9e8hZq3G2rFgMRfV2jXzu5rxyR+GtEFVJTXYWZdV9+K5dd4mNsSp70xAAAAAAAAAAAAAlgLG1ImmbSCkbyWDGNzR17wgSYjBPHMEURD/9EulzmFIxs1vt27Gi0Xn6PX3tx8YhdaA7I8AXO+FTO2GbGKPoq3lWaAt08oGp5AnoV2kHarDblDtRnDN7IX4cR5O7onS1EJrC7JhXh8Me39Ji8/rcGxZ+kwAAAAAAAAAAAABoHhhbW4+zQl+uji+xE6mH9Xud6X7bxF4vxp3SEpVaoAaVpZ1fTXNtR1Pxh1BzRsnJYGaRqim5U1qjT3hn5/Jwjhf2IDPn2uBOVy3P1RWztm5en6Pzc33jQyXDeJdbDtiI9cp45SWeXnTHy4gmPif+X03yPeqWkEz4kuwElSEJqQOPJxW7CJXV0MLjsWWhIiKxGiadxRucK+vzQzLD9cdGoKLOrz8AAAAAAAAAAMCRA2Nr6xnM2HL9+uvZ45foPjP7tJgtYq8ZoxfXbMSoZrDZVqWWqNEAm9dnc0abZj5+vzeTeEU6ZVlLaGuGJH3L8TiSD2S9YIY6STxKwgkfdg9dLpB2ATDhciIKI6fkPjkZ2D2PzN4PZGu9/vpF3XihQ+rsPr10QFq/b+bJuuegdWlfir7cw8BMTl6On8/VjgbiSZIOTRnJhUmOR2e0K4d8fv9+OeYntqVj72Q1tITKQrAcP0RPxt2kwo137N0bOsdPqP7InT2SfMqvPwAAAAAAAAAAwNEDY+sRwNbGl1jPHmAwqxmyduw1Y/Ssu08pwcn4zKWCSi1RY1es35fpOcqJkTF+HC+HdjPXzu39kBnqzAPaDKFvz05TbLp3rI6Q6VEt95emXbNlAduoITcijtlVV3I5T7bV1YioVi8q4Po9cozIHqRNVEnYfF/1r6972kJKehacgzY0ZvIkdYxiyYVJjl/mSSRyxwRGfuwOobKQeOTkxqvJ181ffyiJ0VwXjiCv/gAAAAAAAAAAAMcPjK0AAEGyF688X4qOWDNczpMjqBJvUedLL2X17HTIDmcXmtMKd4nHtEvkRuTgHJD1saAT4NwJoUIXZdCLX+bFG12QiVF6V9Ngb6+GMh3SJpykz0fB40LJhUkmDzyPyRhqKYqdEyoLwiMnN15NBd34Xfec2Xl5+Ez9AQAAAAAAAAAAjh8YWwEAGVzrpqDc3F1p27MLzWmFexF1IhrMFsO0mW5wNSSDXvwyL5iaKiE7H9lE1+9LMs12z8lCKi2iRbNiiyghuWbeVqV6WQAAAAAAAAAAAGBrYGwFADjIGYfJgVMuzMZJEx1dy2b8Mufbh9KEVokztzEhN6KqDOiQrGk5W6u0zQqNjHc1H/XxfXtba5HkwiRLD8yObPOwKqGyCFAm3gq68TSSNzvbOLf+AAAAAAAAAAAAx89JGFtpClfuSSsbeQp2eZtOVf+cTRw3YjyyOuSljjw1cMbMNukthqSnSHTWD1OJkJPylEb1dOOhbInsNJmFwnM8NFVnOAWNQpkEA7HSbpzL8Y1RlkQlmpvzlDbTm7Fng1NrZRPppSXyEjI52q1JKSO0arkRhdlMH+Z2C1hL9zwaj+fuavYwIgOWiXcyI87n86ytNW1fLEG+5MIkU8nYrUzjkc3DEDkaessihIzXnPgViLeMH4FKoy3uhzm3qRbUHwAAAAAAAAAA4MjBzNZG2Uwvug/f9c3OIXNFz56102qcldN0HH3KEOja/WjK23bY4632ViLeA7XKsN86YyGTYHCGpUiMPCye7OBqKbpNWn8yieSWo/K4+VTlo/X95iyr7vP12q72lwJXaqtSHjAnIgfngCwpOutPbiFafmoqGQ4T7+4dQ9kXcw3XafIlFyZ5MPtY9PTzh/OJCJ1PQMNgWYSgeKllEqF4y/gRhIpbkFt/AAAAAAAAAACA4+fsx48f+jKKvn37NhwWvtu3BfG+/vHxQVdkrnq/z3lxJw9e+0yAqv4ttQNmsaKiUOri0dnDebNxbS/KQ1Y6c6HLcW84XJ3fWQ/C7fG9N1/JxG2pGw++pagtCcW+I61E7biMrDUraSwJ1evPYTPwc9JcKz885eqPr64CAMC+Ofa+CPofFugPAOCgTzgs0B/sE1teJzGztfOllyweFi/0InWS1FSvV1qbrmBPwv41zEMgnIAekClhvJST8MzCYF9YchtN9QPlyLxldXBSlyCXUpv5cvkynagvplOTD94V2zyc4yWkpC+iqlzRfpsmJjrH/fxc3/hQyTDeaSF2EjHdiRvlJc6WSKgaKEpIJnxJdoLKkITUgceTil2Eympo4fHYslARkVgNk87iLZ4rO7ibRGatN2gNVIa2Lsg1+Ha/UwAAAAAAAAAAALSe09hGYDDTk6Wk7aq3+CBouSuzQy3Hz+f2XO5k38DEv1z3ygJIuAfpQ5lByPn52q6MV0HXtHa2L1fMS3UCYYn5+P1eOs8GxTrY1HGyJ6eHZKaiXo7HkXwg1zKn44pHSTjhw+68yAXyjM2JKEz8OI4mT06auueRWeJMttbrr1/UjRe5A6gxztI5QP2+2YbAPXOnmyoRgbcaWMpILkxyPDqzZ8Dfv1+O2SFCmdjlemtXQ0uoLATL8UP0ZNxNKtx4x0V7dNJi7yehfroKgMMymLFdBmQNCE/ZBwAAAAAAAAAAQNs4rT1bpQXSHJwzmEm7o2V4r61Zcm9HaUOLH8fLodn0tHN7P4zmL47pyfEgfSQWLzbfrHP75sZF5IVlBsFCHfw4J3wrAjIzUesHZGrr25N4FJvuHUtIklGhjM2NiOPsuXk5j9K7R4qoVjrZ6/fIs3Wmg7SJKgmb76v+9XVPW0hJz4IzdzzVgFEsuTDJ8cs8iYSOCpIXmvzYHUJlIfFV5rx4A1DFtVEUQ949hn/QLLI7MVQontaD+gMAAAAAAAAA4BNwWsZWjwXSEjilnDt3z1P2L3lQkz4ORkLHb5MPsrEZ98DMwGBYwlUmV4fSJFLKRp09x7zTocyzi9FphbskkLG5ETk4B2R9LOhEH3dCqNBFGZnjl3nxsmkyMUrvahrs7dVQpkPahJ2szVDwuFByYZLJA89jMoZaimLnhMqC8MjJjRcAAAAAAAAAAAAA7IPTMrbuAtdMKFBTs2h6J2HP5vbZXANh90HNqKVtzy5GpxXuRdSJiA5KT09uHVwNyWYZv8wLpqZKyE5MNtH1+5JMs91zspBKi2jRrNgiSkjeU7FWLwsAAAAAAAAAAAAAcFBOy9haY1qo3aFTkJm/Kad+Mg8elNGVpmrKeZkJJcIacnWoQW7UzMZJkyFdyyZtUzpJtg8lZSSBjK2QxmIGdEjWtJytVdpmhUbGu5qP+vi+va21SHJhkqUHZke2eViVUFkEaCxeAAAAAAAAAAAAAFCX0zK2kmXM7qC5ofPa80//oZ0tmf+Hecr2qD3cmAXvNNdQrn6nCybaLuHmFq9Q2BSFOvhRJsGAzS836uRwsJuxZ4NTa0kU+UdL5CWhjC2ZxjSUTLsFrKV7Ho3H87Ir7UUGLBPvlPHz+Txra03bIEuQL7kwyVQydivceGTzMESOht6yCCHjNcddlYi3mFQtl/jcHKh25NaBHA+bOM4J2FoKkyywSSvjuZBKQhqJkUHyiCZlAgAAAAAAAAAAJ8OJbSPQocPdV2pdf5mDvAv9Sw/2bHBa0y1nGg5mH4so2biz+3yt3LXFS9mjAmHTVNVZQybB4AzLnKj7k4nS3BcXre83Z1lRouxq/5CSJdPoHpDF8osjtxktPzWVsjrx7t4xeImUJF9yYZKpcvT084fziQidT0DDYFmEoHjNphZl4t0NInvqbauwmV50H77rm9OCJ612/nAaEVITdULcxz73RAEAAAAAAAAAAI6JH4zZTG9EehQI5fXVJ2UxzO4emg/t+1kxCNiS6qW0C2o1FqF6JM1qDJ9bNUKV8HgrZ6Hmh01as7HvPi2fvmMHALSCcF+0mPTlJur9YenOkMZORnYYXS+GZmN25+F6MREPfL2uDRBQQzzRV2kq65/SXuAmIF9gKGkSKdr7q0K466s8mi2Leo/8CE/66jg5dv0BaBvhNtV4nyzwdLwFoZIAfW8HJx7oq+MkrH+T+Z+byXnjSFJgATXEE30FjgFbXjgg63gZ3E0is7QftAZnYwG5L8S2e/C2FrOgnDDzcp1F65QXkotpLNzZ3N1X80SFpLmf46WcAO1Znc7j4cvXXffA3GXmyfHhcye30VQ/GMWpW+PD4IuQP1eqCheeNPJgU8B8Ozqo7NJ4ouFCmAyBTydONkYuS5eYFZLeNEL4NWnhwTXWJ7ml8g0AAE6DzXT0/evbG/2Cfpt9eSzfxfHXqtSqItHXdh+i+7V6vzIPN/Ho4uLx+5e7a/MGnCC62YfzJ+n94+nqvVtejXr6O9Ze8UrINnzKF+hPmkak4nKlXnJrsYuyqPcIAADq0XifLAh1vDmh4tHl6nqhHr/dRdOj3NitDo3nf37RBMaRzfRG5L8MuL4/f+4mb2bg2IGx9Yjp3D5NVmaXTtASBjO2y0CFfSGODWl4E6mT0B4T6XFBjPS0yYJ8fv9+OWYHdi3Hz+fqwXrSp41m5d4MavJOZnV6PEriIf9682CK/1kNS4Tc5SLTFriStMeC8cDdUyHn4/d76a6Kjd+WSHJW1WDScnRYjh8i9Rat80e7ZyiVCRZvjHI/ZrMhCZ3K1u+bzaAzJ+ixtMjsKZ+NAABwEsSPz+fJhkXd85XZor0+9I47Wb/NBh139OsMZm9vs9uB73Pt+j2yuxt1BlfD9BmtQWrpLxRJhq/N9GHF9mzKFRhKmoRODogmT/c9fV+ZHZQFAADslcb75HDHm9uTv8yH93a46XSjl5zDoE+JpvM/v2hCCC16Cx2wM7i9H1Y8bwa0GBhbjxrau7GCMeOQWz1+IiibLUdua9J7wFrsuVtq606Tug6NC+40azFsR2LcVrWNjhWTFxr7QG7UGzzpjdh071guuv7ZnGGZ6enM3rw+L+1JbIOZ9eAoT7pH7EU1dWhccluY5DxVM+TrUD5/CjPBEohRWlvVmL75vupfX/e07ZVyL/e0virZCAAAJwB9g2J0vvRKvxLZ4fRi5LzLqXdc24+XY3DVS3btF0oN00eOBthCf40YGRI7b4HAvKSRqdW+XNZiB2UhqPcIAADq0HifXHJMSYeib3YPejrrJp4+Ps+fX+WDE2cH+Z/ge+QfRwazN/b6Fr+sUvNhwREDYysAIAhf7UCY3Wbk4GQHDAFZYblRkDywkUIaDS1VhpCO/C5LC9oltIxdud/em+PAgpM51+/L0CYOXIXuOTNopnRLbguTHFQ1RFkdwpTJBI43RiobaSVVPwpur4byh4a4WxYqsn0SAADg9KGvfYa3q/ebpMMWQ0v/fBCP1MYrpc14g7vr95uLiwsR4uLx/X7mHeh2Qfi9MkNO0tQ6kOC3wZ0SLouajwAA4GCk++RyY0qmJx/MFr3nS7kw8+blyxV/awN55IyJnkzWg4ggNI5sphcP0T3mxp0OMLYCAGrhbEpD7GZkkMZLuyEBLWPXmCGL9gegHwelzI3bUZDkoKq7o4lM6HzpyTmp6/clmaa752R7lbbWsq/UAAAAyjK46iXLAOij4PPo4fxJDhxvd+W2jItHN+9Xb4KPt9nb7PxhX/u7bablba05SeMfLy/ndLX78duPUxYu9R4BAMD+yPbJZcYUb08+mOmFmTTJUggBJcgZE4uGS884Qju130RPfJYrOHpgbAUAVIbsc3anTx/SA1uJQWN/LeKXOd/v1CNH2RsXziJ2hTPX0oUrTzKLTzErTHIJVV2q6xAmnAmcQIyDq6HIp+nLXK79VzNdH9/L2FqbTAIAALSd1BpDOYVou2n8ov9dRudPt3pzPfF39V1e5UHGShZv+YWPW+qfXRSZJzCcNL7bkhi3hrU2t2++LAAAYL803ieXGVM8oVzoheb6q745aZrPf0NhJqeQhtaXqyfMaT01YGxl0Ly0xj+u+4QWRrRxTgj3kONhEx/lAYKFSRbYpJXxXEglIY3EyCB5RJMy9wrtwroc3xj1qUq7aSED3tzsMh6P7GavIcRw51hnGdaiJ3It2TTWbURieMwuXZfbkZp9VWWWqxBKeev+MC+1w2hhkgVeVb1Jq6dDijKZYMmJkX6ZjcdzHZb0nc/pd1b+eN9IEgAA4IgQ/d7qxfwUoTMtUlvjUa9MY0PSMQvEOxSt5ZShNjGNDqyzFBKjZ92Riqcvq94XdZ0D9dLvazP+bL5Hw7Kvh7X0t3heHvME1klaBZoui3qPAACgPo33ySU6Xq8ZUPVvAtHdXa4mT64aJ0vz+a/JPsofYqShdaaOKBOR5tqJwFHxgzGbsa0kWo9QXl81Be1Hmd6jcmt8QrePyJ4JniLk3n4KNT9s0hqOfSdVLYdajaWw6lKmGEzmOBlFvvXTiQmYykl2q31n8sVKkbEwDdgDzwp/DVPSkexzD+tmYKHsI+YtpKp2FzeOTCatgg6uY2EmFMYoITFJaPeOk9bHJzDtpxpCkr4CAIDDEeyLRN+u+r3+cJHp6FSX3J84HaxgMdGBvMGMRLfndbp3wul8/WESxAN9laKW/oTo271RFQgMqxkckQjhqK9yaLos6j3yIvzpq+Pk2PUHoG0E21TjfTKFst2Vr+P1OFod+kNvXCfcp+0g/0OPAuNIZrCvPSaC1mDL6+zHjx+yTIlv374Nh9nibilnZ2cqJY0Rj84uo1qLmXLwCd0+os30ovt8vc5MNQ+5t59CzQ+btGZj33tamm8sVRF1/uH8GCsm2DOHr6sAAHD8fRH0PyzQHwDAQZ9wWKA/2Ce2vLCNQCynhwsupnZLk8304mw01Qu91TxuctLYid3kdjGdJgLMBPxKMMlWtJKsxTENY+HO5pW/micqpAhFB6Avx12fLjwerqzrzqRzmCfHh8+d3FjupW6ND4MvQv5cqSpceNLIg00B8+3ooLJL44mGC2EyBD6dONkYuSxdYlYI3XGJwq9JCw+usT7JLZVvRwUlm5XRwxz7eQIAAAAAAAAAAODk+eTG1nh0Zs8Ov38f820l5+P3e+k+GyjzWE/N515PVvzY1OV4HMkH60k07la2iXHJUnRisVO4Gl6O2ZE7y/HzuXqwnvTnl6O4c/smruSCgcwMwniUxEP+9VaLFP/ztZ3GnkqchitJh54bDznZwnMvdVsiyVlVg0nL0WE5foie9AOZP9o9Q6lMsHhjlJuDmu06aVvxft8czET7aDp7e7G0yOwpn41HxWAmm4S0FZ/JBB5hIgAAAAAAAAAAAAAq8bmNrfHLPBqajZAHd8nmUURiIIsfx8vhQpuKOrf3zonf5kHn9mnStwcCucwvlcnJkBzywyVL0fa8GUW+huYBmfpCp64rNt07ZrFz/bMJh/KA2LRNbPP6vOxP7pQrHXquPeRni3t0QCAzfUnOUzVDvg7l86cwEyyBGKW1VZ2BRCcZXl/3tO2Vci+VGS5VsvG4kBlpCGYoAAAAAAAAAAAAwOnwqY2tqbO7pUnO4h7qze+658xyx8MHj1NPb3Js9kEmBRxLLFlhuVGwgob5dDpkS5TL2wlaxq7cb++HRoHQZM71+zK0ArxMthDJbWGSg6qGKKtDmDKZwPHGSGUjraQbefzg7dVQ1gVpqS5SZPskAAAAAAAAAAAAAIAWgD1bD03mrLrdnCEkjZd2QwJaxq6hqaoE7Q9Q2ty4HQVJDqq6O5rIBLK1k7V1/b4k03T3nGyv0tZ6/XUXJQoAAAAAAAAAAAAA2sanNramp6LSFM4Adj9OgTPTk4WnSZvVln1LBZjkDBU0zIe2EZ0k+5165Ch748JZxK5w5lq6BLMlSGGSS6jqUl2HMOFM4ARiHFwNRT5NX+ayEqiZro/vZWytTSYBAAAAAAAAAAAAAByMzz2zlcxj9uSkeGS3Uk1Be6XajUXluerMpmrCb6Y34/zNOT0oyTdmo1ea0+keFyU1NBvBhjW0pK2zDGvR20wvkk1jRYxsFmdq2wKF3I40Sf6FCZGbLUEKkyzwqupNWj0dUpTJBEtOjKKwluPxXIclfefzeaGttZEkgBpQXc7UvRwK/ed42MSxdhe1rUqkAAAAAAAAAAAAOCo++TYCg1mycvzhfKK3Us0gz49fKW+pc9X7k0kkH9Q7b11Ktme209r51C4CpGFPP8/R0KLsx5l18IPZYrjUYujk/cVQGS5JvNJfQo+y2xiEkp+TLTkUJTmkqj9p9XRwKZUJlpwYScPIWlfduzBNJAHsAVFQ9Tb52Ewvug/f9Y2o373kYwMAAAAAAAAAAABOi7MfP37oyyj69u3bcFhozmsLZ2dnHx8f+uYgkA0l3zDXNPHo7OF8nxGC0+DwjaWFNN5+QwLT7nT/fg+juh/UVQBAGzj2vgj6HxboDwDgoE84LNAf7BNbXjggq904q+zlGnPs5wlAg7yKJqbhe0nQdhka40xutjFSy5RcTGPhzoKmBJJldbyMaLK2Cdy5vR/azUEAAAAAAAAAAABwSsDY2m4GM7bkHmvMAWiW5fj5fP1BrCf9ZP/lC9nWtPvqMr3JajyS+1/I5/fvl2N2hltGoNwloh/xQ9/koXP8VDQAAAAAAAAAAACcCjC2bkHtPRyrQJFYYGkFoFGG97oF0zlw0er7Jorix/FyuDBtjaah2gPMFPHLPAlHB5zJC41HYJacg+wAAAAAAAAAAABwzMDYCgD4tPTPu/rKsvm+iuRJbIbLeeQYTckDCyeNqhaPQB/d86AhFgAAAAAAAAAAAEcMjK0AAOBCi/4ddj6DHQAAAAAAAAAAACcBjK0AAJAgl/jnbaia3gNg/c72bC0JhcFZdwAAAAAAAAAAwOkBYytwcY5cL0Gh/xwPmzjW7vGoUqQA7A7ahXU5vjH1UdTNVOUcXA2j+YN2ike0zUAu2R1aUzsRgGOnare5C6iiyhPeQso0rqSN8VDwFCWjSUP485NcDSbttfOhsEQaL7ISJCl0Y67qLhEP960/AGC3HKJfSmN73ZAyjStpYzwUPEUY7xoiSaEbc1V3iXi4b/0BAO0HxlawHbVPCRPDavfhu74ZzBa9xLwFwCERdXo9icZd9YvqcjVZp2r4YPYh6qt6/nA+GWrnINI6e5n8QN28Pi/7118xsRXsk72c6HgYnNFkd4hXqcv5cKG2FlkM55cn92IlMpI6PEqf7ANtl1XRXVHiSxQAAOwAjHfbgvGurLsC4x0AwMvWxlbR90iTg6JMV0wh3B5KoD4W4ZPQ52VwJ4Yu58x3AHZK6re4c0s3BuPoeBjM7NMv5lissEDtezaQD8jWOrxPPALQAHTo2n7Zf4z7JJu6+GUe9Sd3qhWrGfByv5HTyYf4cWy7ps7t/TCav8gxuaq7gH7T4dUTgFKwN6nM65HAfdFiPtiD5P1JOTrvU+oVS3Ii71kY75oF4x3Gu2bJ79NYj2QQvrwdXaD3SyTAdNQm6pQ7wcLJAg35PM5y387YKtLcHff0dy/9padO6uPR5Wo4POVx7Nh4TWo5ay28yzPO5GbL3DaCi2ks3FnQlEARqjteRstx1wamocuuzQagvVA1t3V+M32YV9t+Vfxgi+wvWHB6BH5r8O6TPwm5W1wPhsxI2/nS41tTZPtwkiNDqQvqojUs0lAfzpUwjqkYs6iIpolIprJPYI5i3HtK0toZTSgBLD0Ujt0SrihDUX4K6JsJ+5piKcwHQY7+ApVwf0YFhuN8gYKSyeSktjeRM/LpbbKqu0C8qA8X4jchftYBUEQ86oofBXLCXHgCoZliaL/aUhPvPl/LYALVNVH/dxPduw2PXrGUePma1uwiMtbR8J7W7X9CHVeqbyZKdlwY7zDecUomk4PxbocU9Wl2vopkMRQd3JXq17IdnSDtKOq97dNonWGq0oNDUbPcRfNNj2Ven8db7j8Ys5mTtiKoX0mf2i3zQzYK8VQ8pHuJ8uh0RSYsOQ4XPmm5CAn6CjSIKiJeNkmBJh1eUlrJFZW1CafKXfoOCUwCGrIuoCHQWJpFVWqNaRTlEE0DlTwPkaP66ohI+q6kh3OuU52bfRJy3wYpxEpNRNq4Qh5CfTj3wsQUoyLyCAkIVP4DihnvzN2GTER4/NqbmnDhDJ5ZRZTR35dRyt3Ewh4EBG6JI1Vg7qu6W0izsnnUQkTe66vjBPoflrL6O+2G2ozTiAivowgWalxuw3NC54RKE9Q/EU9XRja7duNPnoTct0EKsVITkTaukAeZ78aZrrn2Vi0rphgVkUdIQKDyH1DMeGfuNmQiwuPX3tSEC2fwzCqijP6+jFLuJhb2ICBwSxypAnNf1d1CmhXkkUifvjpOyurv5A3li5NRKZJ88/r0OLo5LSIryHbLZ8n/Q1Gz3ItK0PisXe6HwpbXFjNbvfsO0qee1XdtyV6Ouw/nMiPM7ia0sNZmv/pktpnejHsL9gEDHB6zUCLqfL3uqwKV6ydsOdE01KW76p+WnNhwtOJEXmg8ArN0MucIAdBK+C4D/OtrCQYz72QBcBo4/WRqoRmb/ywrkKk4IfetKOxyfZ18oA8v7PxzMSE7t0+Tvlq8kCvQo9ime8eyJW8QEfD5JnLHDj1folE204vLeX/yVK4pl9Pfk1GSbTNkO0Jyq7oDALykJswJvI2Itn3nk/UoWPR8oxyd6Y1p5LKxS/JB/daqbLdVAox3GTDeYbwDJfs0hWwfptSzHZ0k5ZixFsB00ApqlnvRWGZ9Hm+5b7lnq3f1bJL44UKbFeQg7MtzmFrbiNtWJLItmO6OoN1peImm2pgcDi0egT5oKyAMXQCAI4b3drZL06+7Ev5LIuS+LYVdbqCT9/XhhZ1/Llyi/qGUK9CneadDvyPsik9aRJkDvTart88dvXvSiid6ey791aSU/p6MkmyfIVvh/ZEnqOoOACgBNf4Myefd5Fye9bto9ddP2rU/v8wZQAazD1rTKXqKqEFTq4T3TxjvHIkY73L092SUZPsM2QqMdzvA26dZ5EcPXW19HZ3XcTCTHZriYcXMDaA1lC73grGM+Tzact/S2OodgHx9JZEYYQ0wtR4VmfnamKEHAABlMBsQ2Z8K+udEyD1BvOvIBy6ZvZB2SuOdfzWB8jWLbTuY/xOLXpvp7TPw7rldfgpV1J5UVX64VNO/BCUE1khm6HNnVXcAQE2kaS6MnLlip48aU0/BZD/qLl6uZFdx/ZwclLBLMN45YLzbCox3R01en0anXiTHsCW4HZ2GO5qeRHDf2531HdSnUrkHx7KUzyMt9y2Mrc7HKAMZoENferJGWLJmGxs1favi5yWBViFLW55EGSBdHeSXiopQGHwnBAAcMbyf9HRp6qfCIvM7MuROPzDNd31O85+6Qn14YeefC5NIP73oZbCyQPG7gl5WTZILBxf19jkNzPPZIj/FC90lHYRRMfNL6e/JqCBlBNZIZqoG2PkEVd0BAKVJNSNB3s9g6hzky1Rp0w9/We3Qmu36vbkHjHcOTCLGuzz9PRkVpIxAjHdtIpVVgkCfltpCgGE7Oo7XEQXRGmqWe95YFq4hR1Xu28xslYsX+FljsmPmpmr7VA72bH9XnavMQi2/VfHuFLQLKu1lcoopfWh07eJy5yCz7048ooUyuWQbpbcbBQCAY0H1k3o/Nhr39I8B6jDZFB7b14XcD0KoDy/s/HMxS4JoIYt+Gawh0L6syp8Z8oqRHk3k2+fYRNcUlIJosq61Fidff4kno3IoIbA6vAaw2lvZHQBQGtmMtM1RvlrKViQath4c4lHSPdJz9TJFnZzpBRJXD07vSNMfc425lcB4lwHjHYHx7pNT1KcpUpno7ej8vV8CtVzf1FhwCGqVe85YFm5mx1buPxizGTN+lmQx1IIIMpYayHg6XNjH7EQyswSA+06MraUREvQVaJBUOTi3puQI4+h4sMXdn0zMmXRhgdq3qRopj6BBRDbrKwDazVHWVafzohsNG/eCY2VwDK1LqMvNXiicW18fTpAnAwurSUk0KGeSI+G54RWYEsNuWSYJF7ojYVkPrr5OhLUxsUiRadwomEIuBfqri2xGpeSxW7/AOqR1TiS7Equ6E2nZR4ZIk746TqD/YamgP7UUhW0v0km1KdbanfaUhLKNj3sllPeQgHyEZ32VwmnXHiUIRxEWZ8i9No4y7DZ7oXBurTYY7wwmFikyjRsFU8ilQH918SnHOxFOXx0nFfSn3FDYPJFOSb5RXjr5lWQue+B1TIQX5biL8K+vjpMj0L9GuQtYgbKGlfFZt9wPhdBTXZz9+PFD6S349u3bcMiq9VZsphfd9/tK+7xU4+zsTKUEtJF4dPZwvq4wT3nnFeYzg8YCjgXU1bZQqQ/fTEevX2cpv9SpP19XGQYa41DjiTcfCjlgRoEwx94XQf/DAv2PCYx3NcB4VxH0CYcF+oN9YstrywOyADA4S2Pk1O9KS5Xix3GElQAAAHAgtunD1++5x7rsm83r82HGk5blAwAAAA8Y77YH4x0AABQBYytoiMFsPYnG3TNJd9xbVPnIGo8uV5OnT/iZEwAA2sEWfXj8Enm3sD8AG9oeqvt8fZDxpEX5AAAAIATGu63BeAcAAIXsbhuBnSOGR8ymBqAMaCzgWEBdBQC0gWPvi6D/YYH+AAAO+oTDAv3BPrHldfbzn//8t7/97W9+8xvxVzAajZQPAAAAAAAAAAAAAAAAAGVYrWirFcxsBeD0QWMBxwLqKgCgDRx7XwT9Dwv0BwBw0CccFugP9oktL+zZCgAAAAAAAAAAAAAAAA0AYysAAAAAAAAAAAAAAAA0wGc2tsajs4vpRt8EEb7ORrG4oDMfS/gPYYNbgSEKPVSlWKBQrlYaC/0XRt14jDls4rhewBRWh7zUkSd6FlK4MCHbpHQnnFCKymhia0sb1G68T9gPR6o2AAAAAAAAAACwBZ/X2BqPLuf6ci90bt8+3m47+q5dbF7fr+8G+qYKndv7Y9njdzO96D581zc7ZzO9GfcWs5w8bXN98HF6KcqD15ZTShcAAAAAAAAAAAB2zOc0ttKEq7Km1u55X181RKHA/ccYRavxTa25e5vvq96XHDtU42lpFcHUxY/jaFLLfN1WTi9FAAAAAAAAAAAAAM3zKY2t8ct8uPhYT0rZATtfev3zrr6JotfRmcIuLFarjGPxV0NPyFGjl9HaxcgpgVm4ByZHwBYzk71Yu1HUdq0uD2Aci2N05+6F0jjNuhdNiXWizmaKwcboPAn71/gSK+DO6oFw6Y6X0XLctbr7wpLbaKofKEfmLatDIGM304d5//ort0FnE0iCbT6GSjOUM/tmvykK5bnPndxYkaVujQ+DL0L+XFVt4cJrC3mw6WK+HR2cHsAXjS8i7RgKy/LQOyWbwpZIbCYKkygNizHrqgLrxAukj3BcRJHaAAAAAAAAAADAafODMZvNPo4Hoby+qgcZW/uTtb4rRhlndQh5M1xk3I0J17mV/uiqSnTEYmgiEbAoyd3IomtHFROgToRSgAnFpCl3Xyyl4aFYupwYM1FyT4mz8s09pJxZsq0vxz0nbOLuemPXSQAv7mMl09wnUhJfgdIMBayFkKSv6pDoau52lyLuzOqJ486ulUwrJnXrhJI3KvbkikfBfCce0sGMb3YtL4vSlRORN2wgDzkqbOLsxEw3TGs3Cm+MPHhyTVfGM7vjnrmfEmoXIcLoKwAAOBzH3hdB/8MC/QEAHPQJhwX6g31iywvGVn1XjGNeCJkd8r1ViU6wXjverQTHbsMidN2z98XkKe9zL08oSEhySnd7G/Jg78kDdzdwBfLCsgcpb/aWi/LgBkvJtGHtRch7KGAttmsse0yR11HgykxuPTLZbSqUvbexhJoYV8NeV9Ahk4S8iHxh3bhSvjQp17zEhmUFYnRTZ5IT8mzvXfdUVCXBjwkAQBs49r4I+h8W6A8A4KBPOCzQH+wTW16f94CsWgyv7Jr5zpdetHxfq5vUYvL8Rful6XRo3bZdlUtLm4nN9xWPofP1ui8vyD2aX2rfAtqWdvU9WQJcjhJpdNzLsX5fRqHdXQPZxZ1pd1QnKcHE0pldxp0vbmbkZpSrTK4OpQkkUBIqTUlewIOysxTl1BMe1CmLlMzktrhFBJpYkLI6ZMiLyBM2Nw85JRObiiKgLXe2qaO4l8+vJGfz+ryUu0mE4iqtNgAAAAAAAAAAcLLA2NpmpG3mcsWmlRVhpqBZTvkY9UBiB3p+9sIYXX0210+VUZ+ZgoKu3sRqspeIdlKr6fOFtLZaW6sELQgAAAAAAAAAAPABY2sl2Ky41CSuXRC/zMmiYYwYNOmPSM8rddzVFLRtCKWRRUnubAJsGWpMC+VpyUx4LJFYZXRdDKP5i2ttrZBRuTo0Qqg0j5etUpRTT6qXRXFBB5pYkNr1oWJENfKwQq0OEUrd4IqsrfHr83J4LxMQimurogcAAAAAAAAAAE4CGFsrsRzfmEPEb8bG8rBLrEVjM72gpbqSwdUwmj/oI8LjUeJ+N+lbDdVcOn6QeEmCaZxfmlPIyb2arVUtRh4/KqsnO9I8hEqL9f8wT1t3Q4mlCyba2ou5HahkRhXq4IeKp4JdOVSaLWKPKQrVk3plUaagvU0sbTWU1KwPBm9EIWQe6gZXMg9L1uoQeakT2izHl6zVh+KqoTYAAAAAAAAAAHBawNhqIctOkXGiP7l+79LK9O64t/iYVbC0+CiKcTBbDJdjGd9Z9/l6vRhqA9Bg9rHo6QcP55Oh8h5Fndu39STSD85ozXJqae82aexPJpFclu9Ne6FkqdtKresvk3uF/gOJpbxRekoo31QmKDuQMt4VZpSiqs4aMk15pv2FCJVmi9hjikJ5Xq8sigo63MRYbbHUrA9EMKIQlIdmH4ySeViU2ALyUkfZ4W7nHIirhtoAAAAAAAAAAMBp8YMxm+ndLo8Coby+Ol7Wk2F658PqLIbZ/ROD1IvRnkKeQyNpOREqFYnLFkFz2LqxtC5F4FQ5hY4dAHD8hPuixaQvt93uV//VIwbEKBou9J0hKHC9GOoNvrNx2UfiWVogIR7oqzxqpyVRLZueQDIFuaFchBd9laYlOq8XE/Eg+PtGeNdXx8mx6w9A2wi3qcp9muyuHFjnlHqY6rZMd+YZbqhH0888PeHe9M9TMqfjbY/+Gv+YEoxrC/1BG7HlhZmtB2X9vtJXVXAWCMsFv+W3Eq0XYxl2J/n4GNxNIrMiu4htSnN/nF6KAAAAgKpspqPvX9/e6Bf02+zLo7P8oQDaQ2al3rMYYYGb6c3l6lq+j63vz5+7fPlQPBKPFupd7e0umsal154waqdFDPPdh+h+reJPLfLwJ1OQG6osrdB5E48uLh6/f7m79gQBAIDy1OvTHGvjYpg6RYYb61hnlzOmxKPuw/vVk3y0uF5d8uEmn6b1DyuZ1/G2R39F1eG+vv6g9ehJrRLMbN0zi6H300UxzmHmVWTUjLHEzNbaaTlRKMtK5kjt0iyPEKyv6tOuFIFTRVQZfQUAAIfD3xeJlyr2Y0gMdgW/jRJoYBSeF0N3VAwLFE+4TydgSopvaVFxX1o3LSLysM9AMgtCeWg2/3ekc078xz6WYSwGoFmaHlMM6TDZnkyTN6a4eB/tR/8yShZGckD9JcLJN6aUjquC/qCt2PLCzNZDMpjV/LLfuZVfRRRVZNSMkeIr2P+xdlpOFMqykjlSuzT3y+mlCAAAAKgAHbrJ6Hzp5W+/baGjRXuL7A+pHIGD2RsbP+OXFZs7M7gazh/0dNZNPH18nj+/ygcVqJuW+GUePB82lMz8UOU5Rp0BACBE7THFsnl9jq6/uv2UPjzh7OxixGZI5o0pnI3o+gKPMjSuf1klczio/oIaw71DFf1B+4GxFQAAAAAAgN0Qj+jYwfqfHjfTi4fonr+7DWaL3vOlPKTw5uXL1R6Xs4v3xf75IB5dZF/lc5KZE2oPHKPOAABQgoytb8DWKb9dvd/4FsZnxxQJbQR3dtZ9OPd+ftoNHluxJqBkDm3Qf5vh/hD6g10DYysAAAAAAAA7Qc5n0VONLud0VXJbOIK2qbuJnvhkH8lgppeQ0JP3pXbdPWsR1/Po4fxJLn98u0v2nctLZjjUPjhGnQEAoJDNNGirlAyuevMXt+MKjSkCZadd378/7GvP0JD+OUrm0AL9txru968/2D0wtgIAAAAAAFBAat2fnPtYvNiPb62j9mKzL5D5AuX75svVU8EkF1pzeP1V35SmXlpoB4NldP5021Eqib+r7/IqL5k5oSpxjDoDAECImn2awbeHQB6lxpTOYHbfK3kq8i70LznwBTmo/rWH+4Qq+oP2A2PrFmymF8mp6wE2sT4itoznXUOz04/wu3wjatv8b0NBNIbIGnz7KgFKH+yUVnXvIWUaV/LgAwpPkR1qm8Kfn+RqMGmvnQ+FJdJ4kZUgSaEbc1V3iXi4b/13zuBusnoxv+vix+deak9PlSEX09I1IizQvG/OBtJBSOb1bGMyVni7XE2earyV1kyLCBY9m/fATfyy6n1R17nUC5XhGHU+MQ7RL6WhYs72z4zGlbQxHgqeIox3DZGk0I25qrtEPKylf80+TZO1VYoRgfY8kQI38fTicj680ta+nDGFtB+ZarWJRw+lNw3dgf45A1+I9uifRziu+vqD1gNj6y4RI0f3gX09xwYcLeCkCoJ2bRvf7PnHyTGD0geflhMeg/hQu0PEj2Hx1qIPiF0M55f7fjHcOSIjL1fqcNz1JBp3zStOVXdFPLqc68tTonP7dPVyQ29fZ/RGWGWNo8gvz7rCkMD4Zb5cztW2rISTm+I9TQW5uHg5v6/bsmumRfQl99GDDEaby6XD+ZNZFKos7dBZvX+fnY2Xy7EsoZPrDI4cjHfbgvGurLtii/FuqzEla+sbzN7uz99vZL/UvXzuLdZGYt6YMph93J9rLURnF12vS7efZvXPHfjCHW9r9Df4x5RgXFvoD1rPD8ZsxrZULsl6wnfl76teKBcKYbrvdPjEvRjhXV8dCtI9N8WFHvbMYlgti1tCI2q3rSwaw21PAQ7fWA7L5y794+Io62obKpitC3tT5uC1z6Z0F0nO5ieNRCwWJ/Za+VCodqGHhnHH2uSuqru+kexT/4YR2uur4wT6H5aa+lOr1ySNy4V5cdqXanXcKeSzDCKMvkqx737JB+kgs2dvytgYD4VN6S6SnM1PqkwsFif2WvlQqHahh4YJjV9V3fWNpEB/4UNfHSfQ/7Acgf7UijVJY7HYhpLgNinehHyi8sW3DaGluthuZms8OqMT15QoyoNo3K3x6SvJsCqfE4qQ3xQUztcnnzu5jab6wShO3RofBvdjloI/V19ahEt3vIzo24u+TT7AMN+ODhfT2PPEIRuRdgyFNZ+BhAfvl1AKWyKxmShMojQsxqyrCpxUDOkjHBdRpDbhjz7sLrG6qAt/pgW04s5O5qcykMPC2Iclo3aE8bj5g87t/XD+wDL3s1Aioxx3icp5lD7YIYFC5GXIn4TcLa4HA+9QJZ0vPb7o6NX0oFYmySms/KzjJQ/2CVfCOKZizKIimiYimco+gTmKce8pSWtnqKUEsPRQOHZLuKIMRfkpoIMLfFMNCvNBkKO/QCXcn1G+ohTkCxSUTCZn830VsZQMroaRPFejqrsgfqEpUex3MQCgBHSOdaTeNgOTCUXL7j5fm/dR1iPFo8vVcMiaXNBnk7COhve0bv8T6rhSfTPhejBk8gHjHcY7TslkcjDeAdAwReMX9SoJ8oNFssOFO355RcWPZkQjt1Rf12b0pFZJxZmt1K+kP+Ikn3rEU/Ew9bXH6YqkE7nUs04LCfrKg4xIy010ct3ZtdLL6pG6dULJmyQ16opHwXwnHtLBjG92LS8d74lIS05E3rDk3zirssjIVGETZydmumFau1F4Y+TBk2u6Mp7ZHffM/ZRQ2wnLs4W7s2sr3bkoTELi3Y2FeVJy7AMHLopdqyAFUYcSJW9MWCJ970HEpq9OhDIZxa5tFjkXn6X0j4ujrKtJKfDCYtepYrJPQu7bIIVYqYlIG1fIg6x1xpmuufZWLSumGBWRR0hAoPIfUMx4Z+42ZCLC49fe1IQLZ/DMKqKM/r6MUu4mFvYgIHBLHKkCc1/V3UKalc2jFiLyXl8dJ9D/sNTR32lD1H6cBkUIH942pTzzJhfyWZag/kkkdGVUZNdcC4F9EnLfBinESk1E2rhCHmReG2e65tpbtayYYlREHiEBgcp/QDHjnbnbkIkIj197UxMunMEzq4gy+vsySrmbWNiDgMAtcaQKzH1VdwtpVpBHIn366jiB/oel7fo7bYLag9NAUjjtRXlmTkWinNBtxZbXFsZWf0JF9ihHemx7TXmjM8rNM+VNUS3bRAB9lcWvW6ZvtLdcP0HqNhXK3ttY1msnqsSdqWGvK+iQSUJeRL6wblwpX5qUa15iw7ICMbqpM8kJebb3rnsqKg0XyClUwLlIRZOrVcnM5+Qpwx44ouRFipBKmvTjLHmN5RgpmVFOhrs5TBfMq3UPZfUxl/5xcZR11ZZdXqH7Sinkvg0kkwm1ujkXPg+u8omvdBUrXeXKRZTch/wXjrD2gmDSyZ1HVAtHuIbcMo5BSunvTXjIPSBwS3zlQnKruluaUuxAHPu4Cf0PSw393Rbjaz/SrS/6BYVpf+RM1yxIwGd5RCB9lcJGkuoB7K3RJk3IfRtIJhNqdXMufB5c5RNfvm6N3wcpF1FyH/KP8U6RuJ/OeBdsU0cC9D8sLdffbQEF7YG3J/JK10mQIlGZ1tdKbHlteUBW74tnWcryfa2vhgu9BoEWu0ar7575/LSHucKz3XRt1u9Lv26icNjyh+55P9EqtS4iuaWlA7TBsYU2a3YS0+lQVHY9Ci3xyKWsDhnyIvKETS166Hy9FiOZj5KJTUUR0JY729RR3MvnV5KzeX1e9mk/6VBcpdSuU8RZPEkI5kDFzNcElfEFCSQqt1AEBYk8QVD6n7n0W4630OV+D7oQ+SgXct+WcJ3UeDyEOt6iGpgPl/ilJ38e5Ar0aV5thB3cTfpqdR+NNXaNUnNs5DpO+/OmmFL6ezJKsn2GbEWgn63sDgCoCHUEaeh3QnT9pN+a+mol5WZ6M+4tUvuweX02Du+fMN45EjHe5ejvySjJ9hmyFRjvAGgI3/iVEL/MzRYC3vHLgYnS/QCd3bejnXF2wZbGVu8A5OsricQI60UaZM0GKG0jYz93y1gWvjmkUJrgd8ReIipIbD2oeKW11dpaJTuJa2v8Wu2tlH20M6NOEpQ+2AFmqyLaaEhUJfuuGXJPqLEZWeM0XgOrCazW+ui1mX5KBN49t8tPoYraSKrKDvON9x4lBNZIZujDTVV3AEADSDOdB2PhkQbC1fc4/Kqa8rm/torxzgHj3VZgvAPg6AiNX8Rm+jDvT+6oVyk2tTqizBCyPn9o9pPdTtnC2Op8jDKQqTr0pSdkhDVQZhb5KUlOn6inV0py5scxZEJZqCwi1TSUmtFTfk/Oo7oOmooRpYuoULEyiS0klLrBFVlbY/o9cC8TEIqrlNqNFjEnmANVS1lRSZlAoooKpXoijx2UfsLnK/2WU1Do6pfCIvNlMeQuaoBd/sHJfVmrRajjLaqB+TCJNMTTy2BlgVVbn3r7nAbm+WyRn+KFjr6nV838Uvp7MipIGYE1kpmqASIWpUZVdwBALVJNSpAe3D2/E76L9m9mTtKsP312Us7PpAbBeOfAJGK8y9Pfk1FBygjEeAfAoUk1EUHg5TR+HBtLkGzP2fErKhK19w+IW7HNzFa5eIGfNSY7Zm2qltin0oZtZzMmM2LjURKc8p772QYqhOX4UY3h8oOXMn+Tysz9oVxXqULdGE3pG1vmc5kdSmUmyCtfvRPU08HijSiEPC3RrB2KR4X+BWUSm0Ne6sjaOr4ULcy4hOIqo3azRczJyYFKmS+oqkx+okKF0uBXimMBpf+ZS7/NhAqdSk33aIQttZD7QZAd74OuW6zjza+BRZiunD5f686/hsD81pceaqktzcdsrGkESkE0WVeZ4mMp0Xt4MiqHqt1RKXgN4F1WVXcAQC1kk9L2R/lCKlsU+z0gfyfoxq/fmm71VB+CZv1pw5THZyPvVwyMdxkw3hEY7wD4hBSOXxK38ZipqgQbv7yihCQjh2byh2y5LUSfjSWpdkCWgvaotVAWGSjLhgv7mO0qbZYAkG8enIcugQihr/ywlQYscr+7KV9N6pZgoewj5o2lQ7jQnZKt3cWNI5NJq6AD4Y8oL6wN0Z9MrF4MT0TkZDCP8qJI3bLgqdikLq6bLy6iSG0iFJHP3WqYvVA4t0wC81Mq89MwUVllFKGoQ4lyo0sJ8yLC6KvToURGofSPEJFCfXVElClEVoGcQgy51yZVJ+xt9kLh3FptUh0veTKwsJqURINyJjmSwiqdEsNuC1uf9uDq60RYGxOLFJnGjYIp5FKgv7rIZlRKHrv1C6xDWudEsiuxqjuRln1kiDTpq+ME+h+WmvpTq1HYtiOdnG5Bk2lzbpPL81mMCKWvUjiRBOJgPRRLSNi9Nm6Kk9vshcK5tdpgvDOYWKTING4UTCGXAv3Vxacc70Q4fXWcQP/DcgT6UytQ2LYgnZL2Qm0o0E7cJhQSpSloa21AaKkuzn78+KG0Fnz79m04tB3JlmymF933+0r7vFTj7OxMpQSAT0yphobGcqLsvJvdP6irbSEenT2cr3PX4SVspqPXr7OUX6qez9dlRTTKoVqGNx8KOWBGgTDH3hdB/8MC/Y8JjHc1wHhXEfQJhwX6g31iy2vLA7IAAAclfhxHbOcO8KlA6YMGcZY3yoU+5dforN/DW+EfgM3r82FaRsvyAQAAgAeMd9uD8Q4AAIqAsRWA4yUeXa4mT5/w8zAQoPRBowxm60k07p5JuuPeovxEmfgl0pvdH5wNbQ/Vfb4+SMtoUT4AAAAIgfFuazDeAQBAIbvbRmDniOERs6kBKAMaCzgWUFcBAG3g2Psi6H9YoD8AgIM+4bBAf7BPbHmd/fznP//tb3/7m9/8RvwVjEYj5QMAAAAAAAAAAAAAAABAGVYr2mrliGe2/u3f/u0//af/VN8AAMKgsYBjAXUVANAGjr0vgv6HBfoDADjoEw4L9Af7RJdXFP3/MiIztE9RiSEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compare.png](attachment:compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite SVM model is Option 1 Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix / classification report  - Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision, recall, f1, accuracy - Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the hyperparameters - Tina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make SVC from subsampled set - Tina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite Logistic model is Option 1 Unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix / classification report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the hyperparameters - Paritosh, Fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite model overall is the Logistic regression option 1 unscaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is one better about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is one better from accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_clean\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['bmi', 'ap_hi', 'ap_lo','cholesterol','age']]\n",
    "y = df['cardio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Decision Tree Model\n",
    "Let's start by training a single decision tree first!\n",
    "\n",
    "** Import DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation of Decision Tree\n",
    "\n",
    "Create predictions from the test set and create a classification report and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "auc = mt.roc_auc_score(y_test,predictions)\n",
    "print(\"auc\", auc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Random Forest model\n",
    "Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Evaluation\n",
    "Let's predict off the y_test values and evaluate our model.\n",
    "\n",
    "** Predict the class of not.fully.paid for the X_test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a classification report from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following Logistical Regression Models were rejected, but they were not far in accuracy and AUC scores from the preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Logistical Regression Options:\n",
    "\n",
    "Description of Variable Combinations for Logistical Regresson models: \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest correlation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 model is shown earlier in this document as it is the model we have chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2   AP_HI variable only (systolic blood pressure).  With unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_clean\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','age','gender','height','weight','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bmi','bp'], axis =1, inplace = True) # get rid of the class label\n",
    "df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "#  {'C': [.1, 1, 10, 100, 1000],\n",
    " #  'penalty': ['l1'],\n",
    "  # 'solver': ['liblinear', 'saga']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=4000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.1, class_weight=None, solver='lbfgs' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','gluc','smoke','alco','active','cardio','bmi','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','ap_hi','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "LogisticRegression()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
