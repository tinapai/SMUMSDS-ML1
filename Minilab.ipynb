{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "df = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df = df[df[\"weight\"] < 200]\n",
    "df = df[df[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df = df[df[\"height\"] < 200]\n",
    "df = df[df[\"height\"] > 130]\n",
    "\n",
    "# Keeping only reasonable blood pressure measurements\n",
    "df = df[df[\"ap_hi\"] < 200]\n",
    "df = df[df[\"ap_hi\"] > 110]\n",
    "df = df[df[\"ap_lo\"] < 150]\n",
    "df = df[df[\"ap_lo\"] > 60]\n",
    "\n",
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df['bp'] = np.where((df.ap_hi < 120) & (df.ap_lo < 80), 1, 0)\n",
    "df['bp'] = np.where((df.ap_hi >= 120) & (df.ap_hi < 130) & (df.ap_lo < 80), 2, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi >= 130) & (df.ap_hi < 140) | ((df.ap_lo >= 80) & (df.ap_lo < 90)), 3, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi >= 140) | (df.ap_lo >= 90), 4, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi > 180) | (df.ap_lo > 120), 5, df.bp)\n",
    "df['bp'] = pd.cut(df.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n",
    "\n",
    "# compute the body mass index based on weight and height\n",
    "df['bmi'] = df['weight'] / (df['height']/100)**2\n",
    "\n",
    "if 'cardio' in df:\n",
    "    y = df['cardio'].values\n",
    "    del df['cardio']\n",
    "    X = df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Variable Selection Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 'ap_hi' (highest co-relation)\n",
    "2. 'bmi', 'ap_hi', 'ap_lo','cholesterol','age'\n",
    "3. 'bmi', 'age', ‘bp’, 'cholesterol'\n",
    "4. ‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol'\n",
    "5. 'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active', 'weight' (all variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Baseline model (ap_hi only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73474949 0.73226494 0.73699703]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py:401: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py:401: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py:401: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73560513 0.73413289 0.73557645]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM using BMI, age, ap_hi, ap_lo, cholesterol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64436945 0.56968912 0.71217683]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77296258 0.7736283  0.78275248]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier', SGDClassifier())]),\n",
       "             param_grid=[{'classifier__alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1],\n",
       "                          'classifier__loss': ['modified_huber'],\n",
       "                          'classifier__penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__loss': ['modified_huber'],\n",
    "   'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "   'classifier__alpha': [.001, .01, .05, .1, .5, 1]}\n",
    " ]\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SGDClassifier())])\n",
    "\n",
    "clf = GridSearchCV(svm, param_grid, scoring=\"roc_auc\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.05,\n",
       " 'classifier__loss': 'modified_huber',\n",
       " 'classifier__penalty': 'l1'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best auc: 0.777694 using {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.772528 (0.005303) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.772481 (0.006019) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.771480 (0.004149) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.776109 (0.002568) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.776786 (0.003735) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.777035 (0.003645) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.776539 (0.002835) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.777287 (0.003335) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.777694 (0.003501) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.775580 (0.003113) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.777292 (0.003630) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.777522 (0.003234) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.733425 (0.003279) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.775528 (0.003732) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775208 (0.003611) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.500000 (0.000000) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.773843 (0.003831) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.774933 (0.003551) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best auc: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77982185 0.77476165 0.77906842]\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model = clf.best_estimator_ #this was alpha=.1, loss='modified_huber', penalty='elasticnet'\n",
    "calibrator = CalibratedClassifierCV(model, cv=3)\n",
    "\n",
    "aucs = cross_val_score(calibrator, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model ROC AUC=0.769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "scl_obj = std_scl.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "svm_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "svm_probs = svm_probs[:, 1]\n",
    "# calculate scores\n",
    "svm_auc = roc_auc_score(y_test, svm_probs)\n",
    "# summarize scores\\\n",
    "print('SVM Model ROC AUC=%.3f' % (svm_auc))\n",
    "# calculate roc curves\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(svm_fpr, svm_tpr, marker='.', label='SVM')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find probability threshold for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43619674, 0.56858624, 0.37566759, ..., 0.34705585, 0.45247799,\n",
       "       0.75793575])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.000000 : accuracy=0.560\n",
      "alpha 0.100000 : accuracy=0.560\n",
      "alpha 0.200000 : accuracy=0.562\n",
      "alpha 0.300000 : accuracy=0.608\n",
      "alpha 0.400000 : accuracy=0.689\n",
      "alpha 0.500000 : accuracy=0.707\n",
      "alpha 0.600000 : accuracy=0.683\n",
      "alpha 0.700000 : accuracy=0.622\n",
      "alpha 0.800000 : accuracy=0.561\n",
      "alpha 0.900000 : accuracy=0.511\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, .1)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune a little finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.400000 : accuracy=0.689\n",
      "alpha 0.410000 : accuracy=0.694\n",
      "alpha 0.420000 : accuracy=0.699\n",
      "alpha 0.430000 : accuracy=0.703\n",
      "alpha 0.440000 : accuracy=0.705\n",
      "alpha 0.450000 : accuracy=0.708\n",
      "alpha 0.460000 : accuracy=0.710\n",
      "alpha 0.470000 : accuracy=0.710\n",
      "alpha 0.480000 : accuracy=0.709\n",
      "alpha 0.490000 : accuracy=0.708\n",
      "alpha 0.500000 : accuracy=0.707\n",
      "alpha 0.510000 : accuracy=0.706\n",
      "alpha 0.520000 : accuracy=0.707\n",
      "alpha 0.530000 : accuracy=0.705\n",
      "alpha 0.540000 : accuracy=0.705\n",
      "alpha 0.550000 : accuracy=0.703\n",
      "alpha 0.560000 : accuracy=0.701\n",
      "alpha 0.570000 : accuracy=0.695\n",
      "alpha 0.580000 : accuracy=0.692\n",
      "alpha 0.590000 : accuracy=0.688\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(.4, .6, .01)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elevated</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage1</th>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage2</th>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "Following are combo I selected based on high correlation and removing\n",
    "\n",
    "'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "'ap_hi' (highest co-relation)\n",
    "'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','gluc','smoke','alco','active','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21914</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22113</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  ap_hi  ap_lo  cholesterol        bmi\n",
       "1  20228    140     90            3  34.927679\n",
       "2  18857    130     70            3  23.507805\n",
       "3  17623    150    100            1  28.710479\n",
       "5  21914    120     80            2  29.384676\n",
       "6  22113    130     80            3  37.729725"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.13633084, 1.00117302, 1.24963212, 1.06326763, 1.4947203 ,\n",
       "        0.74481932, 0.57179991, 0.83711425, 0.96098264, 0.88291057]),\n",
       " 'std_fit_time': array([0.19599763, 0.35013641, 0.37566614, 0.02926901, 0.16095971,\n",
       "        0.27037105, 0.26492049, 0.63907737, 0.62121947, 0.56914189]),\n",
       " 'mean_score_time': array([0.01731292, 0.01359653, 0.01662254, 0.01372441, 0.02104044,\n",
       "        0.01151768, 0.00826097, 0.01566847, 0.01730092, 0.01324264]),\n",
       " 'std_score_time': array([0.00397366, 0.00540765, 0.00397869, 0.00513832, 0.00100068,\n",
       "        0.00259998, 0.00047408, 0.00308104, 0.00376869, 0.00584744]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77354859, 0.77339347, 0.77335239, 0.77340219, 0.77348796,\n",
       "        0.62066448, 0.62066384, 0.62066373, 0.62066376, 0.62066376]),\n",
       " 'split1_test_score': array([0.77821298, 0.77816996, 0.77801629, 0.77812607, 0.77800416,\n",
       "        0.65239514, 0.65238052, 0.65238009, 0.65238002, 0.65237937]),\n",
       " 'split2_test_score': array([0.77284672, 0.77274832, 0.77281112, 0.77270991, 0.77281295,\n",
       "        0.64307394, 0.64305867, 0.7728051 , 0.77280449, 0.77280334]),\n",
       " 'mean_test_score': array([0.77486943, 0.77477058, 0.7747266 , 0.77474606, 0.77476836,\n",
       "        0.63871119, 0.63870101, 0.68194964, 0.68194942, 0.68194882]),\n",
       " 'std_test_score': array([0.00238155, 0.00241811, 0.00233663, 0.00240669, 0.00230459,\n",
       "        0.01331625, 0.01330987, 0.06553634, 0.06553606, 0.06553562]),\n",
       " 'rank_test_score': array([ 1,  2,  5,  4,  3,  9, 10,  6,  7,  8]),\n",
       " 'split0_train_score': array([0.77714461, 0.77709433, 0.77703508, 0.7770614 , 0.77717382,\n",
       "        0.61365642, 0.61365594, 0.61365593, 0.61365594, 0.61365594]),\n",
       " 'split1_train_score': array([0.77605312, 0.77606586, 0.77611173, 0.77608354, 0.77609557,\n",
       "        0.64745374, 0.64743886, 0.64743746, 0.6474372 , 0.64743424]),\n",
       " 'split2_train_score': array([0.7775122 , 0.77743548, 0.77744364, 0.77742187, 0.77742088,\n",
       "        0.64976586, 0.64974714, 0.77738592, 0.77738589, 0.77738446]),\n",
       " 'mean_train_score': array([0.77690331, 0.77686522, 0.77686349, 0.77685561, 0.77689676,\n",
       "        0.63695867, 0.63694731, 0.6794931 , 0.67949301, 0.67949155]),\n",
       " 'std_train_score': array([0.00061962, 0.00058214, 0.00055712, 0.00056542, 0.00057543,\n",
       "        0.0165042 , 0.01649642, 0.07058116, 0.07058118, 0.07058097])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a grid search for logistic regression\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.774869 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774869 (0.002382) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774771 (0.002418) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774727 (0.002337) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774746 (0.002407) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774768 (0.002305) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.638711 (0.013316) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.638701 (0.013310) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681950 (0.065536) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681949 (0.065536) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681949 (0.065536) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=1000, class_weight=None, solver='liblinear' ) # get object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7829547933192589\n",
      "confusion matrix\n",
      " [[3456 1276]\n",
      " [1670 4209]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7754650624424138\n",
      "confusion matrix\n",
      " [[3376 1312]\n",
      " [1690 4233]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7685047471625793\n",
      "confusion matrix\n",
      " [[3365 1360]\n",
      " [1696 4190]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.14850839, 0.52759393, 0.20345561, 0.55784543, 0.19016083,\n",
       "        0.54111687, 0.1761651 , 0.60507512, 0.18359399, 0.61951089,\n",
       "        0.13863087, 0.64345797, 0.45117307, 0.16854954, 0.74270328,\n",
       "        0.52776082, 0.16951672, 0.75927965, 0.54756435, 0.18110339,\n",
       "        0.76051315, 0.36976258, 0.11459931, 0.75434391, 0.60609031]),\n",
       " 'std_fit_time': array([0.02457383, 0.07212964, 0.02330939, 0.01973177, 0.00335044,\n",
       "        0.03443176, 0.00698294, 0.04338684, 0.03389014, 0.0577429 ,\n",
       "        0.03420258, 0.2195953 , 0.06371536, 0.02378538, 0.02790232,\n",
       "        0.05588873, 0.0049283 , 0.04496753, 0.01357849, 0.00762215,\n",
       "        0.05408066, 0.03968448, 0.02429979, 0.02349125, 0.03094362]),\n",
       " 'mean_score_time': array([0.00908422, 0.01424702, 0.01928926, 0.01858425, 0.02127004,\n",
       "        0.01599201, 0.01230033, 0.0159208 , 0.01322508, 0.01127847,\n",
       "        0.01539556, 0.01201558, 0.01624791, 0.01328397, 0.01759481,\n",
       "        0.01326013, 0.01230065, 0.02023172, 0.01894561, 0.01062473,\n",
       "        0.0126191 , 0.00744255, 0.01505693, 0.01791191, 0.01857305]),\n",
       " 'std_score_time': array([0.00149151, 0.00520065, 0.00381545, 0.00402075, 0.0024865 ,\n",
       "        0.00426891, 0.00462986, 0.00373344, 0.00289823, 0.00112502,\n",
       "        0.00251954, 0.0062935 , 0.00599632, 0.00471222, 0.00402535,\n",
       "        0.00702302, 0.00286043, 0.00094444, 0.00285511, 0.00491102,\n",
       "        0.00233471, 0.00069654, 0.00521949, 0.00423947, 0.00328897]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77483743, 0.774841  , 0.77483333, 0.77483452, 0.77483373,\n",
       "        0.77483369, 0.77483495, 0.77483365, 0.77483398, 0.77483394,\n",
       "        0.77482548, 0.77482545, 0.77482559, 0.77483362, 0.77483387,\n",
       "        0.77483337, 0.77483365, 0.77483617, 0.77483272, 0.77483387,\n",
       "        0.77483351, 0.77483315, 0.77483394, 0.77483437, 0.77483455]),\n",
       " 'split1_test_score': array([0.77921687, 0.7792177 , 0.77920819, 0.77920769, 0.77920707,\n",
       "        0.77920671, 0.77920581, 0.77920624, 0.77920711, 0.77920603,\n",
       "        0.77920038, 0.77919999, 0.77920049, 0.77920512, 0.77920487,\n",
       "        0.77920534, 0.77920678, 0.77920577, 0.77920812, 0.77920693,\n",
       "        0.77920556, 0.77920592, 0.77920693, 0.77920816, 0.77920635]),\n",
       " 'split2_test_score': array([0.77224057, 0.77224453, 0.77222309, 0.77222406, 0.77222295,\n",
       "        0.77222248, 0.77222233, 0.77222302, 0.77222244, 0.77222349,\n",
       "        0.77221722, 0.77221819, 0.77221505, 0.77222342, 0.77222215,\n",
       "        0.77222363, 0.77222248, 0.77222237, 0.77222482, 0.77222305,\n",
       "        0.77222219, 0.77222273, 0.77222313, 0.7722219 , 0.77222223]),\n",
       " 'mean_test_score': array([0.77543162, 0.77543441, 0.77542154, 0.77542209, 0.77542125,\n",
       "        0.77542096, 0.77542103, 0.77542097, 0.77542118, 0.77542115,\n",
       "        0.77541436, 0.77541454, 0.77541371, 0.77542072, 0.7754203 ,\n",
       "        0.77542078, 0.77542097, 0.77542144, 0.77542189, 0.77542128,\n",
       "        0.77542042, 0.7754206 , 0.77542133, 0.77542148, 0.77542104]),\n",
       " 'std_test_score': array([0.00287889, 0.00287754, 0.00288183, 0.00288117, 0.00288137,\n",
       "        0.00288138, 0.00288095, 0.00288098, 0.00288155, 0.00288069,\n",
       "        0.00288112, 0.00288058, 0.00288196, 0.00288034, 0.00288068,\n",
       "        0.00288038, 0.00288142, 0.00288084, 0.0028812 , 0.00288125,\n",
       "        0.00288099, 0.00288098, 0.00288122, 0.00288218, 0.00288126]),\n",
       " 'rank_test_score': array([ 2,  1,  5,  3, 10, 17, 14, 16, 11, 12, 24, 23, 25, 19, 22, 18, 15,\n",
       "         7,  4,  9, 21, 20,  8,  6, 13]),\n",
       " 'split0_train_score': array([0.77686376, 0.77686744, 0.77685519, 0.77685545, 0.77685433,\n",
       "        0.77685489, 0.77685546, 0.7768551 , 0.77685423, 0.77685483,\n",
       "        0.77684542, 0.77684542, 0.77684544, 0.77685373, 0.7768542 ,\n",
       "        0.77685361, 0.77685466, 0.77685446, 0.77685436, 0.77685469,\n",
       "        0.77685442, 0.7768544 , 0.77685471, 0.77685499, 0.7768549 ]),\n",
       " 'split1_train_score': array([0.77594984, 0.77595254, 0.77594102, 0.77594219, 0.77594087,\n",
       "        0.77594032, 0.77593968, 0.77594024, 0.77594033, 0.77594017,\n",
       "        0.77593218, 0.77593244, 0.77593214, 0.77593982, 0.77593997,\n",
       "        0.77594011, 0.77594042, 0.77594014, 0.77594062, 0.77594059,\n",
       "        0.77594064, 0.77594016, 0.77594054, 0.77594111, 0.77594075]),\n",
       " 'split2_train_score': array([0.77741992, 0.77742302, 0.77741173, 0.77741254, 0.7774121 ,\n",
       "        0.77741166, 0.77741126, 0.77741176, 0.77741184, 0.77741228,\n",
       "        0.77740428, 0.77740434, 0.7774035 , 0.77741103, 0.77741036,\n",
       "        0.77741098, 0.77741166, 0.77741136, 0.77741225, 0.77741178,\n",
       "        0.77741097, 0.77741163, 0.77741182, 0.77741152, 0.7774119 ]),\n",
       " 'mean_train_score': array([0.77674451, 0.77674767, 0.77673598, 0.77673673, 0.77673577,\n",
       "        0.77673562, 0.77673547, 0.7767357 , 0.77673547, 0.77673576,\n",
       "        0.77672729, 0.7767274 , 0.77672703, 0.77673486, 0.77673485,\n",
       "        0.7767349 , 0.77673558, 0.77673532, 0.77673574, 0.77673568,\n",
       "        0.77673534, 0.77673539, 0.77673569, 0.77673587, 0.77673585]),\n",
       " 'std_train_score': array([0.00060605, 0.00060627, 0.0006063 , 0.00060611, 0.00060645,\n",
       "        0.00060656, 0.00060673, 0.00060665, 0.00060658, 0.00060686,\n",
       "        0.00060676, 0.00060667, 0.00060648, 0.00060647, 0.00060619,\n",
       "        0.00060632, 0.0006065 , 0.0006065 , 0.00060662, 0.00060648,\n",
       "        0.00060614, 0.00060659, 0.00060651, 0.00060618, 0.00060647])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.775434 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775432 (0.002879) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.775434 (0.002878) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775422 (0.002882) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.775422 (0.002881) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002882) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.775414 (0.002881) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.775415 (0.002881) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.775414 (0.002882) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002880) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.775420 (0.002881) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.775421 (0.002880) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.775422 (0.002881) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.775420 (0.002881) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.775421 (0.002882) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.775421 (0.002881) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7690173795950215\n",
      "[0.71718028 0.70737913 0.71388182]\n"
     ]
    }
   ],
   "source": [
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7787723787464775\n",
      "confusion matrix\n",
      " [[3424 1306]\n",
      " [1702 4179]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7766689020714688\n",
      "confusion matrix\n",
      " [[3458 1314]\n",
      " [1706 4133]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7689773257589287\n",
      "confusion matrix\n",
      " [[3342 1349]\n",
      " [1752 4168]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29730359, 0.895704  , 0.12862789, 0.28280883, 0.10074451]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Heigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elevated</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage1</th>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage2</th>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options 3\n",
    "Following are combo I selected based on high correlation and removing\n",
    "\n",
    "'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "'ap_hi' (highest co-relation)\n",
    "'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "df1\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.23018305, 2.54380488, 2.12472892, 1.7286675 , 2.29781906,\n",
       "        0.7234079 , 0.67552582, 0.77360185, 0.42936484, 0.58078138]),\n",
       " 'std_fit_time': array([0.85776811, 0.49020266, 0.39763073, 0.26371298, 0.68896882,\n",
       "        0.18729209, 0.22380029, 0.28650149, 0.00422998, 0.26058274]),\n",
       " 'mean_score_time': array([0.01946378, 0.01161702, 0.01521269, 0.0116206 , 0.01758536,\n",
       "        0.01559059, 0.0119702 , 0.01063728, 0.0103337 , 0.01331186]),\n",
       " 'std_score_time': array([0.00318901, 0.0069068 , 0.00343195, 0.0055378 , 0.00477862,\n",
       "        0.00129262, 0.00423109, 0.0030843 , 0.00629732, 0.00365406]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.7772374 , 0.77736965, 0.77731488, 0.77728615, 0.77732462,\n",
       "        0.6072456 , 0.60724473, 0.60724445, 0.60724445, 0.60724445]),\n",
       " 'split1_test_score': array([0.78513583, 0.78550534, 0.78544397, 0.78530513, 0.78499073,\n",
       "        0.6540201 , 0.66655707, 0.65399176, 0.6304015 , 0.65396622]),\n",
       " 'split2_test_score': array([0.77616396, 0.7761092 , 0.77609118, 0.77603606, 0.776101  ,\n",
       "        0.66767271, 0.65354567, 0.65354499, 0.65354517, 0.65354521]),\n",
       " 'mean_test_score': array([0.7795124 , 0.7796614 , 0.77961668, 0.77954245, 0.77947212,\n",
       "        0.64297947, 0.64244916, 0.6382604 , 0.63039704, 0.63825196]),\n",
       " 'std_test_score': array([0.00400045, 0.00416421, 0.00415069, 0.00410667, 0.00393409,\n",
       "        0.02587509, 0.02545372, 0.02193235, 0.01890219, 0.0219263 ]),\n",
       " 'rank_test_score': array([ 4,  1,  2,  3,  5,  6,  7,  8, 10,  9]),\n",
       " 'split0_train_score': array([0.77853191, 0.77856994, 0.77851077, 0.77850004, 0.7785287 ,\n",
       "        0.6161027 , 0.61610242, 0.61610235, 0.61610235, 0.61610235]),\n",
       " 'split1_train_score': array([0.77646364, 0.77662407, 0.77659702, 0.77652478, 0.7763357 ,\n",
       "        0.65767141, 0.66983538, 0.65762706, 0.63530388, 0.65764234]),\n",
       " 'split2_train_score': array([0.77911162, 0.77905801, 0.77904932, 0.77901365, 0.7790565 ,\n",
       "        0.67396264, 0.65804559, 0.65804452, 0.65804431, 0.65804427]),\n",
       " 'mean_train_score': array([0.77803572, 0.778084  , 0.77805237, 0.77801282, 0.77797363,\n",
       "        0.64924558, 0.64799446, 0.64392464, 0.63648351, 0.64392965]),\n",
       " 'std_train_score': array([0.00113654, 0.00105138, 0.00105231, 0.0010729 , 0.00117807,\n",
       "        0.02436102, 0.02305901, 0.01967407, 0.01714304, 0.01967756])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.779661 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779512 (0.004000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779661 (0.004164) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779617 (0.004151) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779542 (0.004107) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779472 (0.003934) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.642979 (0.025875) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642449 (0.025454) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.638260 (0.021932) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.630397 (0.018902) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.638252 (0.021926) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7760096265232266\n",
      "confusion matrix\n",
      " [[3413 1337]\n",
      " [1699 4162]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7739519469347773\n",
      "confusion matrix\n",
      " [[3350 1327]\n",
      " [1740 4194]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7742651046124266\n",
      "confusion matrix\n",
      " [[3357 1264]\n",
      " [1767 4223]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\parit\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.25365353, 0.83486994, 0.15757902, 0.72542707, 0.22569505,\n",
       "        0.78545435, 0.24665689, 0.74967806, 0.26828988, 0.81947478,\n",
       "        0.13663451, 0.84688743, 0.68685714, 0.18023849, 0.99644303,\n",
       "        0.71114993, 0.13461121, 0.99999277, 0.84047906, 0.0728054 ,\n",
       "        0.93457731, 0.71811438, 0.18915884, 1.06844449, 0.99353941]),\n",
       " 'std_fit_time': array([0.03692751, 0.12044648, 0.01585361, 0.07668434, 0.02440388,\n",
       "        0.05604756, 0.00981837, 0.03971338, 0.00563256, 0.0509568 ,\n",
       "        0.03118987, 0.27463422, 0.04416542, 0.02685969, 0.06286471,\n",
       "        0.07949175, 0.00817267, 0.04873309, 0.0550668 , 0.02386716,\n",
       "        0.21794282, 0.02649502, 0.00782439, 0.06449792, 0.08747253]),\n",
       " 'mean_score_time': array([0.01196893, 0.01261576, 0.01200112, 0.01661587, 0.01630004,\n",
       "        0.02093355, 0.01382693, 0.01929681, 0.02057894, 0.01862303,\n",
       "        0.01466219, 0.01308179, 0.02160978, 0.01757741, 0.01771577,\n",
       "        0.01823115, 0.01662087, 0.01761937, 0.01261822, 0.00631571,\n",
       "        0.00898449, 0.01660609, 0.01271868, 0.0152866 , 0.01609341]),\n",
       " 'std_score_time': array([0.00215428, 0.00586764, 0.00713501, 0.00368238, 0.00574658,\n",
       "        0.0008301 , 0.00411846, 0.003789  , 0.00260275, 0.00265495,\n",
       "        0.00461837, 0.0062882 , 0.00090567, 0.00583309, 0.0052517 ,\n",
       "        0.00523409, 0.00523539, 0.00544693, 0.00330741, 0.00205009,\n",
       "        0.00410413, 0.00325349, 0.00441764, 0.00398604, 0.00347091]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.7731973 , 0.77320043, 0.77316672, 0.77316726, 0.77316327,\n",
       "        0.7731642 , 0.77316355, 0.77316373, 0.7731619 , 0.77316424,\n",
       "        0.77314949, 0.77315028, 0.77314941, 0.77316183, 0.77316244,\n",
       "        0.77316201, 0.77316449, 0.77316363, 0.77316237, 0.77316435,\n",
       "        0.77316406, 0.77316399, 0.77316424, 0.77316301, 0.77316388]),\n",
       " 'split1_test_score': array([0.78417708, 0.78417808, 0.78415168, 0.78415226, 0.78414801,\n",
       "        0.78414963, 0.78414855, 0.78415028, 0.78414758, 0.78414837,\n",
       "        0.78414118, 0.78414042, 0.78414179, 0.78414819, 0.7841492 ,\n",
       "        0.78414773, 0.78414841, 0.78414888, 0.78414855, 0.7841487 ,\n",
       "        0.7841497 , 0.78414834, 0.78414866, 0.78414913, 0.78414783]),\n",
       " 'split2_test_score': array([0.77788038, 0.77788179, 0.7778753 , 0.77787516, 0.77787364,\n",
       "        0.77787584, 0.77787559, 0.77787494, 0.77787422, 0.77787523,\n",
       "        0.77785847, 0.77785771, 0.77785807, 0.77787361, 0.77787307,\n",
       "        0.77787328, 0.77787512, 0.77787422, 0.77787537, 0.77787574,\n",
       "        0.77787465, 0.77787523, 0.77787577, 0.77787455, 0.77787574]),\n",
       " 'mean_test_score': array([0.77841826, 0.7784201 , 0.7783979 , 0.77839823, 0.77839497,\n",
       "        0.77839656, 0.7783959 , 0.77839632, 0.77839457, 0.77839595,\n",
       "        0.77838305, 0.7783828 , 0.77838309, 0.77839454, 0.7783949 ,\n",
       "        0.77839434, 0.77839601, 0.77839557, 0.77839543, 0.77839626,\n",
       "        0.77839614, 0.77839585, 0.77839622, 0.77839556, 0.77839582]),\n",
       " 'std_test_score': array([0.00449858, 0.00449774, 0.00449979, 0.00449983, 0.00449963,\n",
       "        0.00449987, 0.00449967, 0.00450036, 0.00449995, 0.00449935,\n",
       "        0.00450264, 0.00450205, 0.00450295, 0.00450027, 0.00450048,\n",
       "        0.00450001, 0.00449927, 0.00449984, 0.00450014, 0.00449942,\n",
       "        0.0045    , 0.00449943, 0.00449945, 0.00450017, 0.00449924]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3, 18,  5, 12,  6, 20, 11, 24, 25, 23, 21, 19, 22, 10,\n",
       "        15, 17,  7,  9, 13,  8, 16, 14]),\n",
       " 'split0_train_score': array([0.77964087, 0.77964321, 0.77961486, 0.77961515, 0.77961164,\n",
       "        0.77961191, 0.77961144, 0.77961249, 0.77961058, 0.77961207,\n",
       "        0.77960564, 0.77960585, 0.77960558, 0.77961104, 0.77961143,\n",
       "        0.77961088, 0.77961165, 0.77961118, 0.77961152, 0.77961163,\n",
       "        0.77961228, 0.77961161, 0.77961167, 0.7796116 , 0.77961131]),\n",
       " 'split1_train_score': array([0.77701593, 0.77701956, 0.7769905 , 0.77699094, 0.77698794,\n",
       "        0.7769883 , 0.77698797, 0.77698874, 0.77698755, 0.77698823,\n",
       "        0.77698135, 0.77698142, 0.77698132, 0.77698761, 0.77698751,\n",
       "        0.77698741, 0.77698823, 0.77698801, 0.77698806, 0.77698819,\n",
       "        0.776988  , 0.77698788, 0.77698817, 0.77698819, 0.77698784]),\n",
       " 'split2_train_score': array([0.77851228, 0.77851477, 0.77849106, 0.77849018, 0.77848769,\n",
       "        0.77848796, 0.77848875, 0.7784879 , 0.77848733, 0.77848798,\n",
       "        0.77848142, 0.77848062, 0.77848132, 0.77848746, 0.77848671,\n",
       "        0.77848721, 0.77848808, 0.77848718, 0.77848784, 0.77848817,\n",
       "        0.7784877 , 0.77848791, 0.77848812, 0.7784876 , 0.77848798]),\n",
       " 'mean_train_score': array([0.77838969, 0.77839251, 0.77836547, 0.77836542, 0.77836242,\n",
       "        0.77836272, 0.77836272, 0.77836304, 0.77836182, 0.77836276,\n",
       "        0.77835614, 0.77835596, 0.77835607, 0.77836203, 0.77836188,\n",
       "        0.77836183, 0.77836265, 0.77836212, 0.77836247, 0.77836267,\n",
       "        0.77836266, 0.77836247, 0.77836265, 0.77836246, 0.77836238]),\n",
       " 'std_train_score': array([0.00107513, 0.00107459, 0.00107506, 0.00107495, 0.00107478,\n",
       "        0.00107474, 0.00107473, 0.00107478, 0.00107452, 0.00107483,\n",
       "        0.00107502, 0.00107504, 0.00107501, 0.00107468, 0.00107484,\n",
       "        0.00107469, 0.00107467, 0.00107455, 0.00107468, 0.00107469,\n",
       "        0.001075  , 0.0010748 , 0.00107471, 0.00107465, 0.0010747 ])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.778420 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778418 (0.004499) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.778420 (0.004498) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778398 (0.004500) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.778398 (0.004500) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778395 (0.004500) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.778397 (0.004500) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778396 (0.004500) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.778396 (0.004500) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778395 (0.004500) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.778383 (0.004503) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.778383 (0.004502) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.778383 (0.004503) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.778395 (0.004500) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.778395 (0.004500) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.778394 (0.004500) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.778396 (0.004500) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.778395 (0.004500) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.778396 (0.004500) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.778396 (0.004500) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.778396 (0.004499) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7742956684281203\n",
      "[0.71473    0.71746301 0.7221751 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7766636992771293\n",
      "confusion matrix\n",
      " [[3272 1278]\n",
      " [1787 4274]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7779139340127131\n",
      "confusion matrix\n",
      " [[3373 1302]\n",
      " [1710 4226]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7814293307063339\n",
      "confusion matrix\n",
      " [[3362 1305]\n",
      " [1705 4239]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2956479 ,  0.9020887 ,  0.12967055,  0.32368209, -0.07845395,\n",
       "        -0.03661296, -0.04821579, -0.09435271,  0.10182013]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.781\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
