{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Machine Learning I / Mini Lab Predictive Analysis</b>\n",
    "<br><b>Authors:</b> Fabio Savorgnon, Tina Pai, Paritosh Rai, Ellen Lull\n",
    "<br><b>Data set from:</b> https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our initial Exploratory Data Analysis (EDA) project, we needed to pick a model that would predict if a patient would have cardiovascular disease based on the variables available in our data.  These are:  gender, systolic blood pressure, diastolic blood pressure, age, height and weight (which we used to calculate Body Mass Index or BMI), a cholesterol level indicator, a glucose level indicator, and indicators to identify if a patient used alcohol, smoked or was active.    You can view the full descriptions of these data elements in our EDA document.\n",
    "<br>  \n",
    "\n",
    "During our EDA, we determined that the factors that had the highest level of correlation to cardiovascular disease were:   Blood pressure, BMI, Age, Cholesterol and Glucose.     However, we didn’t want to limit ourselves to only these.   So, we ran five combinations of these variables.  For each combination of variables, we ran both SVM and Logistical Regression models.  For each combination and method, we ran with scaled data and non-scaled data.   Our findings are documented below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "df = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df = df[df[\"weight\"] < 200]\n",
    "df = df[df[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df = df[df[\"height\"] < 200]\n",
    "df = df[df[\"height\"] > 130]\n",
    "\n",
    "# Keeping only reasonable blood pressure measurements\n",
    "df = df[df[\"ap_hi\"] < 200]\n",
    "df = df[df[\"ap_hi\"] > 110]\n",
    "df = df[df[\"ap_lo\"] < 150]\n",
    "df = df[df[\"ap_lo\"] > 60]\n",
    "\n",
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df['bp'] = np.where((df.ap_hi < 120) & (df.ap_lo < 80), 1, 0)\n",
    "df['bp'] = np.where((df.ap_hi >= 120) & (df.ap_hi < 130) & (df.ap_lo < 80), 2, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi >= 130) & (df.ap_hi < 140) | ((df.ap_lo >= 80) & (df.ap_lo < 90)), 3, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi >= 140) | (df.ap_lo >= 90), 4, df.bp)\n",
    "df['bp'] = np.where((df.ap_hi > 180) | (df.ap_lo > 120), 5, df.bp)\n",
    "df['bp'] = pd.cut(df.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n",
    "\n",
    "# compute the body mass index based on weight and height\n",
    "df['bmi'] = df['weight'] / (df['height']/100)**2\n",
    "\n",
    "# Make a backup of the dataframe to use later in other models when we need a clean copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bp</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio            bp        bmi  \n",
       "1     0       1       1  Hyper_Stage2  34.927679  \n",
       "2     0       0       1  Hyper_Stage1  23.507805  \n",
       "3     0       1       1  Hyper_Stage2  28.710479  \n",
       "5     0       0       0  Hyper_Stage1  29.384676  \n",
       "6     0       1       0  Hyper_Stage1  37.729725  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cardio' in df:\n",
    "    y = df['cardio'].values\n",
    "    del df['cardio']\n",
    "    X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bp</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio            bp        bmi  \n",
       "1     0       1       1  Hyper_Stage2  34.927679  \n",
       "2     0       0       1  Hyper_Stage1  23.507805  \n",
       "3     0       1       1  Hyper_Stage2  28.710479  \n",
       "5     0       0       0  Hyper_Stage1  29.384676  \n",
       "6     0       1       0  Hyper_Stage1  37.729725  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Variable Selection Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 'ap_hi' (highest co-relation)\n",
    "2. 'bmi', 'ap_hi', 'ap_lo','cholesterol','age'\n",
    "3. 'bmi', 'age', ‘bp’, 'cholesterol'\n",
    "4. ‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol'\n",
    "5. 'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active', 'weight' (all variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some more explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Baseline model (ap_hi only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7425574 0.735634  0.7298479]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73377019 0.74223865 0.73171025]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM using BMI, age, ap_hi, ap_lo, cholesterol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72368417 0.60739185 0.70509633]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77701171 0.77547317 0.77613334]\n"
     ]
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "svm_clf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "aucs = cross_val_score(svm_clf, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('classifier',\n",
       "                                        SGDClassifier(alpha=0.0001,\n",
       "                                                      average=False,\n",
       "                                                      class_weight=None,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=0.1, eta0=0.0,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      l1_ratio=0.15,\n",
       "                                                      learning_rate='optimal',\n",
       "                                                      loss='hinge',\n",
       "                                                      max_it...\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'classifier__alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1],\n",
       "                          'classifier__loss': ['modified_huber'],\n",
       "                          'classifier__penalty': ['l1', 'l2', 'elasticnet']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['ap_hi', 'ap_lo', 'bmi', 'age', 'cholesterol']]\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__loss': ['modified_huber'],\n",
    "   'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "   'classifier__alpha': [.001, .01, .05, .1, .5, 1]}\n",
    " ]\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SGDClassifier())])\n",
    "\n",
    "clf = GridSearchCV(svm, param_grid, scoring=\"roc_auc\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.01,\n",
       " 'classifier__loss': 'modified_huber',\n",
       " 'classifier__penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best auc: 0.775945 using {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.774276 (0.003020) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.773332 (0.001356) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.773893 (0.001474) with: {'classifier__alpha': 0.001, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.775523 (0.000801) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.774672 (0.001004) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775945 (0.001854) with: {'classifier__alpha': 0.01, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.775161 (0.000670) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.775641 (0.000980) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775855 (0.001158) with: {'classifier__alpha': 0.05, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.775388 (0.001566) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.775604 (0.001511) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775726 (0.001287) with: {'classifier__alpha': 0.1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.733432 (0.001926) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.773784 (0.001604) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775564 (0.001489) with: {'classifier__alpha': 0.5, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n",
      "0.500000 (0.000000) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l1'}\n",
      "0.772542 (0.001764) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'l2'}\n",
      "0.775183 (0.001653) with: {'classifier__alpha': 1, 'classifier__loss': 'modified_huber', 'classifier__penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best auc: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77007485 0.7667135  0.77846179]\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model = clf.best_estimator_ #this was alpha=.1, loss='modified_huber', penalty='elasticnet'\n",
    "calibrator = CalibratedClassifierCV(model, cv=3)\n",
    "\n",
    "aucs = cross_val_score(calibrator, X, y=y, cv=cv_object, scoring = 'roc_auc')\n",
    "print(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model ROC AUC=0.761\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "scl_obj = std_scl.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test) \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "svm_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "svm_probs = svm_probs[:, 1]\n",
    "# calculate scores\n",
    "svm_auc = roc_auc_score(y_test, svm_probs)\n",
    "# summarize scores\\\n",
    "print('SVM Model ROC AUC=%.3f' % (svm_auc))\n",
    "# calculate roc curves\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(svm_fpr, svm_tpr, marker='.', label='SVM')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find probability threshold for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33405097, 0.47074938, 0.32091254, ..., 0.31125349, 0.71742679,\n",
       "       0.99003976])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.000000 : accuracy=0.561\n",
      "alpha 0.100000 : accuracy=0.561\n",
      "alpha 0.200000 : accuracy=0.575\n",
      "alpha 0.300000 : accuracy=0.631\n",
      "alpha 0.400000 : accuracy=0.695\n",
      "alpha 0.500000 : accuracy=0.698\n",
      "alpha 0.600000 : accuracy=0.681\n",
      "alpha 0.700000 : accuracy=0.625\n",
      "alpha 0.800000 : accuracy=0.569\n",
      "alpha 0.900000 : accuracy=0.522\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, .1)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune a little finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.400000 : accuracy=0.695\n",
      "alpha 0.410000 : accuracy=0.698\n",
      "alpha 0.420000 : accuracy=0.700\n",
      "alpha 0.430000 : accuracy=0.702\n",
      "alpha 0.440000 : accuracy=0.703\n",
      "alpha 0.450000 : accuracy=0.704\n",
      "alpha 0.460000 : accuracy=0.700\n",
      "alpha 0.470000 : accuracy=0.699\n",
      "alpha 0.480000 : accuracy=0.699\n",
      "alpha 0.490000 : accuracy=0.698\n",
      "alpha 0.500000 : accuracy=0.698\n",
      "alpha 0.510000 : accuracy=0.697\n",
      "alpha 0.520000 : accuracy=0.697\n",
      "alpha 0.530000 : accuracy=0.697\n",
      "alpha 0.540000 : accuracy=0.695\n",
      "alpha 0.550000 : accuracy=0.694\n",
      "alpha 0.560000 : accuracy=0.692\n",
      "alpha 0.570000 : accuracy=0.689\n",
      "alpha 0.580000 : accuracy=0.687\n",
      "alpha 0.590000 : accuracy=0.684\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(.4, .6, .01)\n",
    "for alpha in np.nditer(alphas):\n",
    "    y_hat = list(map(lambda y_prob: 1 if y_prob > alpha else 0, svm_probs))\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    print('alpha %f : accuracy=%.3f' % (alpha, acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are multiple parameters that can help build a Logistic  Regression model listed below with the default value.  \n",
    "\n",
    "\n",
    "*(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None])*\n",
    "\n",
    "\n",
    "\n",
    "However, our team decided to focus on few critical in tuning process like C, solver and penalty. \n",
    "\n",
    "\n",
    "\n",
    "Hyperparameters sets the algorithm that can be adjusted to optimize performance, these are the knobs to generate optimal outcome. These Hyperparameters in machine learning model help define your model architecture. Leveraging grid search optimal automated exploration is launched to find the optimal parameter value to extract best model architecture. \n",
    "\n",
    "The project Grid search approach was used to tune the parameters of the model. Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid. However, grid search suffers from the curse of dimensionality: the number of times required to evaluate the model during hyperparameter optimization grows exponentially in the number of parameters. \n",
    "\n",
    "The other popular method is Random Search. It is performed by evaluating n uniformly random points in the hyperparameter space and select the one producing the best performance. The drawback of random search is unnecessarily high variance. The method is, after all, entirely random, and uses no intelligence in selecting which points to try. You are relying on luck to get good results.\n",
    "\n",
    "In the model building excises Grid Search was used and to overcome the curse of dimensionality hyper parameter list was highly evaluated and one making maxim impact were chosen. The model tuning process three parameters were considered, C, penalty and Solver. \n",
    "\n",
    "<b>C:</b> This control the complexity and simplicity of model. However, complexity can lead to over fitting vs. simplicity will lead to under fitting. Small values of C, we increase the regularization strength which will create simple models which underfit the data. For big values of C the power of regularization is decrease which impels the model is allowed to increase it's complexity, and therefore, overfit the data. \n",
    "\n",
    "<b>Penalty:</b> This project uses two penalties. Li and L2. The Penalty is used to specify the penalization method of the coefficients of noncontributing or less contributing variables.\n",
    "Lasso (L1) performs feature selection by shrinking the less important feature’s coefficient to zero.\n",
    "Ridge (L2) all variables are included in the model, though some are shrunk (but not to zero like L1 Penalty. Less computationally intensive than lasso.\n",
    "Both penalty values restrict solver choices. It is critical to choose the right combination of Penalty.\n",
    "\n",
    "\n",
    "\n",
    "<b>Solver:</b> Are the algorithm used in Logistic Regression to predict the outcome. Default value is lbfgs. other possible values (to list few) are, liblinear, sag and saga.\n",
    "liblinear − It is a good choice for small datasets. It also handles L1 penalty. For multiclass problems, it is limited to one-versus-rest schemes.\n",
    "lbfgs − For multiclass problems, it handles multinomial loss. It also handles only L2 penalty.\n",
    "saga − It is a good choice for large datasets. For multiclass problems, it also handles multinomial loss. Along with L1 penalty, it also supports ‘elasticnet’ penalty.\n",
    "sag − It is also used for large datasets. For multiclass problems, it also handles multinomial loss.\n",
    "\n",
    "\n",
    "\n",
    "<b>Ref:</b> \n",
    "https://sigopt.com/blog/common-problems-in-hyperparameter-optimization\n",
    "\n",
    "https://towardsdatascience.com/hyper-parameter-tuning-and-model-selection-like-a-movie-star-a884b8ee8d\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "df1 = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "#df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    " \n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elevated</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage1</th>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage2</th>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "Following are combo I selected based on high correlation and removing\n",
    "\n",
    "'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "'ap_hi' (highest co-relation)\n",
    "'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','gluc','smoke','alco','active','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.56433924, 0.64494141, 0.51362602, 0.87200109, 0.62565875,\n",
       "        0.13596837, 0.13563744, 0.18317771, 0.1768616 , 0.15824223]),\n",
       " 'std_fit_time': array([0.11467713, 0.09939101, 0.11071117, 0.25055357, 0.09812524,\n",
       "        0.03430025, 0.00814316, 0.02075014, 0.04631067, 0.03341949]),\n",
       " 'mean_score_time': array([0.00498637, 0.00365694, 0.00432197, 0.00498613, 0.00432229,\n",
       "        0.00398954, 0.0049866 , 0.0049843 , 0.00465361, 0.00432237]),\n",
       " 'std_score_time': array([8.14393390e-04, 4.70077860e-04, 4.70077860e-04, 8.14782773e-04,\n",
       "        4.69853158e-04, 8.14588058e-04, 8.14393390e-04, 3.15297992e-06,\n",
       "        4.70134691e-04, 4.70639899e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77362172, 0.77353775, 0.77366599, 0.77366783, 0.77377593,\n",
       "        0.62479078, 0.62479327, 0.62479413, 0.62479406, 0.62479403]),\n",
       " 'split1_test_score': array([0.77291339, 0.77279614, 0.77278872, 0.77278716, 0.77276188,\n",
       "        0.61148701, 0.61148625, 0.61148632, 0.61148632, 0.61148632]),\n",
       " 'split2_test_score': array([0.78296495, 0.7827396 , 0.7828581 , 0.78273671, 0.78277562,\n",
       "        0.62003942, 0.62003844, 0.62003848, 0.62003848, 0.62003848]),\n",
       " 'mean_test_score': array([0.77650002, 0.77635783, 0.7764376 , 0.77639723, 0.77643781,\n",
       "        0.6187724 , 0.61877265, 0.61877298, 0.61877295, 0.61877294]),\n",
       " 'std_test_score': array([0.00458054, 0.00452274, 0.00455408, 0.00449708, 0.00450059,\n",
       "        0.00550464, 0.00550581, 0.00550609, 0.00550607, 0.00550605]),\n",
       " 'rank_test_score': array([ 1,  5,  3,  4,  2, 10,  9,  6,  7,  8])}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a grid search for logistic regression\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.776500 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.776500 (0.004581) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.776358 (0.004523) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.776438 (0.004554) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.776397 (0.004497) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.776438 (0.004501) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.618772 (0.005505) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.618773 (0.005506) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.618773 (0.005506) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.618773 (0.005506) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.618773 (0.005506) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=1000, class_weight=None, solver='liblinear' ) # get object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7745925371623696\n",
      "confusion matrix\n",
      " [[3324 1330]\n",
      " [1673 4284]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7668001045237833\n",
      "confusion matrix\n",
      " [[3352 1362]\n",
      " [1785 4112]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7750326945691538\n",
      "confusion matrix\n",
      " [[3400 1286]\n",
      " [1764 4161]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.06449413, 0.16987896, 0.08909416, 0.18816344, 0.07081064,\n",
       "        0.15757839, 0.06382926, 0.12366875, 0.06582411, 0.12333608,\n",
       "        0.04290072, 0.14328329, 0.10139513, 0.04454764, 0.17586279,\n",
       "        0.11702029, 0.04488015, 0.16688633, 0.14660668, 0.04971949,\n",
       "        0.20312333, 0.1283234 , 0.0428857 , 0.19514434, 0.12799072]),\n",
       " 'std_fit_time': array([0.01062792, 0.01084416, 0.00124433, 0.00803367, 0.0045337 ,\n",
       "        0.02040716, 0.00533999, 0.01468031, 0.00141063, 0.00729892,\n",
       "        0.00160965, 0.01434551, 0.00678076, 0.00600238, 0.03717734,\n",
       "        0.01306303, 0.00430903, 0.00463084, 0.01547223, 0.00278997,\n",
       "        0.0168137 , 0.00339034, 0.00215439, 0.02079793, 0.00477116]),\n",
       " 'mean_score_time': array([0.00497468, 0.00598407, 0.00698209, 0.00532039, 0.00498692,\n",
       "        0.00531761, 0.00432158, 0.0039893 , 0.00498668, 0.0053192 ,\n",
       "        0.00431856, 0.00398914, 0.00465441, 0.0053188 , 0.00398906,\n",
       "        0.00465425, 0.00465409, 0.00531912, 0.00531928, 0.00465417,\n",
       "        0.00531896, 0.00432158, 0.00398882, 0.00432173, 0.00465433]),\n",
       " 'std_score_time': array([8.29035770e-04, 8.14782881e-04, 3.89335909e-07, 1.24557841e-03,\n",
       "        8.14977441e-04, 1.24556240e-03, 9.40043329e-04, 2.97360213e-07,\n",
       "        8.13712082e-04, 9.40605287e-04, 1.24469357e-03, 1.12391596e-07,\n",
       "        4.70190333e-04, 9.40155721e-04, 4.05233662e-07, 4.70246438e-04,\n",
       "        4.69965550e-04, 4.70021695e-04, 4.70415116e-04, 4.70358870e-04,\n",
       "        4.70302644e-04, 4.70021655e-04, 2.24783192e-07, 4.70246438e-04,\n",
       "        9.40436725e-04]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77631568, 0.77631799, 0.77630809, 0.77630799, 0.77630831,\n",
       "        0.77630791, 0.77630755, 0.77630726, 0.77630737, 0.77630752,\n",
       "        0.77630719, 0.7763069 , 0.77630766, 0.77630654, 0.77630777,\n",
       "        0.77630665, 0.77630759, 0.77630726, 0.77630766, 0.77630741,\n",
       "        0.77630824, 0.77630773, 0.7763073 , 0.77630737, 0.77630734]),\n",
       " 'split1_test_score': array([0.78102875, 0.7810306 , 0.78101441, 0.78101535, 0.78101405,\n",
       "        0.78101571, 0.78101496, 0.78101553, 0.7810142 , 0.78101539,\n",
       "        0.78100546, 0.78100585, 0.78100343, 0.78101373, 0.78101355,\n",
       "        0.78101506, 0.78101521, 0.78101528, 0.7810142 , 0.78101521,\n",
       "        0.7810146 , 0.78101535, 0.78101521, 0.78101496, 0.78101496]),\n",
       " 'split2_test_score': array([0.77201767, 0.77201893, 0.77201547, 0.77201565, 0.77201486,\n",
       "        0.77201471, 0.77201497, 0.77201475, 0.7720146 , 0.77201529,\n",
       "        0.77201323, 0.77201349, 0.77201352, 0.77201565, 0.77201518,\n",
       "        0.77201417, 0.77201547, 0.77201616, 0.77201525, 0.77201576,\n",
       "        0.772015  , 0.77201515, 0.77201569, 0.77201479, 0.77201576]),\n",
       " 'mean_test_score': array([0.77645403, 0.77645584, 0.77644599, 0.77644633, 0.77644574,\n",
       "        0.77644611, 0.77644582, 0.77644585, 0.77644539, 0.77644607,\n",
       "        0.77644196, 0.77644208, 0.77644154, 0.77644531, 0.7764455 ,\n",
       "        0.7764453 , 0.77644609, 0.77644623, 0.7764457 , 0.77644613,\n",
       "        0.77644594, 0.77644608, 0.77644606, 0.7764457 , 0.77644602]),\n",
       " 'std_test_score': array([0.00368006, 0.00368029, 0.0036751 , 0.00367542, 0.00367519,\n",
       "        0.00367594, 0.00367553, 0.00367586, 0.00367536, 0.00367558,\n",
       "        0.0036723 , 0.00367236, 0.00367134, 0.00367476, 0.00367486,\n",
       "        0.00367591, 0.00367543, 0.00367519, 0.0036751 , 0.00367532,\n",
       "        0.00367536, 0.00367562, 0.00367535, 0.00367561, 0.00367522]),\n",
       " 'rank_test_score': array([ 2,  1, 12,  3, 16,  6, 15, 14, 20,  9, 24, 23, 25, 21, 19, 22,  7,\n",
       "         4, 18,  5, 13,  8, 10, 17, 11])}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.776456 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776454 (0.003680) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776456 (0.003680) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776445 (0.003675) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776442 (0.003672) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776442 (0.003672) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776442 (0.003671) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776445 (0.003675) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776445 (0.003675) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776445 (0.003676) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776446 (0.003676) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776446 (0.003675) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749714293946777\n",
      "[0.71020639 0.71114881 0.7135991 ]\n"
     ]
    }
   ],
   "source": [
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7643587600026608\n",
      "confusion matrix\n",
      " [[3383 1342]\n",
      " [1760 4126]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7779199363845227\n",
      "confusion matrix\n",
      " [[3431 1299]\n",
      " [1712 4169]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7737970666712515\n",
      "confusion matrix\n",
      " [[3433 1284]\n",
      " [1760 4134]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29714113, 0.89570692, 0.1285665 , 0.28284633, 0.10073921]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.774\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"cardio_train.csv\", sep=\";\")\n",
    "#df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elevated</th>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage1</th>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage2</th>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyper_Stage3</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3\n",
    "Following are combo I selected based on high correlation and removing\n",
    "\n",
    "'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "'ap_hi' (highest co-relation)\n",
    "'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "df1\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ellen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.76628423, 1.02961103, 0.97273175, 0.81980681, 0.7214276 ,\n",
       "        0.13198137, 0.20013221, 0.1672198 , 0.16356285, 0.1841735 ]),\n",
       " 'std_fit_time': array([0.06352953, 0.1204915 , 0.27850657, 0.10984514, 0.06397788,\n",
       "        0.03456158, 0.09933532, 0.07361484, 0.07687842, 0.0806396 ]),\n",
       " 'mean_score_time': array([0.00465385, 0.00498605, 0.00465385, 0.00398914, 0.00396546,\n",
       "        0.00398866, 0.00432134, 0.00432134, 0.00432126, 0.0049874 ]),\n",
       " 'std_score_time': array([4.69459737e-04, 1.03008599e-06, 1.24398522e-03, 2.97360213e-07,\n",
       "        1.59774052e-05, 5.94720425e-07, 4.70527507e-04, 4.70190494e-04,\n",
       "        4.70415035e-04, 8.15464186e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77699047, 0.77705618, 0.77703519, 0.77707854, 0.77702681,\n",
       "        0.62727052, 0.62727045, 0.62727042, 0.62727045, 0.62727049]),\n",
       " 'split1_test_score': array([0.78118661, 0.78127102, 0.78126317, 0.78119204, 0.78104972,\n",
       "        0.6239296 , 0.67127912, 0.65256644, 0.65256651, 0.65256488]),\n",
       " 'split2_test_score': array([0.77827206, 0.77816687, 0.77818274, 0.77812963, 0.77817975,\n",
       "        0.62455325, 0.62455278, 0.62455282, 0.62455282, 0.62455282]),\n",
       " 'mean_test_score': array([0.77881638, 0.77883136, 0.77882703, 0.77880007, 0.7787521 ,\n",
       "        0.62525112, 0.64103412, 0.63479656, 0.63479659, 0.63479606]),\n",
       " 'std_test_score': array([0.00175577, 0.0017837 , 0.00178518, 0.00174496, 0.00169148,\n",
       "        0.00145045, 0.02141521, 0.01261409, 0.01261412, 0.01261334]),\n",
       " 'rank_test_score': array([ 3,  1,  2,  4,  5, 10,  6,  8,  7,  9])}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.778831 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778816 (0.001756) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778831 (0.001784) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778827 (0.001785) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778800 (0.001745) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778752 (0.001691) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.625251 (0.001450) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.641034 (0.021415) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634797 (0.012614) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634797 (0.012614) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634796 (0.012613) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.778831 using {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778816 (0.001756) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778831 (0.001784) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778827 (0.001785) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778800 (0.001745) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778752 (0.001691) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.625251 (0.001450) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.641034 (0.021415) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634797 (0.012614) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634797 (0.012614) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.634796 (0.012613) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7780257418339118\n",
      "confusion matrix\n",
      " [[3330 1338]\n",
      " [1628 4315]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7839205793065955\n",
      "confusion matrix\n",
      " [[3394 1272]\n",
      " [1721 4224]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7760973052063483\n",
      "confusion matrix\n",
      " [[3381 1307]\n",
      " [1727 4196]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.09241843, 0.2087756 , 0.10571734, 0.20245735, 0.08211374,\n",
       "        0.25199294, 0.10937428, 0.30536819, 0.11635566, 0.24102211,\n",
       "        0.04620965, 0.20212483, 0.18517121, 0.04753963, 0.24467953,\n",
       "        0.16954668, 0.04920181, 0.2430172 , 0.16854914, 0.04620949,\n",
       "        0.23437421, 0.16590254, 0.04854719, 0.25666142, 0.17453313]),\n",
       " 'std_fit_time': array([0.01018199, 0.00971508, 0.00987304, 0.00723825, 0.01018244,\n",
       "        0.0305606 , 0.01708759, 0.04735486, 0.00738885, 0.04782605,\n",
       "        0.00204958, 0.0087836 , 0.02974581, 0.00204915, 0.00799278,\n",
       "        0.01389112, 0.00611176, 0.0129354 , 0.01000683, 0.00124435,\n",
       "        0.01148778, 0.00896147, 0.00045479, 0.02550922, 0.01572916]),\n",
       " 'mean_score_time': array([0.00465441, 0.00531904, 0.00731365, 0.00465584, 0.00498796,\n",
       "        0.00465377, 0.00665053, 0.00498557, 0.00764632, 0.0053188 ,\n",
       "        0.00498637, 0.00432181, 0.0049866 , 0.00465385, 0.00398842,\n",
       "        0.00465433, 0.00498652, 0.00432102, 0.00498692, 0.00498676,\n",
       "        0.00432118, 0.0049866 , 0.00465385, 0.00464034, 0.00398922]),\n",
       " 'std_score_time': array([4.70358829e-04, 4.70415277e-04, 4.69909263e-04, 9.39369141e-04,\n",
       "        6.74349576e-07, 4.70583653e-04, 4.71261983e-04, 1.40939063e-03,\n",
       "        9.40211942e-04, 4.69572088e-04, 8.14490753e-04, 4.70190333e-04,\n",
       "        8.14588058e-04, 4.70302644e-04, 4.89903609e-07, 4.70471221e-04,\n",
       "        0.00000000e+00, 4.70246478e-04, 8.14198722e-04, 3.37174788e-07,\n",
       "        4.70809040e-04, 8.14685398e-04, 4.70808436e-04, 4.89746622e-04,\n",
       "        0.00000000e+00]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.7826273 , 0.78263109, 0.78260967, 0.78261032, 0.78261032,\n",
       "        0.78261093, 0.78261267, 0.78260963, 0.78261028, 0.78261054,\n",
       "        0.7826031 , 0.78260205, 0.78260227, 0.78260945, 0.78260956,\n",
       "        0.78261018, 0.78261151, 0.7826109 , 0.78261036, 0.78261151,\n",
       "        0.78261043, 0.78261003, 0.78261148, 0.7826101 , 0.78261086]),\n",
       " 'split1_test_score': array([0.77313026, 0.77313303, 0.77308128, 0.77308139, 0.77307598,\n",
       "        0.77307703, 0.77307526, 0.77307735, 0.77307465, 0.77307681,\n",
       "        0.77306593, 0.77306679, 0.7730664 , 0.7730762 , 0.77307678,\n",
       "        0.77307602, 0.77307577, 0.77307588, 0.77307638, 0.77307613,\n",
       "        0.77307552, 0.77307699, 0.77307606, 0.77307706, 0.77307616]),\n",
       " 'split2_test_score': array([0.77710948, 0.77711341, 0.77707825, 0.77707828, 0.7770742 ,\n",
       "        0.7770759 , 0.77707406, 0.77707449, 0.77707373, 0.7770733 ,\n",
       "        0.77708251, 0.77708215, 0.77708229, 0.77707438, 0.77707514,\n",
       "        0.77707492, 0.77707355, 0.77707417, 0.77707344, 0.77707348,\n",
       "        0.77707377, 0.77707391, 0.77707341, 0.77707294, 0.77707456]),\n",
       " 'mean_test_score': array([0.77762234, 0.77762584, 0.77758973, 0.77759   , 0.77758684,\n",
       "        0.77758795, 0.77758733, 0.77758716, 0.77758622, 0.77758688,\n",
       "        0.77758384, 0.77758366, 0.77758365, 0.77758668, 0.77758716,\n",
       "        0.77758704, 0.77758694, 0.77758698, 0.77758673, 0.77758704,\n",
       "        0.77758657, 0.77758698, 0.77758698, 0.7775867 , 0.7775872 ]),\n",
       " 'std_test_score': array([0.00389407, 0.00389446, 0.00390673, 0.00390696, 0.00390922,\n",
       "        0.00390901, 0.00391051, 0.00390839, 0.00390974, 0.00390903,\n",
       "        0.00390964, 0.00390887, 0.00390911, 0.00390876, 0.00390855,\n",
       "        0.00390911, 0.00390984, 0.00390951, 0.00390911, 0.00390971,\n",
       "        0.00390946, 0.00390872, 0.00390972, 0.00390877, 0.00390937]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3, 17,  5,  6,  9, 22, 16, 23, 24, 25, 20,  8, 11, 15,\n",
       "        12, 18, 10, 21, 14, 13, 19,  7])}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.777626 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777622 (0.003894) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777626 (0.003894) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777590 (0.003907) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777590 (0.003907) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777588 (0.003909) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003911) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777587 (0.003908) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777586 (0.003910) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777584 (0.003910) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777584 (0.003909) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777584 (0.003909) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003910) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777587 (0.003910) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003910) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777587 (0.003910) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777587 (0.003909) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761565481414212\n",
      "[0.71595514 0.70869852 0.71859391]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7795611436020357\n",
      "confusion matrix\n",
      " [[3393 1273]\n",
      " [1723 4222]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7724868254110693\n",
      "confusion matrix\n",
      " [[3326 1383]\n",
      " [1705 4197]]\n",
      "====Iteration 2  ====\n",
      "auc 0.782566524098974\n",
      "confusion matrix\n",
      " [[3452 1273]\n",
      " [1710 4176]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29565197,  0.90210508,  0.129676  ,  0.32371193, -0.07848186,\n",
       "        -0.03659014, -0.04822248, -0.09435681,  0.10182126]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following is the summary of Analysis that was run on Logistic Regression and SVM with Five options in unscaled and scaled options.\n",
    "\n",
    "The chart below shows the comparison of all models we ran on AUC score.   We are showing the results of the more significant models in the main body of this notebook, and have included the models of less interest in the Appendix.\n",
    "\n",
    "We compared all models both with and without scaling the data.  \n",
    "\n",
    "The highest performing model for Logistic Regression, per AUC, was Option 3, which included all variables.   A very close score was obtained for Option 1, which included: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age.   Since these Option 1 variables were our most significant variables per our Exploratory Data Analysis, we chose Option 1 as our preferred model.  For these Logistical Regression models, scaling the data did not seem to help.\n",
    "\n",
    "The highest performing model for SVM was option 1 with the variables described above.   In this case, scaling the data did make a difference.\n",
    "\n",
    "Our primary model is Logistic Regression, unscaled data with the following attributes: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age.\n",
    "\n",
    "Our backup/ secondary model is SVM with scaled data and the following attributes: Body Mass Index, Systolic Blood Pressure, Diastolic Blood pressure, Cholesterol and Age."
   ]
  },
  {
   "attachments": {
    "compare.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compare.png](attachment:compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite SVM model is Option 1 Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix / classification report  - Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision, recall, f1, accuracy - Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the hyperparameters - Tina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make SVC from subsampled set - Tina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite Logistic model is Option 1 Unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix / classification report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the hyperparameters - Paritosh, Fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite model overall is the Logistic regression option 1 unscaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is one better about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is one better from accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bp</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>34.927679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>23.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>28.710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>29.384676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>37.729725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio            bp        bmi  \n",
       "1     0       1       1  Hyper_Stage2  34.927679  \n",
       "2     0       0       1  Hyper_Stage1  23.507805  \n",
       "3     0       1       1  Hyper_Stage2  28.710479  \n",
       "5     0       0       0  Hyper_Stage1  29.384676  \n",
       "6     0       1       0  Hyper_Stage1  37.729725  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_clean\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['bmi', 'ap_hi', 'ap_lo','cholesterol','age']]\n",
    "y = df['cardio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#make CV spit 80/20 object\\n\\nnum_cv_iterations = 3\\nnum_instances = len(y)\\ncv_object = ShuffleSplit(n_splits=num_cv_iterations,\\n                         test_size  = 0.2)\\n                         \\nprint(cv_object)\\n'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#make CV spit 80/20 object\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Decision Tree Model\n",
    "Let's start by training a single decision tree first!\n",
    "\n",
    "** Import DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation of Decision Tree\n",
    "\n",
    "Create predictions from the test set and create a classification report and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      4679\n",
      "           1       0.67      0.67      0.67      5932\n",
      "\n",
      "    accuracy                           0.63     10611\n",
      "   macro avg       0.62      0.62      0.62     10611\n",
      "weighted avg       0.63      0.63      0.63     10611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.6237689612430226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics as mt\n",
    "auc = mt.roc_auc_score(y_test,predictions)\n",
    "print(\"auc\", auc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Random Forest model\n",
    "Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Evaluation\n",
    "Let's predict off the y_test values and evaluate our model.\n",
    "\n",
    "** Predict the class of not.fully.paid for the X_test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a classification report from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      4679\n",
      "           1       0.71      0.73      0.72      5932\n",
      "\n",
      "    accuracy                           0.68     10611\n",
      "   macro avg       0.68      0.68      0.68     10611\n",
      "weighted avg       0.68      0.68      0.68     10611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following Logistical Regression Models were rejected, but they were not far in accuracy and AUC scores from the preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2   AP_HI variable only (systolic blood pressure).  With unscaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','gluc','smoke','alco','active','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.59676925, 0.82714343, 0.4690938 , 0.56981913, 0.67389536,\n",
       "        0.20877488, 0.17586263, 0.17718148, 0.15691272, 0.21043698]),\n",
       " 'std_fit_time': array([0.09953698, 0.1779119 , 0.09510146, 0.16243457, 0.19888046,\n",
       "        0.07100195, 0.04217917, 0.04620582, 0.05259981, 0.09405589]),\n",
       " 'mean_score_time': array([0.00700227, 0.0036339 , 0.00364161, 0.00364685, 0.00295989,\n",
       "        0.00598399, 0.00465504, 0.00332435, 0.00631738, 0.00432158]),\n",
       " 'std_score_time': array([5.01612216e-03, 4.54131439e-04, 4.59480172e-04, 4.62948024e-04,\n",
       "        2.28453717e-05, 2.15438807e-03, 1.69654192e-03, 4.69965550e-04,\n",
       "        2.48858646e-03, 1.88042379e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77436411, 0.77434394, 0.77423573, 0.77433893, 0.77432185,\n",
       "        0.61547778, 0.61547771, 0.61547767, 0.61547767, 0.61547767]),\n",
       " 'split1_test_score': array([0.76548753, 0.76537142, 0.76543481, 0.76548649, 0.7653571 ,\n",
       "        0.65328433, 0.65326677, 0.65326544, 0.65326493, 0.65326497]),\n",
       " 'split2_test_score': array([0.7802853 , 0.78036549, 0.78036065, 0.78030579, 0.78022412,\n",
       "        0.64261832, 0.64260674, 0.64260443, 0.64260512, 0.78041703]),\n",
       " 'mean_test_score': array([0.77337898, 0.77336028, 0.77334373, 0.77337707, 0.77330102,\n",
       "        0.63712681, 0.63711707, 0.63711585, 0.63711591, 0.68305322]),\n",
       " 'std_test_score': array([0.00608119, 0.00616069, 0.00612601, 0.00608807, 0.00611221,\n",
       "        0.01591543, 0.01590819, 0.01590749, 0.0159074 , 0.07055378]),\n",
       " 'rank_test_score': array([ 1,  3,  4,  2,  5,  7,  8, 10,  9,  6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.773379 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773379 (0.006081) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773360 (0.006161) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773344 (0.006126) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773377 (0.006088) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773301 (0.006112) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.637127 (0.015915) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637117 (0.015908) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637116 (0.015907) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637116 (0.015907) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.683053 (0.070554) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l1', C=1000, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7778126510967109\n",
      "confusion matrix\n",
      " [[3381 1311]\n",
      " [1732 4187]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7732837004564681\n",
      "confusion matrix\n",
      " [[3378 1295]\n",
      " [1762 4176]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7774341023047546\n",
      "confusion matrix\n",
      " [[3339 1361]\n",
      " [1646 4265]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0724771 , 0.14029209, 0.0588425 , 0.12036641, 0.0681409 ,\n",
       "        0.11003931, 0.06449445, 0.11868278, 0.05589135, 0.15026553,\n",
       "        0.03855356, 0.12066483, 0.1067156 , 0.04521147, 0.1698796 ,\n",
       "        0.1279796 , 0.03623637, 0.16784644, 0.12930894, 0.03658096,\n",
       "        0.18417303, 0.11136858, 0.0378987 , 0.13830805, 0.10038638]),\n",
       " 'std_fit_time': array([0.01093367, 0.00870546, 0.00354984, 0.01165632, 0.01434765,\n",
       "        0.00169528, 0.01155431, 0.02891668, 0.00217465, 0.01434609,\n",
       "        0.00417367, 0.0111725 , 0.0168263 , 0.00835769, 0.01141046,\n",
       "        0.01435748, 0.00470168, 0.00122883, 0.01305101, 0.00188802,\n",
       "        0.02835262, 0.0012445 , 0.00570075, 0.00752963, 0.00385977]),\n",
       " 'mean_score_time': array([0.00365297, 0.00365599, 0.00465417, 0.00497707, 0.00399963,\n",
       "        0.00365655, 0.00365678, 0.00365607, 0.00394869, 0.003335  ,\n",
       "        0.00398819, 0.00332673, 0.0033261 , 0.00531888, 0.00332419,\n",
       "        0.00498668, 0.00398954, 0.00432316, 0.00332451, 0.00332419,\n",
       "        0.00465536, 0.0036571 , 0.00398922, 0.0046552 , 0.00465425]),\n",
       " 'std_score_time': array([4.67629557e-04, 4.70078344e-04, 4.70190736e-04, 8.27768805e-04,\n",
       "        1.54087198e-05, 4.70302644e-04, 4.70134086e-04, 9.39256568e-04,\n",
       "        5.79940636e-05, 4.61953373e-04, 8.77806426e-07, 4.72831444e-04,\n",
       "        4.68227436e-04, 1.88008666e-03, 4.70077860e-04, 2.15427770e-03,\n",
       "        4.49566384e-07, 1.22582790e-03, 4.70358870e-04, 4.70077941e-04,\n",
       "        4.70527910e-04, 4.70358870e-04, 3.89335909e-07, 1.69255247e-03,\n",
       "        2.35038925e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77735931, 0.77736586, 0.77734318, 0.77734297, 0.77734038,\n",
       "        0.7773411 , 0.77734002, 0.7773416 , 0.7773403 , 0.77734052,\n",
       "        0.77731994, 0.77731922, 0.77731979, 0.77734009, 0.77733915,\n",
       "        0.77734052, 0.77734178, 0.77734059, 0.77734102, 0.77734153,\n",
       "        0.77734074, 0.77734167, 0.7773416 , 0.77734196, 0.77734214]),\n",
       " 'split1_test_score': array([0.77797437, 0.77797938, 0.77796425, 0.77796386, 0.77796375,\n",
       "        0.77796339, 0.77796465, 0.77796306, 0.77796404, 0.77796378,\n",
       "        0.77794916, 0.77794902, 0.77794862, 0.77796371, 0.77796378,\n",
       "        0.77796418, 0.7779636 , 0.77796296, 0.77796025, 0.77796321,\n",
       "        0.77796213, 0.77796346, 0.77796321, 0.77796468, 0.77796389]),\n",
       " 'split2_test_score': array([0.77379457, 0.77379915, 0.77379064, 0.77379223, 0.77379122,\n",
       "        0.77379075, 0.77378956, 0.77379064, 0.77378859, 0.77379086,\n",
       "        0.77378851, 0.77378884, 0.77378862, 0.77378855, 0.77378837,\n",
       "        0.77378866, 0.77379061, 0.77379154, 0.77379028, 0.77379061,\n",
       "        0.77379043, 0.77379089, 0.77379061, 0.77379075, 0.77379107]),\n",
       " 'mean_test_score': array([0.77637608, 0.77638146, 0.77636603, 0.77636635, 0.77636511,\n",
       "        0.77636508, 0.77636474, 0.7763651 , 0.77636431, 0.77636505,\n",
       "        0.77635254, 0.77635236, 0.77635235, 0.77636412, 0.77636377,\n",
       "        0.77636445, 0.77636533, 0.77636503, 0.77636385, 0.77636511,\n",
       "        0.77636443, 0.77636534, 0.77636514, 0.7763658 , 0.7763657 ]),\n",
       " 'std_test_score': array([0.00184259, 0.00184307, 0.00183864, 0.00183774, 0.00183773,\n",
       "        0.00183797, 0.0018387 , 0.00183801, 0.00183902, 0.00183793,\n",
       "        0.00183115, 0.00183083, 0.00183091, 0.00183891, 0.00183885,\n",
       "        0.00183907, 0.00183822, 0.00183738, 0.00183727, 0.00183806,\n",
       "        0.00183769, 0.00183802, 0.00183807, 0.0018385 , 0.00183815]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3, 10, 13, 16, 12, 19, 14, 23, 24, 25, 20, 22, 17,  8,\n",
       "        15, 21, 11, 18,  7,  9,  5,  6])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.776381 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776376 (0.001843) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776381 (0.001843) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776366 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001839) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.776353 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776352 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776352 (0.001831) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776364 (0.001839) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776365 (0.001837) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776364 (0.001837) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776364 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.776365 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.776366 (0.001838) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7772939740908584\n",
      "[0.7181227  0.71689756 0.71237395]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7757609974791919\n",
      "confusion matrix\n",
      " [[3425 1301]\n",
      " [1714 4171]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7789532951984123\n",
      "confusion matrix\n",
      " [[3418 1332]\n",
      " [1659 4202]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7750579545752139\n",
      "confusion matrix\n",
      " [[3354 1299]\n",
      " [1772 4186]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29725385, 0.8957176 , 0.12865162, 0.28283007, 0.10075454]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','age','gender','height','weight','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bmi','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.06715377, 2.32718468, 3.63931052, 0.05352354, 2.02214718,\n",
       "        3.6851689 , 0.0418884 , 2.02882441, 3.57047542, 0.04785983,\n",
       "        2.02494955, 3.58376257, 0.06781888, 1.99593377, 3.53813108]),\n",
       " 'std_fit_time': array([0.00448684, 0.31920119, 0.05985453, 0.01293594, 0.03740269,\n",
       "        0.05784741, 0.00081381, 0.05553029, 0.06400667, 0.00706186,\n",
       "        0.02777344, 0.07860238, 0.01332982, 0.0424709 , 0.04103285]),\n",
       " 'mean_score_time': array([0.00365583, 0.00395568, 0.00294582, 0.00332403, 0.00298842,\n",
       "        0.0026323 , 0.00299207, 0.00365559, 0.00263182, 0.0023396 ,\n",
       "        0.00264359, 0.0033075 , 0.00398922, 0.00462969, 0.00394996]),\n",
       " 'std_score_time': array([9.39088107e-04, 1.63003243e-03, 8.26212019e-06, 1.88042380e-03,\n",
       "        8.29912582e-04, 4.50805606e-04, 1.12391596e-07, 4.68617578e-04,\n",
       "        4.73652910e-04, 4.61339684e-04, 4.58831708e-04, 1.89071105e-03,\n",
       "        1.62839744e-03, 1.89988598e-03, 1.41524403e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100,\n",
       "                    1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}],\n",
       " 'split0_test_score': array([0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918,\n",
       "        0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918,\n",
       "        0.73067918, 0.73067918, 0.73067918, 0.73067918, 0.73067918]),\n",
       " 'split1_test_score': array([0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204,\n",
       "        0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204,\n",
       "        0.73918204, 0.73918204, 0.73918204, 0.73918204, 0.73918204]),\n",
       " 'split2_test_score': array([0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652,\n",
       "        0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652,\n",
       "        0.73553652, 0.73553652, 0.73553652, 0.73553652, 0.73553652]),\n",
       " 'mean_test_score': array([0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258,\n",
       "        0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258,\n",
       "        0.73513258, 0.73513258, 0.73513258, 0.73513258, 0.73513258]),\n",
       " 'std_test_score': array([0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301,\n",
       "        0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301,\n",
       "        0.00348301, 0.00348301, 0.00348301, 0.00348301, 0.00348301]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "#  {'C': [.1, 1, 10, 100, 1000],\n",
    " #  'penalty': ['l1'],\n",
    "  # 'solver': ['liblinear', 'saga']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=4000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.735133 using {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735133 (0.003483) with: {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.1, class_weight=None, solver='lbfgs' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7363849510067295\n",
      "confusion matrix\n",
      " [[3423 1246]\n",
      " [1911 4031]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7375246503388824\n",
      "confusion matrix\n",
      " [[3384 1301]\n",
      " [1838 4088]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7327580506037955\n",
      "confusion matrix\n",
      " [[3458 1278]\n",
      " [1922 3953]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0325791 , 0.07116469, 0.02892232, 0.0730962 , 0.03889481,\n",
       "        0.0545187 , 0.0279146 , 0.06483905, 0.03257958, 0.06748637,\n",
       "        0.02127663, 0.07280533, 0.06948074, 0.01762009, 0.11470334,\n",
       "        0.09506663, 0.0169553 , 0.0887622 , 0.05784512, 0.02393643,\n",
       "        0.08477259, 0.05053147, 0.01562421, 0.09341677, 0.07446869]),\n",
       " 'std_fit_time': array([0.0032912 , 0.01220755, 0.00354928, 0.01957796, 0.01345487,\n",
       "        0.00680523, 0.00244313, 0.00923087, 0.00124277, 0.00981776,\n",
       "        0.0012439 , 0.00960049, 0.01541438, 0.0032915 , 0.02268182,\n",
       "        0.03235604, 0.00293731, 0.00453496, 0.00508453, 0.00373092,\n",
       "        0.01355328, 0.00773932, 0.00308316, 0.01727902, 0.01129311]),\n",
       " 'mean_score_time': array([0.00432173, 0.00363588, 0.00233873, 0.00265988, 0.00432158,\n",
       "        0.00399113, 0.0033346 , 0.00398763, 0.00432165, 0.00465401,\n",
       "        0.00265988, 0.00265956, 0.00365671, 0.00365694, 0.00564011,\n",
       "        0.0049866 , 0.00398938, 0.00299207, 0.0039889 , 0.00498645,\n",
       "        0.00299263, 0.00332475, 0.00332355, 0.00432189, 0.00498573]),\n",
       " 'std_score_time': array([1.88081723e-03, 9.32039673e-04, 4.62242751e-04, 4.70246438e-04,\n",
       "        1.88092956e-03, 2.15273440e-03, 4.61568695e-04, 2.15578633e-03,\n",
       "        2.04911212e-03, 1.88081723e-03, 4.70077860e-04, 4.70527507e-04,\n",
       "        1.69549779e-03, 9.40998764e-04, 4.62634009e-04, 2.15446164e-03,\n",
       "        1.40995259e-03, 8.13712245e-04, 1.40894105e-03, 1.62937097e-03,\n",
       "        3.37174788e-07, 4.71371801e-04, 1.87958086e-03, 1.88053628e-03,\n",
       "        1.40950306e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013,\n",
       "        0.73602013, 0.73602013, 0.73602013, 0.73602013, 0.73602013]),\n",
       " 'split1_test_score': array([0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018,\n",
       "        0.74092018, 0.74092018, 0.74092018, 0.74092018, 0.74092018]),\n",
       " 'split2_test_score': array([0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786, 0.7270786,\n",
       "        0.7270786]),\n",
       " 'mean_test_score': array([0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297,\n",
       "        0.73467297, 0.73467297, 0.73467297, 0.73467297, 0.73467297]),\n",
       " 'std_test_score': array([0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053,\n",
       "        0.00573053, 0.00573053, 0.00573053, 0.00573053, 0.00573053]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734673 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.734673 (0.005731) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7327580506037955\n",
      "[0.70587127 0.69503346 0.70530581]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7392666949100711\n",
      "confusion matrix\n",
      " [[3453 1206]\n",
      " [1905 4047]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7323875924914998\n",
      "confusion matrix\n",
      " [[3444 1238]\n",
      " [1934 3995]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7273072261367277\n",
      "confusion matrix\n",
      " [[3440 1286]\n",
      " [1945 3940]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.09443405]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','cardio','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\parit\\Anaconda\\envs\\ML1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.85772761, 1.05984712, 0.89385668, 1.24303007, 0.80253839,\n",
       "        0.25166003, 0.23107775, 0.24800316, 0.25132895, 0.18483861]),\n",
       " 'std_fit_time': array([0.11453076, 0.3602612 , 0.27844553, 0.22999703, 0.15472474,\n",
       "        0.11010601, 0.0640617 , 0.08573024, 0.07164654, 0.06119013]),\n",
       " 'mean_score_time': array([0.00429519, 0.00396919, 0.0039645 , 0.00629536, 0.00562851,\n",
       "        0.00432158, 0.00329518, 0.00664941, 0.00465322, 0.00731365]),\n",
       " 'std_score_time': array([1.26596863e-03, 2.02501463e-05, 1.70713178e-05, 1.87108661e-03,\n",
       "        1.71076111e-03, 1.24413389e-03, 4.90599204e-04, 1.87969325e-03,\n",
       "        1.69482766e-03, 4.70077941e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77987107, 0.77982106, 0.77981164, 0.77981232, 0.77979055,\n",
       "        0.66067475, 0.66066092, 0.6627988 , 0.67384393, 0.66065905]),\n",
       " 'split1_test_score': array([0.78198072, 0.78156855, 0.78206247, 0.78207487, 0.78161375,\n",
       "        0.61334362, 0.61334228, 0.61334214, 0.61334214, 0.6133421 ]),\n",
       " 'split2_test_score': array([0.78019565, 0.78027309, 0.77966553, 0.78027482, 0.7802537 ,\n",
       "        0.65539128, 0.6528766 , 0.65285732, 0.65285732, 0.65285721]),\n",
       " 'mean_test_score': array([0.78068248, 0.78055424, 0.78051321, 0.78072067, 0.78055266,\n",
       "        0.64313655, 0.64229327, 0.64299942, 0.64668113, 0.64228612]),\n",
       " 'std_test_score': array([0.00092751, 0.00074059, 0.00109711, 0.000976  , 0.00077376,\n",
       "        0.02117692, 0.02071664, 0.02135999, 0.02508287, 0.02071287]),\n",
       " 'rank_test_score': array([ 2,  3,  5,  1,  4,  7,  9,  8,  6, 10])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.780721 using {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780682 (0.000928) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780554 (0.000741) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780513 (0.001097) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780721 (0.000976) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.780553 (0.000774) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.643137 (0.021177) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642293 (0.020717) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642999 (0.021360) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.646681 (0.025083) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642286 (0.020713) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7854504726435688\n",
      "confusion matrix\n",
      " [[3388 1222]\n",
      " [1725 4276]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7817470520594516\n",
      "confusion matrix\n",
      " [[3372 1281]\n",
      " [1730 4228]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7786116035695742\n",
      "confusion matrix\n",
      " [[3399 1389]\n",
      " [1631 4192]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0867784 , 0.19680611, 0.09707483, 0.20843832, 0.08710074,\n",
       "        0.23805221, 0.08577061, 0.22979315, 0.08510574, 0.19846845,\n",
       "        0.0468746 , 0.2081097 , 0.17187405, 0.0588429 , 0.26696332,\n",
       "        0.16589936, 0.04654225, 0.23171298, 0.16057134, 0.06151366,\n",
       "        0.18784165, 0.15691241, 0.04688811, 0.23803997, 0.16389434]),\n",
       " 'std_fit_time': array([0.00803452, 0.03944448, 0.02067177, 0.02817772, 0.01924246,\n",
       "        0.01225835, 0.00081624, 0.0336347 , 0.00896927, 0.02378397,\n",
       "        0.00635917, 0.0363652 , 0.01964279, 0.0078523 , 0.03987367,\n",
       "        0.01483394, 0.00094117, 0.00983122, 0.00695654, 0.02439465,\n",
       "        0.00878869, 0.02823671, 0.00588624, 0.02971557, 0.01459726]),\n",
       " 'mean_score_time': array([0.00664981, 0.00598502, 0.00797757, 0.00398938, 0.00432142,\n",
       "        0.00396641, 0.00797892, 0.00464328, 0.00531896, 0.00465504,\n",
       "        0.00498676, 0.00364582, 0.00365655, 0.00565076, 0.00564138,\n",
       "        0.00398986, 0.00571744, 0.00399065, 0.00498629, 0.00576242,\n",
       "        0.00364614, 0.00598502, 0.00564893, 0.00397937, 0.00598383]),\n",
       " 'std_score_time': array([1.24371040e-03, 2.82131005e-03, 2.82052358e-03, 2.24783192e-07,\n",
       "        4.70134691e-04, 1.66896790e-05, 2.15442485e-03, 9.47835939e-04,\n",
       "        1.88019902e-03, 2.35016452e-03, 2.15457201e-03, 4.85475743e-04,\n",
       "        4.71145933e-04, 1.69393912e-03, 2.35812633e-03, 4.05233662e-07,\n",
       "        2.30456559e-03, 1.52040533e-06, 1.40939063e-03, 2.29656734e-03,\n",
       "        4.63135807e-04, 2.15541816e-03, 2.48448719e-03, 8.02158127e-04,\n",
       "        1.62800842e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.77901223, 0.77901557, 0.77900687, 0.77900637, 0.77900565,\n",
       "        0.77900536, 0.77900446, 0.77900543, 0.77900464, 0.77900612,\n",
       "        0.77900392, 0.779004  , 0.77900331, 0.77900482, 0.77900407,\n",
       "        0.77900446, 0.77900565, 0.77900572, 0.77900619, 0.77900511,\n",
       "        0.77900551, 0.77900525, 0.77900511, 0.77900497, 0.77900561]),\n",
       " 'split1_test_score': array([0.77520229, 0.77520164, 0.77519228, 0.77519225, 0.77519171,\n",
       "        0.77519044, 0.77519116, 0.77519055, 0.77519048, 0.77519077,\n",
       "        0.77519766, 0.77519622, 0.77519748, 0.77519102, 0.77518972,\n",
       "        0.77519041, 0.77519084, 0.77519095, 0.77519124, 0.77519084,\n",
       "        0.77519059, 0.77519023, 0.77519091, 0.77519149, 0.77519033]),\n",
       " 'split2_test_score': array([0.77860264, 0.77860383, 0.77855605, 0.77855623, 0.7785513 ,\n",
       "        0.7785512 , 0.77855076, 0.77855231, 0.77855105, 0.77855199,\n",
       "        0.77854523, 0.77854375, 0.77854541, 0.77855148, 0.77855159,\n",
       "        0.77855231, 0.77855188, 0.77855127, 0.77855202, 0.77855181,\n",
       "        0.7785513 , 0.77855174, 0.77855174, 0.77855041, 0.77855051]),\n",
       " 'mean_test_score': array([0.77760572, 0.77760701, 0.77758507, 0.77758495, 0.77758289,\n",
       "        0.77758233, 0.77758213, 0.77758277, 0.77758206, 0.77758296,\n",
       "        0.77758227, 0.77758132, 0.77758207, 0.77758244, 0.77758179,\n",
       "        0.77758239, 0.77758279, 0.77758265, 0.77758315, 0.77758259,\n",
       "        0.77758247, 0.77758241, 0.77758259, 0.77758229, 0.77758215]),\n",
       " 'std_test_score': array([0.00170769, 0.00170914, 0.00170193, 0.00170185, 0.00170096,\n",
       "        0.00170145, 0.00170078, 0.00170164, 0.00170121, 0.00170166,\n",
       "        0.00169654, 0.00169696, 0.00169649, 0.00170109, 0.00170151,\n",
       "        0.00170143, 0.00170148, 0.00170133, 0.00170147, 0.00170131,\n",
       "        0.00170145, 0.00170163, 0.00170127, 0.0017007 , 0.00170145]),\n",
       " 'rank_test_score': array([ 2,  1,  3,  4,  7, 17, 21,  9, 23,  6, 19, 25, 22, 14, 24, 16,  8,\n",
       "        10,  5, 12, 13, 15, 11, 18, 20])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.777607 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777606 (0.001708) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777607 (0.001709) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777585 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777585 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777583 (0.001702) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.777583 (0.001702) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001697) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777581 (0.001697) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001696) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001702) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001702) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.777583 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.777582 (0.001701) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7786511652363493\n",
      "[0.71265668 0.71199698 0.71623787]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7773814507479797\n",
      "confusion matrix\n",
      " [[3361 1293]\n",
      " [1725 4232]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7734876054094295\n",
      "confusion matrix\n",
      " [[3313 1292]\n",
      " [1712 4294]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7798040522052846\n",
      "confusion matrix\n",
      " [[3402 1324]\n",
      " [1699 4186]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29565621,  0.9020981 ,  0.1296683 ,  0.3236999 , -0.07848062,\n",
       "        -0.03665095, -0.04820689, -0.09434821,  0.10183709]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.780\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','gluc','smoke','alco','active','cardio','bmi','bp','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.58977667, 0.61006085, 0.50205167, 0.66789786, 0.62170815,\n",
       "        0.23470434, 0.16256507, 0.14594237, 0.1791877 , 0.16256571]),\n",
       " 'std_fit_time': array([0.14277105, 0.12323054, 0.06742446, 0.12424486, 0.14168672,\n",
       "        0.11365907, 0.02684776, 0.02407847, 0.02394067, 0.0355976 ]),\n",
       " 'mean_score_time': array([0.00361983, 0.00462731, 0.00363   , 0.00498184, 0.00395195,\n",
       "        0.00698217, 0.00365702, 0.00498676, 0.00465393, 0.00664822]),\n",
       " 'std_score_time': array([4.67968739e-04, 9.58724525e-04, 4.85599762e-04, 2.17114763e-03,\n",
       "        7.80211418e-06, 8.13322746e-04, 9.39425201e-04, 2.15405697e-03,\n",
       "        1.24273209e-03, 1.24328429e-03]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.77541749, 0.77528774, 0.77530839, 0.77534189, 0.77542691,\n",
       "        0.65145173, 0.61447231, 0.61447238, 0.61447238, 0.61447238]),\n",
       " 'split1_test_score': array([0.77700179, 0.77685783, 0.77690186, 0.77696873, 0.77695995,\n",
       "        0.61707295, 0.77693632, 0.61707366, 0.61707331, 0.61707331]),\n",
       " 'split2_test_score': array([0.77182184, 0.77169922, 0.77185484, 0.77164538, 0.77166388,\n",
       "        0.61772326, 0.61772341, 0.61772337, 0.61772333, 0.61772333]),\n",
       " 'mean_test_score': array([0.77474704, 0.77461493, 0.77468836, 0.774652  , 0.77468358,\n",
       "        0.62874931, 0.66971068, 0.61642314, 0.61642301, 0.61642301]),\n",
       " 'std_test_score': array([0.0021672 , 0.00215906, 0.00210656, 0.00222733, 0.00222508,\n",
       "        0.01605523, 0.07583159, 0.00140466, 0.0014046 , 0.0014046 ]),\n",
       " 'rank_test_score': array([1, 5, 2, 4, 3, 7, 6, 8, 9, 9])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.774747 using {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774747 (0.002167) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774615 (0.002159) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774688 (0.002107) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774652 (0.002227) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.774684 (0.002225) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.628749 (0.016055) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.669711 (0.075832) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.616423 (0.001405) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "#LogisticRegression(solver='lbfgs')\n",
    "lr_clf = LogisticRegression(penalty='l1', C=0.1, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7829777782643877\n",
      "confusion matrix\n",
      " [[3402 1285]\n",
      " [1742 4182]]\n",
      "====Iteration 1  ====\n",
      "auc 0.77953422780246\n",
      "confusion matrix\n",
      " [[3366 1317]\n",
      " [1697 4231]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7747743403872166\n",
      "confusion matrix\n",
      " [[3349 1325]\n",
      " [1708 4229]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08809757, 0.13563728, 0.06482752, 0.16489116, 0.07480113,\n",
       "        0.14961012, 0.06216677, 0.15092953, 0.05485304, 0.17256172,\n",
       "        0.04654177, 0.16123454, 0.11635526, 0.03590242, 0.18483822,\n",
       "        0.13430683, 0.03324374, 0.20578257, 0.15159082, 0.04055818,\n",
       "        0.19380649, 0.15458751, 0.04986604, 0.21110177, 0.15325602]),\n",
       " 'std_fit_time': array([0.03218648, 0.01485994, 0.00924807, 0.03804149, 0.01216045,\n",
       "        0.04236068, 0.00470067, 0.01793922, 0.00293634, 0.02788303,\n",
       "        0.00835811, 0.01477766, 0.01192058, 0.00162811, 0.0333917 ,\n",
       "        0.01265079, 0.00046997, 0.00954353, 0.02492565, 0.00308274,\n",
       "        0.02732095, 0.04044341, 0.01447601, 0.01186529, 0.01681352]),\n",
       " 'mean_score_time': array([0.00565147, 0.0036575 , 0.00432118, 0.00365742, 0.00398898,\n",
       "        0.00364661, 0.0043215 , 0.00531912, 0.00365702, 0.00529559,\n",
       "        0.00365678, 0.0053196 , 0.00398978, 0.00532039, 0.00399025,\n",
       "        0.00531896, 0.00332483, 0.00631698, 0.00465369, 0.00548855,\n",
       "        0.00397881, 0.0043207 , 0.00631706, 0.0039893 , 0.0053192 ]),\n",
       " 'std_score_time': array([2.48763076e-03, 4.70471583e-04, 4.70471583e-04, 4.70077860e-04,\n",
       "        1.94667955e-07, 4.62491035e-04, 4.69909263e-04, 2.61769653e-03,\n",
       "        9.40436725e-04, 1.87182507e-03, 4.70471261e-04, 1.88143536e-03,\n",
       "        8.15074920e-04, 2.61832230e-03, 7.86741172e-07, 2.04895751e-03,\n",
       "        4.71314168e-04, 2.35100780e-03, 9.40211902e-04, 2.12054846e-03,\n",
       "        1.43874413e-05, 4.70808557e-04, 2.04940865e-03, 1.07214749e-06,\n",
       "        1.88070477e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.78195624, 0.78195818, 0.78194988, 0.78195117, 0.78194956,\n",
       "        0.78194776, 0.78194772, 0.78194837, 0.78194546, 0.78194718,\n",
       "        0.78193935, 0.78193928, 0.78194003, 0.78194582, 0.78194603,\n",
       "        0.781946  , 0.78194744, 0.78194787, 0.7819474 , 0.78194751,\n",
       "        0.78194754, 0.78194643, 0.7819474 , 0.78194794, 0.78194797]),\n",
       " 'split1_test_score': array([0.77785879, 0.77786002, 0.77785547, 0.77785568, 0.77785547,\n",
       "        0.77785568, 0.77785532, 0.77785659, 0.77785493, 0.77785576,\n",
       "        0.7778524 , 0.77785319, 0.77785258, 0.77785493, 0.77785467,\n",
       "        0.77785485, 0.77785558, 0.77785597, 0.77785576, 0.77785576,\n",
       "        0.77785518, 0.77785532, 0.77785597, 0.77785478, 0.77785359]),\n",
       " 'split2_test_score': array([0.78418725, 0.78418923, 0.78417137, 0.78417022, 0.78416942,\n",
       "        0.78416863, 0.78416935, 0.78416989, 0.7841673 , 0.78416896,\n",
       "        0.78415934, 0.7841592 , 0.78415938, 0.78416748, 0.78416654,\n",
       "        0.78416798, 0.78416942, 0.78417195, 0.78416842, 0.78416964,\n",
       "        0.78416838, 0.78416849, 0.78416964, 0.78416795, 0.78416795]),\n",
       " 'mean_test_score': array([0.78133409, 0.78133581, 0.78132557, 0.78132569, 0.78132482,\n",
       "        0.78132403, 0.78132413, 0.78132495, 0.78132256, 0.78132397,\n",
       "        0.78131703, 0.78131722, 0.78131733, 0.78132274, 0.78132242,\n",
       "        0.78132295, 0.78132415, 0.78132526, 0.78132386, 0.7813243 ,\n",
       "        0.7813237 , 0.78132341, 0.78132434, 0.78132356, 0.78132317]),\n",
       " 'std_test_score': array([0.00262077, 0.0026211 , 0.00261597, 0.00261556, 0.00261524,\n",
       "        0.00261472, 0.00261513, 0.00261482, 0.00261439, 0.00261476,\n",
       "        0.00261213, 0.00261172, 0.00261212, 0.00261448, 0.00261427,\n",
       "        0.00261471, 0.00261503, 0.0026158 , 0.00261458, 0.00261503,\n",
       "        0.00261483, 0.00261472, 0.00261493, 0.00261488, 0.00261541]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  3,  7, 12, 11,  6, 21, 13, 25, 24, 23, 20, 22, 19, 10,\n",
       "         5, 14,  9, 15, 17,  8, 16, 18])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.781336 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781334 (0.002621) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781336 (0.002621) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781326 (0.002616) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781326 (0.002616) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781325 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781325 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781323 (0.002614) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781317 (0.002612) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781323 (0.002614) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781322 (0.002614) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781325 (0.002616) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.781324 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.781323 (0.002615) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774929622251729\n",
      "[0.71124305 0.71209123 0.70907549]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'saga'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7753158137417063\n",
      "confusion matrix\n",
      " [[3353 1340]\n",
      " [1733 4185]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7755508656370104\n",
      "confusion matrix\n",
      " [[3434 1287]\n",
      " [1762 4128]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7724583962001766\n",
      "confusion matrix\n",
      " [[3362 1318]\n",
      " [1747 4184]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30249373, 0.09140337, 0.8996206 , 0.12844921, 0.28637318]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.772\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data setup\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Paritosh\\SMU\\SMUMSDS-ML1\\cardio_train.csv\", sep=\";\")\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We address the weight with reasonable weight, the other values probably are a mistake\n",
    "df1 = df1[df1[\"weight\"] < 200]\n",
    "df1 = df1[df1[\"weight\"] > 55]\n",
    "\n",
    "# We address the height, the other values probably are a mistake\n",
    "df1 = df1[df1[\"height\"] < 200]\n",
    "df1 = df1[df1[\"height\"] > 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only reasonable blood pressure measurements\n",
    "df1 = df1[df1[\"ap_hi\"] < 200]\n",
    "df1 = df1[df1[\"ap_hi\"] > 110]\n",
    "df1 = df1[df1[\"ap_lo\"] < 150]\n",
    "df1 = df1[df1[\"ap_lo\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the body mass index based on weight and height\n",
    "df1['bmi'] = df1['weight'] / (df1['height']/100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df1['bp'] = np.where((df1.ap_hi < 120) & (df1.ap_lo < 80), 1, 0)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 120) & (df1.ap_hi < 130) & (df1.ap_lo < 80), 2, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 130) & (df1.ap_hi < 140) | ((df1.ap_lo >= 80) & (df1.ap_lo < 90)), 3, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi >= 140) | (df1.ap_lo >= 90), 4, df1.bp)\n",
    "df1['bp'] = np.where((df1.ap_hi > 180) | (df1.ap_lo > 120), 5, df1.bp)\n",
    "df1['bp1'] = pd.cut(df1.bp,[0,1,2,3,4,5],5,labels=['Normal','Elevated','Hyper_Stage1','Hyper_Stage2','Hyper_Stage3' ]) # this creates a new variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains primarily people in hypertension stage 1 and stage 2. See the counts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Normal</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elevated</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage1</td>\n",
       "      <td>28219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage2</td>\n",
       "      <td>22049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hyper_Stage3</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bp\n",
       "bp1                \n",
       "Normal          177\n",
       "Elevated       2472\n",
       "Hyper_Stage1  28219\n",
       "Hyper_Stage2  22049\n",
       "Hyper_Stage3    136"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#show counts of people in each BMI group\n",
    "\n",
    "df_grouped = df1.groupby(by='bp1')\n",
    "\n",
    "df_grouped[['bp']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>bp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>4</td>\n",
       "      <td>Hyper_Stage2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.729725</td>\n",
       "      <td>3</td>\n",
       "      <td>Hyper_Stage1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "\n",
       "   alco  active  cardio        bmi  bp           bp1  \n",
       "1     0       1       1  34.927679   4  Hyper_Stage2  \n",
       "2     0       0       1  23.507805   3  Hyper_Stage1  \n",
       "3     0       1       1  28.710479   4  Hyper_Stage2  \n",
       "5     0       0       0  29.384676   3  Hyper_Stage1  \n",
       "6     0       1       0  37.729725   3  Hyper_Stage1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "Following are combo I selected based on high correlation and removing \n",
    "1.\t'bmi', 'ap_hi', 'ap_lo','cholesterol','age' (top 5 co-relation)\n",
    "2.\t'ap_hi' (highest co-relation)\n",
    "3.\t'bmi', 'age', 'ap_lo','ap_hi', 'cholesterol','gluc','smoke','alco','active' (all variable)\n",
    "4.\t‘weight’, 'age', 'ap_lo','ap_hi', 'cholesterol' (replace BMI with weight and drop Height as co-relation is low for height)\n",
    "5.\t'bmi', 'age', ‘bp’, 'cholesterol' (high correlation and removed colinear once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1\n",
    "#df\n",
    "# option 1\n",
    "y = df['cardio'].values # get the labels we want\n",
    "df.drop(['id','gender','height','weight','ap_hi','ap_lo','cholesterol','gluc','smoke','alco','active','cardio','bp1'], axis =1, inplace = True) # get rid of the class label\n",
    "#df.head(5)\n",
    "X = df.values # Option1\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.28792159, 0.3982842 , 0.34011745, 0.27063163, 0.29957183,\n",
       "        0.02470827, 0.02825872, 0.02491188, 0.03523866, 0.03025254]),\n",
       " 'std_fit_time': array([0.02944319, 0.03942984, 0.08878178, 0.03130499, 0.03117728,\n",
       "        0.00250116, 0.00248755, 0.00162936, 0.00971533, 0.00692428]),\n",
       " 'mean_score_time': array([0.0029579 , 0.00430473, 0.00362992, 0.00496467, 0.00361713,\n",
       "        0.0032169 , 0.0046525 , 0.00332411, 0.00432165, 0.00299136]),\n",
       " 'std_score_time': array([3.22428747e-06, 4.81892504e-04, 4.74639717e-04, 8.28353901e-04,\n",
       "        9.35435760e-04, 5.61182179e-04, 2.35229991e-03, 4.68617012e-04,\n",
       "        1.88070479e-03, 1.32507737e-06]),\n",
       " 'param_C': masked_array(data=[0.1, 1, 10, 100, 1000, 0.1, 1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear', 'liblinear', 'liblinear',\n",
       "                    'liblinear', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.74937626, 0.74934896, 0.74934534, 0.74936344, 0.74936742,\n",
       "        0.61387189, 0.61387189, 0.61387189, 0.61387189, 0.61387189]),\n",
       " 'split1_test_score': array([0.73950087, 0.73943044, 0.73943141, 0.73949925, 0.73944709,\n",
       "        0.60895519, 0.60895519, 0.60895519, 0.60895519, 0.60895519]),\n",
       " 'split2_test_score': array([0.74173435, 0.741696  , 0.74172531, 0.74171948, 0.74172024,\n",
       "        0.6147249 , 0.6147249 , 0.6147249 , 0.6147249 , 0.6147249 ]),\n",
       " 'mean_test_score': array([0.74353716, 0.7434918 , 0.74350069, 0.74352739, 0.74351158,\n",
       "        0.61251733, 0.61251733, 0.61251733, 0.61251733, 0.61251733]),\n",
       " 'std_test_score': array([0.00422835, 0.00424366, 0.00423757, 0.00422508, 0.00424342,\n",
       "        0.00254277, 0.00254277, 0.00254277, 0.00254277, 0.00254277]),\n",
       " 'rank_test_score': array([1, 5, 4, 2, 3, 6, 6, 6, 6, 6])}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l1'],\n",
    "   'solver': ['liblinear']},\n",
    "  {'C': [.1, 1, 10, 100, 1000],\n",
    "   'penalty': ['l2'], \n",
    "   'solver': ['lbfgs']},\n",
    " ]\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\",cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "LogisticRegression()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None, solver='liblinear' ) # get object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.6545841722217853\n",
      "confusion matrix\n",
      " [[ 321 4334]\n",
      " [ 157 5799]]\n",
      "====Iteration 1  ====\n",
      "auc 0.6576116009160325\n",
      "confusion matrix\n",
      " [[ 256 4415]\n",
      " [ 154 5786]]\n",
      "====Iteration 2  ====\n",
      "auc 0.6506144107276153\n",
      "confusion matrix\n",
      " [[ 403 4267]\n",
      " [ 275 5666]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make CV spit 80/20 object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03557197, 0.08942699, 0.04489152, 0.10970656, 0.04089117,\n",
       "        0.0997328 , 0.02991954, 0.0930829 , 0.04255311, 0.11668921,\n",
       "        0.02760235, 0.11135689, 0.10040871, 0.03058624, 0.13398631,\n",
       "        0.07944194, 0.02359223, 0.12234012, 0.1090529 , 0.03292378,\n",
       "        0.17496681, 0.10039862, 0.03058441, 0.15358957, 0.078789  ]),\n",
       " 'std_fit_time': array([0.00308246, 0.00448607, 0.00775783, 0.0171591 , 0.01272123,\n",
       "        0.00906804, 0.00081459, 0.01164095, 0.00339056, 0.00614811,\n",
       "        0.00515952, 0.01110522, 0.01970331, 0.00417954, 0.02376628,\n",
       "        0.01262173, 0.0012312 , 0.01301187, 0.01477985, 0.00734337,\n",
       "        0.02226991, 0.01186713, 0.00542353, 0.00564352, 0.0048851 ]),\n",
       " 'mean_score_time': array([0.00432221, 0.00398938, 0.00563947, 0.00531912, 0.00365655,\n",
       "        0.00565219, 0.00365734, 0.00398993, 0.00433334, 0.00564988,\n",
       "        0.0056502 , 0.00299287, 0.00431061, 0.00598327, 0.00432189,\n",
       "        0.00465322, 0.00400066, 0.00365686, 0.00564019, 0.00497564,\n",
       "        0.00397452, 0.00398874, 0.00565203, 0.00565108, 0.00531888]),\n",
       " 'std_score_time': array([4.70246599e-04, 2.97360213e-07, 2.33381149e-03, 3.29133173e-03,\n",
       "        4.70134207e-04, 1.87974945e-03, 4.70527668e-04, 1.03008599e-06,\n",
       "        4.85475509e-04, 1.87997427e-03, 2.32778454e-03, 1.52040533e-06,\n",
       "        1.24607396e-03, 2.15457205e-03, 4.70979246e-04, 1.69389232e-03,\n",
       "        1.58472150e-05, 4.70023630e-04, 2.33465443e-03, 1.65849024e-05,\n",
       "        8.21387273e-04, 1.01152436e-06, 2.35038935e-03, 1.69423526e-03,\n",
       "        1.88076098e-03]),\n",
       " 'param_classifier__C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10, 100, 100, 1000, 1000, 0.1, 0.1,\n",
       "                    0.1, 1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga', 'lbfgs', 'sag', 'saga',\n",
       "                    'lbfgs', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'liblinear'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l1',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 0.1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 10,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 100,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'lbfgs'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'sag'},\n",
       "  {'classifier__C': 1000,\n",
       "   'classifier__penalty': 'l2',\n",
       "   'classifier__solver': 'saga'}],\n",
       " 'split0_test_score': array([0.74323294, 0.74323341, 0.74323193, 0.74323294, 0.74323215,\n",
       "        0.74323279, 0.7432324 , 0.74323243, 0.74323229, 0.74323247,\n",
       "        0.74323121, 0.74323142, 0.7432311 , 0.74323114, 0.74323182,\n",
       "        0.74323153, 0.74323233, 0.74323157, 0.74323186, 0.74323233,\n",
       "        0.74323272, 0.74323222, 0.74323233, 0.74323153, 0.74323269]),\n",
       " 'split1_test_score': array([0.74452091, 0.74451986, 0.74452026, 0.74452047, 0.74451989,\n",
       "        0.74452026, 0.74451997, 0.74451986, 0.74451989, 0.74452004,\n",
       "        0.74452033, 0.74452054, 0.7445204 , 0.74451971, 0.74452015,\n",
       "        0.74451961, 0.74451971, 0.74451986, 0.74452036, 0.74451982,\n",
       "        0.74452022, 0.74451986, 0.74451993, 0.74451982, 0.74451946]),\n",
       " 'split2_test_score': array([0.74398301, 0.74398347, 0.74398066, 0.74398102, 0.74397983,\n",
       "        0.74398037, 0.74398023, 0.74398001, 0.74398041, 0.74397976,\n",
       "        0.74398048, 0.74398001, 0.74398005, 0.74398045, 0.74398023,\n",
       "        0.74398091, 0.74398034, 0.74397969, 0.74398037, 0.74398037,\n",
       "        0.74398041, 0.74398052, 0.74398037, 0.74398019, 0.74398034]),\n",
       " 'mean_test_score': array([0.74391228, 0.74391225, 0.74391095, 0.74391148, 0.74391062,\n",
       "        0.74391114, 0.74391086, 0.74391077, 0.74391086, 0.74391076,\n",
       "        0.74391067, 0.74391066, 0.74391052, 0.74391043, 0.74391073,\n",
       "        0.74391068, 0.74391079, 0.74391037, 0.74391086, 0.74391084,\n",
       "        0.74391112, 0.74391086, 0.74391088, 0.74391052, 0.74391083]),\n",
       " 'std_test_score': array([0.00052818, 0.0005276 , 0.00052826, 0.00052793, 0.00052799,\n",
       "        0.00052788, 0.00052793, 0.00052786, 0.00052796, 0.00052791,\n",
       "        0.00052859, 0.00052856, 0.00052865, 0.00052838, 0.00052825,\n",
       "        0.00052819, 0.00052787, 0.00052822, 0.00052832, 0.00052791,\n",
       "        0.0005279 , 0.00052798, 0.00052795, 0.00052824, 0.00052762]),\n",
       " 'rank_test_score': array([ 1,  2,  6,  3, 21,  4,  9, 15, 10, 16, 19, 20, 22, 24, 17, 18, 14,\n",
       "        25,  8, 12,  5, 11,  7, 23, 13])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#make a grid search for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l1'],\n",
    "   'classifier__solver': ['liblinear', 'saga']},\n",
    "  {'classifier__C': [.1, 1, 10, 100, 1000],\n",
    "   'classifier__penalty': ['l2'], \n",
    "   'classifier__solver': ['lbfgs', 'sag', 'saga']},\n",
    " ]\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "clf = GridSearchCV(lr, param_grid, scoring=\"roc_auc\", cv=cv_object)\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "clf.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.743912 using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743912 (0.000528) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743912 (0.000528) with: {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000529) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743910 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743910 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
      "0.743911 (0.000528) with: {'classifier__C': 1000, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#code adapted from https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333350033357999\n",
      "[0.69983979 0.70483461 0.70210159]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C= 0.1, penalty= 'l1', solver= 'liblinear'))\n",
    "model_s=lr_clf\n",
    "model_s.fit(X_train, y_train)\n",
    "pred_prob_s = model_s.predict_proba(X_test)\n",
    "auc_score_s = roc_auc_score(y_test, pred_prob_s[:,1])\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(auc_score_s)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "auc 0.7449583077169937\n",
      "confusion matrix\n",
      " [[3178 1483]\n",
      " [1636 4314]]\n",
      "====Iteration 1  ====\n",
      "auc 0.7403036835573813\n",
      "confusion matrix\n",
      " [[3123 1522]\n",
      " [1641 4325]]\n",
      "====Iteration 2  ====\n",
      "auc 0.7442072616685852\n",
      "confusion matrix\n",
      " [[3157 1549]\n",
      " [1602 4303]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    y_prob=lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    #acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    auc = mt.roc_auc_score(y_test,y_prob)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "   # print(\"accuracy\", acc )\n",
    "    print(\"auc\", auc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\\naccuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\\nprint(accuracies)\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lr_clf = make_pipeline(StandardScaler(), LogisticRegression( solver= 'lbfgs'))\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object)\n",
    "print(accuracies)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34692142, 0.18307629, 0.79513794]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: ROC AUC=0.744\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = lr_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\\\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
